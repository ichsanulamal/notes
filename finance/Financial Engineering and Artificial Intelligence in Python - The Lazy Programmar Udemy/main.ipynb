{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 1000 samples from standard normal distribution\n",
    "samples = np.random.normal(loc=0, scale=1, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time indices\n",
    "time_indices = np.arange(1000)\n",
    "\n",
    "# Plot time series\n",
    "plt.plot(time_indices, samples, color='blue')\n",
    "plt.title('Time Series of Standard Normal Distribution')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "plt.hist(samples, bins=30, density=True, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Standard Normal Distribution')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a linear trend to the samples\n",
    "trend = 0.02 * time_indices  # Adjust the slope for the trend\n",
    "samples_with_trend = samples + trend\n",
    "\n",
    "# Plot scatter plot of the time series with trend\n",
    "plt.scatter(time_indices, samples_with_trend, color='blue', alpha=0.5, label='Samples with Trend')\n",
    "\n",
    "# Find and plot the best-fit line\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(time_indices, samples_with_trend)\n",
    "best_fit_line = slope * time_indices + intercept\n",
    "plt.plot(time_indices, best_fit_line, color='red', label='Best-fit Line')\n",
    "\n",
    "plt.title('Time Series with Trend and Best-fit Line')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cumulative sum\n",
    "cumulative_sum = np.cumsum(samples)\n",
    "\n",
    "# Plot the cumulative sum\n",
    "plt.plot(cumulative_sum, color='blue')\n",
    "plt.title('Cumulative Sum of Standard Normal Distribution')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Cumulative Sum')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you apply `np.cumsum()` (cumulative sum) to a series of random noise, it effectively integrates the noise over time, accumulating the values. This process can resemble a random walk.\n",
    "\n",
    "The resulting plot demonstrates the cumulative effect of adding each value of the random noise sequentially, which resembles a random walk process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean vector and covariance matrix for multivariate normal distribution\n",
    "mean = [0, 0]  # mean vector\n",
    "covariance_matrix = [[1, -0.5], [0.5, 2]]  # covariance matrix\n",
    "\n",
    "# Generate 1000 samples from multivariate normal distribution\n",
    "samples = np.random.multivariate_normal(mean, covariance_matrix, size=1000)\n",
    "\n",
    "# Extract x and y coordinates\n",
    "x = samples[:, 0]\n",
    "y = samples[:, 1]\n",
    "\n",
    "# Plot the samples\n",
    "plt.scatter(x, y, color='blue', alpha=0.5)\n",
    "plt.title('Scatter Plot of Multivariate Normal Distribution')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sample mean\n",
    "sample_mean = np.mean(samples, axis=0)\n",
    "\n",
    "# Calculate sample covariance\n",
    "sample_covariance = np.cov(samples, rowvar=False)\n",
    "\n",
    "print(\"Sample Mean:\")\n",
    "print(sample_mean)\n",
    "\n",
    "print(\"\\nSample Covariance Matrix:\")\n",
    "print(sample_covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sample mean\n",
    "sample_mean = np.sum(samples, axis=0) / len(samples)\n",
    "\n",
    "# Calculate sample covariance\n",
    "centered_samples = samples - sample_mean\n",
    "sample_covariance = np.dot(centered_samples.T, centered_samples) / (len(samples) - 1)\n",
    "\n",
    "print(\"Sample Mean:\")\n",
    "print(sample_mean)\n",
    "\n",
    "print(\"\\nSample Covariance Matrix:\")\n",
    "print(sample_covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Financial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best IoT companies in the NASDAQ are:\n",
    "\n",
    "1. **Cisco Systems (NASDAQ:CSCO)**: A leading provider of enterprise networking hardware[2].\n",
    "2. **Alarm.com (NASDAQ:ALRM)**: A cloud-based platform for managing connected home and business devices[2].\n",
    "3. **Skyworks Solutions (NASDAQ: SWKS)**: Excels in semiconductor technology[5].\n",
    "4. **Honeywell (NASDAQ: HON)**: Has a diversified portfolio navigating various IoT sectors[5].\n",
    "5. **Johnson Controls (NYSE: JCI)**: A leader in intelligent and sustainable building solutions[5].\n",
    "\n",
    "These companies are among the top IoT stocks in the market and are worth considering for investment.\n",
    "\n",
    "Citations:\n",
    "[1] https://consent.yahoo.com/v2/collectConsent\n",
    "[2] https://www.fool.com/investing/stock-market/market-sectors/information-technology/iot-stocks/\n",
    "[3] https://finance.yahoo.com/news/10-internet-things-iot-stocks-145900609.html\n",
    "[4] https://www.nasdaq.com/articles/the-3-most-promising-iot-stocks-to-buy-in-2023\n",
    "[5] https://finbold.com/guide/3-iot-stocks-to-buy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "\n",
    "# Define the tickers\n",
    "tickers = ['CSCO', 'ALRM', 'SWKS', 'HON', 'JCI']\n",
    "\n",
    "# Download historical data\n",
    "# data = yf.download(tickers, start='2020-01-01', end='2024-01-01')['Adj Close']\n",
    "data = yf.download(tickers, start='2018-01-01', end='2023-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.xs('CSCO', level=1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ df['Adj Close'].isna() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data\n",
    "plt.figure(figsize=(14, 7))\n",
    "for ticker in tickers:\n",
    "    plt.plot(data['Adj Close'][ticker], label=ticker)\n",
    "\n",
    "plt.title('S&P 500 vs DOW vs NASDAQ')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Adjusted Close Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fillna with Backward Filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t, norm, skewnorm\n",
    "\n",
    "# Parameters\n",
    "df = 3  # degrees of freedom for t-distribution\n",
    "alpha_left = -5  # left skewness parameter\n",
    "alpha_right = 5  # right skewness parameter\n",
    "\n",
    "# Generate data\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "t_dist = t.pdf(x, df)\n",
    "norm_dist = norm.pdf(x)\n",
    "skew_left_dist = skewnorm.pdf(x, alpha_left)\n",
    "skew_right_dist = skewnorm.pdf(x, alpha_right)\n",
    "\n",
    "# Plot distributions\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Thick Tails (t-distribution)\n",
    "plt.plot(x, t_dist, label='Thick Tails (t-distribution)', color='blue')\n",
    "\n",
    "# Thin Tails (normal distribution)\n",
    "plt.plot(x, norm_dist, label='Thin Tails (normal distribution)', color='red')\n",
    "\n",
    "# Left Skewed Distribution\n",
    "plt.plot(x, skew_left_dist, label='Left Skewed', color='green', linestyle='--')\n",
    "\n",
    "# Right Skewed Distribution\n",
    "plt.plot(x, skew_right_dist, label='Right Skewed', color='purple', linestyle='--')\n",
    "\n",
    "plt.title('Comparison of Different Tail Behaviors')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QQ Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t, norm, skewnorm, probplot\n",
    "\n",
    "# Parameters\n",
    "df = 3  # degrees of freedom for t-distribution\n",
    "alpha_left = -5  # left skewness parameter\n",
    "alpha_right = 5  # right skewness parameter\n",
    "\n",
    "# Generate data\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "t_dist = t.rvs(df, size=1000)\n",
    "norm_dist = norm.rvs(size=1000)\n",
    "skew_left_dist = skewnorm.rvs(alpha_left, size=1000)\n",
    "skew_right_dist = skewnorm.rvs(alpha_right, size=1000)\n",
    "\n",
    "# Create QQ plots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "# QQ plot for t-distribution\n",
    "probplot(t_dist, dist=\"t\", sparams=(df,), plot=axs[0, 0])\n",
    "axs[0, 0].set_title('QQ Plot for t-distribution')\n",
    "\n",
    "# QQ plot for normal distribution\n",
    "probplot(norm_dist, dist=\"norm\", plot=axs[0, 1])\n",
    "axs[0, 1].set_title('QQ Plot for Normal distribution')\n",
    "\n",
    "# QQ plot for left skewed distribution\n",
    "probplot(skew_left_dist, dist=\"norm\", plot=axs[1, 0])\n",
    "axs[1, 0].set_title('QQ Plot for Left Skewed distribution')\n",
    "\n",
    "# QQ plot for right skewed distribution\n",
    "probplot(skew_right_dist, dist=\"norm\", plot=axs[1, 1])\n",
    "axs[1, 1].set_title('QQ Plot for Right Skewed distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def qqplot(data1, data2, label1=\"data1\", label2=\"data2\", title=\"QQ Plot\"):\n",
    "    \"\"\"\n",
    "    Generates a QQ plot comparing two datasets.\n",
    "\n",
    "    Args:\n",
    "        data1 (list or np.array): The first dataset.\n",
    "        data2 (list or np.array): The second dataset.\n",
    "        label1 (str, optional): The label for the first dataset. Defaults to \"data1\".\n",
    "        label2 (str, optional): The label for the second dataset. Defaults to \"data2\".\n",
    "        title (str, optional): The title of the plot. Defaults to \"QQ Plot\".\n",
    "    \"\"\"\n",
    "\n",
    "    quantiles1 = np.quantile(data1, np.linspace(0, 1, 100))\n",
    "    quantiles2 = np.quantile(data2, np.linspace(0, 1, 100))\n",
    "\n",
    "    quantiles1.sort()\n",
    "    quantiles2.sort()\n",
    "\n",
    "    plt.plot(quantiles1, quantiles2, \"o\", markersize=5, label=label1)\n",
    "    plt.plot(quantiles1, quantiles1, \"-\", label=\"Reference\")\n",
    "    plt.xlabel(\"Quantiles of \" + label1)\n",
    "    plt.ylabel(\"Quantiles of \" + label2)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Simulate data with thin tails\n",
    "data1_thin = np.random.normal(loc=0, scale=1, size=1000)\n",
    "data2_thin = np.random.uniform(low=-1, high=1, size=1000)\n",
    "\n",
    "# Simulate data with thick tails\n",
    "data1_thick = np.random.power(2, size=1000)\n",
    "data2_thick = np.random.laplace(loc=0, scale=1 / np.sqrt(2), size=1000)\n",
    "\n",
    "# Generate QQ plots\n",
    "qqplot(data1_thin, data2_thin, label1=\"Thin-tailed data1\", label2=\"Thin-tailed data2\", title=\"QQ Plot of Thin-tailed Distributions\")\n",
    "qqplot(data1_thick, data2_thick, label1=\"Thick-tailed data1\", label2=\"Thick-tailed data2\", title=\"QQ Plot of Thick-tailed Distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The t-Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-distribution, also known as Student's t-distribution, is a probability distribution that is used in statistics. It is similar to the standard normal distribution (bell curve), but it has heavier tails, which means it is more spread out and has more probability in the tails of the distribution compared to the normal distribution.\n",
    "\n",
    "The t-distribution is commonly used in hypothesis testing and confidence interval estimation when the sample size is small and the population standard deviation is unknown. It arises from the fact that when we estimate the population standard deviation from a sample, there is additional uncertainty introduced into the calculations.\n",
    "\n",
    "The shape of the t-distribution depends on a parameter called the degrees of freedom (\\( \\nu \\)). The degrees of freedom represent the number of independent observations in a sample. As the degrees of freedom increase, the t-distribution approaches the standard normal distribution. When the degrees of freedom are small, the tails of the t-distribution are thicker, indicating greater uncertainty.\n",
    "\n",
    "The t-distribution is symmetrical and centered at zero, like the standard normal distribution, and its shape becomes more similar to the normal distribution as the degrees of freedom increase. It is often used in hypothesis testing, especially when dealing with small sample sizes or when the population standard deviation is unknown.\n",
    "\n",
    "The probability density function (PDF) of the t-distribution is given by:\n",
    "\n",
    "$$\n",
    "f(t) = \\frac{\\Gamma\\left(\\frac{\\nu + 1}{2}\\right)}{\\sqrt{\\pi \\nu} \\Gamma\\left(\\frac{\\nu}{2}\\right)} \\left(1 + \\frac{t^2}{\\nu}\\right)^{-\\frac{\\nu + 1}{2}}\n",
    "$$\n",
    "\n",
    "\n",
    "where:\n",
    "- $t$ is the random variable following the t-distribution.\n",
    "- $\\nu$ is the degrees of freedom.\n",
    "- $\\Gamma$ is the gamma function.\n",
    "\n",
    "The t-distribution is widely used in various statistical analyses, particularly in situations where assumptions about normality and sample size need to be carefully considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Walk Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setting parameters\n",
    "np.random.seed(0)\n",
    "num_periods = 1000\n",
    "mean_return = 0.0006\n",
    "std_dev = 0.02\n",
    "\n",
    "# Simulating random walk\n",
    "returns = np.random.normal(mean_return, std_dev, num_periods)\n",
    "prices = np.cumsum(returns)\n",
    "\n",
    "# Plotting random walk\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(prices, color='red')\n",
    "plt.title('Random Walk Simulation')\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Price')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_log_returns(num_days, mu, sigma):\n",
    "    np.random.seed(0)\n",
    "    return np.random.normal(mu, sigma, num_days)\n",
    "\n",
    "def simple_moving_average(data, window_size):\n",
    "    sma = np.convolve(data, np.ones(window_size), 'valid') / window_size\n",
    "    return sma\n",
    "\n",
    "# Parameters\n",
    "num_days = 100\n",
    "mu = 0.001  # mean of the log returns\n",
    "sigma = 0.02  # standard deviation of the log returns\n",
    "window_size = 10  # size of the moving average window\n",
    "\n",
    "# Generate log returns\n",
    "log_returns = generate_log_returns(num_days, mu, sigma)\n",
    "\n",
    "# Calculate Simple Moving Average\n",
    "sma = simple_moving_average(log_returns, window_size)\n",
    "\n",
    "print(\"Log Returns:\")\n",
    "print(log_returns)\n",
    "print(\"\\nSimple Moving Average with window size\", window_size, \":\")\n",
    "print(sma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(log_returns, label='Log Returns', color='blue')\n",
    "plt.plot(range(window_size - 1, num_days), sma, label=f'SMA ({window_size} days)', color='red', linestyle='--')\n",
    "plt.title('Log Returns and Simple Moving Average')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Log Returns / SMA')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convolve(input_array, kernel, mode='full'):\n",
    "    if mode not in ['full', 'valid', 'same']:\n",
    "        raise ValueError(\"Invalid mode. Mode must be one of 'full', 'valid', or 'same'.\")\n",
    "\n",
    "    input_shape = np.array(input_array.shape)\n",
    "    kernel_shape = np.array(kernel.shape)\n",
    "\n",
    "    if mode == 'full':\n",
    "        output_shape = input_shape + kernel_shape - 1\n",
    "        pad_width = [(kernel_shape[i] - 1, 0) for i in range(len(kernel_shape))]\n",
    "        padded_input = np.pad(input_array, pad_width, mode='constant')\n",
    "    elif mode == 'valid':\n",
    "        output_shape = np.maximum(input_shape - kernel_shape + 1, 0)\n",
    "        padded_input = input_array\n",
    "    elif mode == 'same':\n",
    "        output_shape = input_shape\n",
    "        pad_width = [(kernel_shape[i] - 1, kernel_shape[i] - 1) for i in range(len(kernel_shape))]\n",
    "        padded_input = np.pad(input_array, pad_width, mode='constant')\n",
    "\n",
    "    output_array = np.zeros(output_shape)\n",
    "\n",
    "    for i in range(output_shape[0]):\n",
    "        for j in range(output_shape[1]):\n",
    "            output_array[i, j] = np.sum(padded_input[i:i+kernel_shape[0], j:j+kernel_shape[1]] * kernel)\n",
    "\n",
    "    return output_array\n",
    "\n",
    "# Example usage:\n",
    "input_array = np.array([[1, 2, 3],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9]])\n",
    "\n",
    "kernel = np.array([[1, 0],\n",
    "                   [0, 1]])\n",
    "\n",
    "print(\"Input Array:\")\n",
    "print(input_array)\n",
    "\n",
    "print(\"\\nKernel:\")\n",
    "print(kernel)\n",
    "\n",
    "print(\"\\nConvolution (Full):\")\n",
    "print(convolve(input_array, kernel, mode='full'))\n",
    "\n",
    "print(\"\\nConvolution (Valid):\")\n",
    "print(convolve(input_array, kernel, mode='valid'))\n",
    "\n",
    "print(\"\\nConvolution (Same):\")\n",
    "print(convolve(input_array, kernel, mode='same'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentially-Weighted Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "num_periods = 100\n",
    "mu = 0.001  # average return\n",
    "sigma = 0.02  # volatility\n",
    "alpha = 0.1  # smoothing factor for EWMA\n",
    "\n",
    "# Generate random stock returns\n",
    "returns = np.random.normal(mu, sigma, num_periods)\n",
    "\n",
    "# Calculate cumulative returns (random walk)\n",
    "cumulative_returns = np.cumprod(1 + returns)  # Cumulative product of (1 + returns)\n",
    "\n",
    "# Apply Exponentially Weighted Moving Average (EWMA)\n",
    "ewma = np.zeros_like(cumulative_returns)\n",
    "ewma[0] = cumulative_returns[0]  # Initial value is the same as the first observation\n",
    "\n",
    "for t in range(1, len(cumulative_returns)):\n",
    "    ewma[t] = (1 - alpha) * ewma[t - 1] + alpha * cumulative_returns[t]\n",
    "\n",
    "# Plot the simulated returns and EWMA\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cumulative_returns, color='blue', label='Cumulative Returns')\n",
    "plt.plot(ewma, color='red', label='EWMA')\n",
    "plt.title('Simulated Stock Returns with EWMA')\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holt's Linear Trend Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import Holt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate time series data with trend\n",
    "n_obs = 100\n",
    "time = np.arange(n_obs)\n",
    "trend = 0.5 * time  # Simulated linear trend\n",
    "noise = np.random.normal(loc=0, scale=5, size=n_obs)  # Simulated noise\n",
    "data = trend + noise\n",
    "\n",
    "# Fit Holt's linear trend model\n",
    "model = Holt(data)\n",
    "fit = model.fit()\n",
    "\n",
    "# Forecast future values\n",
    "forecast_values = fit.forecast(steps=10)\n",
    "\n",
    "# Plot the original data, fitted trend, and forecast\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time, data, label='Original Data')\n",
    "plt.plot(time, fit.fittedvalues, color='orange', label='Fitted Trend')\n",
    "plt.plot(np.arange(n_obs, n_obs + 10), forecast_values, color='red', label='Forecast')\n",
    "plt.title(\"Holt's Linear Trend Model Simulation\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holt-Winters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Generate some sample data\n",
    "np.random.seed(0)\n",
    "index = pd.date_range(start='2023-01-01', end='2024-12-31', freq='D')\n",
    "data = np.random.normal(loc=100, scale=20, size=len(index))\n",
    "ts_data = pd.Series(data, index=index)\n",
    "\n",
    "# Perform Holt-Winters forecasting\n",
    "model = ExponentialSmoothing(ts_data, trend='add', seasonal='add', seasonal_periods=365)\n",
    "fit_model = model.fit()\n",
    "\n",
    "# Forecast for the next year\n",
    "forecast = fit_model.forecast(steps=365)\n",
    "\n",
    "# Plot the original data and forecast\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ts_data, label='Actual Data')\n",
    "plt.plot(fit_model.fittedvalues, label='Fitted Values', color='green')\n",
    "plt.plot(forecast, label='Forecast', color='red')\n",
    "plt.title('Holt-Winters Forecasting')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Generate or load your time series data\n",
    "# For example, you can load data from a CSV file or generate synthetic data\n",
    "\n",
    "# Assuming you have a pandas DataFrame with a 'date' index and a 'value' column\n",
    "# For demonstration purposes, let's create a synthetic time series\n",
    "date_range = pd.date_range(start='2020-01-01', end='2021-12-31', freq='D')\n",
    "values = np.random.randn(len(date_range)).cumsum()\n",
    "data = pd.DataFrame({'date': date_range, 'value': values})\n",
    "data.set_index('date', inplace=True)\n",
    "\n",
    "# Visualize the time series\n",
    "data['value'].plot(figsize=(12, 6))\n",
    "plt.title('Time Series Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "\n",
    "# Plot ACF and PACF to determine ARIMA parameters\n",
    "plot_acf(data['value'], lags=20)\n",
    "plt.title('Autocorrelation Function (ACF)')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.show()\n",
    "\n",
    "plot_pacf(data['value'], lags=20)\n",
    "plt.title('Partial Autocorrelation Function (PACF)')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Partial Autocorrelation')\n",
    "plt.show()\n",
    "\n",
    "# Fit ARIMA model\n",
    "# Determine the appropriate values for p, d, and q based on ACF and PACF plots\n",
    "p = 1  # AR order\n",
    "d = 1  # differencing\n",
    "q = 1  # MA order\n",
    "\n",
    "# Instantiate and fit the ARIMA model\n",
    "model = ARIMA(data['value'], order=(p, d, q))\n",
    "results = model.fit()\n",
    "\n",
    "# Summary of the model\n",
    "print(results.summary())\n",
    "\n",
    "# Plot residuals\n",
    "residuals = pd.Series(results.resid)\n",
    "residuals.plot(figsize=(12, 6))\n",
    "plt.title('Residuals of ARIMA Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Make predictions\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-12-31'\n",
    "forecast = results.predict(start=start_date, end=end_date, dynamic=True)\n",
    "\n",
    "# Visualize actual vs. predicted values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data['value'], label='Actual')\n",
    "plt.plot(forecast, color='red', label='Predicted')\n",
    "plt.title('Actual vs. Predicted Values')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
