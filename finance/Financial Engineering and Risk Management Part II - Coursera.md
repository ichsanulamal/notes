## 001.Mean Variance Overview and in Excel

### 001. Overview of Mean Variance

This module is the first of three modules, where we'll be walking through the main theoretical ideas behind mean variance portfolio selection. We'll first define what a portfolio is. We'll talk about what the return and risk of a portfolio is going to be. We're going to define what an efficient frontier is. We're going to define how an efficient frontier changes when there is a risk-free asset and how all of that leads up to the capital asset pricing market. The overview of what we're going to be talking about here is that we're going to define assets. We're going to define portfolios. We're going to define how to measure random returns in assets and portfolios. And for the mean-variance optimization as the name suggests, we're going to quantify the random asset and portfolio returns by their mean and variance. We're going to define something called mean-variance optimal portfolios or mean-variance efficient portfolios. We're going to define something called the efficient frontier, and the portfolios that lie on this efficient frontier and how does one compute them. Along the way We're also going to talk about Sharpe ratio and Sharpe optimal portfolios. We're going to define something called a market portfolio, and after defining the market portfolio, we'll get to something called the Capital Asset Pricing Model. These are the various modules that we're going to be walking through in this bigger topic of mean variance optimization. So what's the goal here? What I really want to do is I've got a certain amount of money and I want to split it among various assets that are available for investment. I'm going to caracterize and asset by its price. More often than not I'll be interested in returns on these assets I'm going to invest in them today, I'm going to sell them tomorrow and Whatever difference is the return that I make on it. And I would like to maximize this return in some appropriate sense. I'm going to define the random gross return on a particular asset to be simply the price one time step later. The time step could be a quarter, could be a year, could be six months. So it's p t plus 1 divided by p t. The net return is simply r t minus 1. It's going to be p t plus 1 minus p t divided by p t. I want to point out that both r t, and little r t are random quantities. These are random because the price at time t plus 1 is random. Price at time t, which is right now, is know, but the price at time t plus 1 is random, and therefore these returns are going to be random. I've got d different assets, and I want to split an amount, capital W, that I'm going to assume is strictly positive. This is the capital that I have, and I want to split it over the d assets that I have. W sub i will be the total dollar amount that I've invested in asset i. If w i is greater than 0, I'm going to say that that's a long investment. If w i is less than 0, it's going to be a short investment. For the purposes of modeling, we allow w to be both positive or negative. Our sub w will be The net rate of return or net return on the position w. By position I mean, the wealth and the various assets. So what is the definition? It's simply the total value of this 1 times detonator. Which is the gross returns of each of the assets times the amount of money which was put into those assets. Minus the initial values, which is sum of the w's divided by the initial value which is capital w. If you do the math, this 1 could be subtracted from ri. And you end up getting, this is going to be the net return. Little rit, wi, divided by the sum of the wi's. Rearrange them a little bit, and you end up getting that the net return on position w is the net return on each of the assets rit, which is a random quantity times wi divided by capital W. So what is important for the net return is not the absolute amount of wealth that is invested, but the relative amount, or the fraction of the total wealth that is invested in a particular asset. So instead of worrying about positions, we just have to consider a portfolio vector. So x is a portfolio vector. It could be positive or negative. Xi's represent the fraction invested in a particular asset. So some of the xi's must be equal to 1. One thing that I want to point out here is I, I've been talking about time t. In reality the return that you get, whether it's a gross return or the net return changes over time. The random properties change over time. The actual values that are realized change over time. But in this set of modules we are going to be looking at a very myopic investment strategy. I'm sitting at a particular time t. I only want to invest at time T plus one. When we get into more advance topics, we're going to talk about how to extend this idea into a multi-period optimization. People are interested in multi-period optimization because at the end of the day they want to save money for retirement, they want to save money for buying a house and so one, which is not a one period problem but a multi-period problem. A multi-period problem is not simply a concatination of one period problems because the space over which you can optimize becomes much larger when you look at multi-period problem. But in this set of modules we're going to be concerned only with one period of optimization, one quarter, one era, and so on. So how does one deal with randomness? The return on the portfolio R's of X is going to be defined as R I, X I. And notice over here I've dropped the R I, the time in the R I, because I'm focusing mainly on myopic optimization. This is a random return. Why is it random? Because the each of the returns, each of the net returns, R I's are going to be random. How does one quantify these returns? Should I simply look at the, maximize the expected value? Is that the right thing to do? Should one be worried about the spread around the mean? So the expected value or the mean value tells you what happens when you repeatedly invest. Most of us don't have the ability to repeatedly invest. If we go bankrupt, our investment is over. You don't have the ability to return from bankruptcy then you might have to worry about what happened to the spread around the mean. How does one quantify the spread around the mean is going to be a question that we'll have to deal with. The way we are going to do this in these set of modules is we're going to talk about the mean and we're going to quantify the spread around the mean by the variance. So the d, the values defining the asset returns are going to be the mean return which is the expected value of the net return, the variance of the asset return which is simply the variance of the random variables. Notice the mu I's and the sigma I's are assumed to be independent of time, again. Either the market itself is stationary or we are only interested in myopic investment therefore we don't have to worry about time. The covariance between the asset return is the covariance between a random return and a particular asset i and a asset j. Correlation again it's between two assets and there's a relationship between covariance and In correlation. Covariance is nothing but the correlation times the volatility of asset I and the volatility of asset d. All parameter are assumed to be constant over time. Now, I'm going to characterized the random return that I get on a portfolio by looking at the expected return on the portfolio. And the variance of the return on the portfolio. So the expected return on a portfolio x, Mu sub x, is going to be expected return on the net return of that portfolio r sub x, by using linearity of expectations. We end up getting that this is nothing but the expected return on each of the assets times the fraction invested in that asset, xi. So it's just mu i times xi, sum from I going from Y to D. The variance of the return again, just by the expression, it's the sum of R I time X I, the variance of this random variable. And if you expand it out it becomes the covariance of R I and R J times X I, X J. Here's just a simple example to try to work you through it. So I have 2 assets with normally distributed returns with mean mew and variance sigma squared. So R1 is one asset it has a mean 1, and it has a variance 0.1. R 2 is another asset, it has a mean 2, it has a variance 0.5. The correlation between these two assets is -0.25. If it translates this statement into those parameters, mu 1 is 1, mu 2 is 2, sigma 1 squared is 0.1, sigma 2 squared is 0.5. Sigma 1 2 is which is the covariance between r 1 and r 2. Is going to be the correlation whose number is right here, times Sigma 1, Sigma 2 you plug in the answers you end up getting it's .0559. In the 2 asset market, portfolios are very easy to define. Remember portfolios were the fractions invested. So if I invest fraction x in asset 1. And since the fraction invested in asset 1, and the fraction invested in asset 2 must add up to 1. I should invest 1 minus x in asset 2. Later on, we will see how we can use this x1 minus x to try to do efficient portfolio selection between these 2 assets. Plugging it then into the formula, the expected return on this portfolio is going to be sum of mu i xi 1 through d, 2 assets, the first asset has x, its expected return is 1 so it's 1 times x, the second asset has 1 minus x, its expected return is 2, so the total expected return that you get on this portfolio is x plus 2 times 1 minus x. What is the variance associated with the return of this portfolio? The formula is Sigma i j x i j, x i x j summed from i equals 1 through d, which can be equally written as sum of i going from 1 through d Sigma i squared, x i squared plus 2 times j greater than i Sigma i j x i x j, plugging it in, .1 which is a variance of the first asset times the investment in the first asset squared. .5, which is the variance of the second asset, times the investment in the second asset squared. Two times the variance, covariance between the two assets, which is just computed here, times the investment in the first asset and investment in the second asset. This exact thing can be generalized to multiple assets, and that is what we'll do in later modules. Okay, the first thing that we want to talk about is that diversification, or thinking about the spread around the means, is important because it reduces uncertainty. So let's consider a very contrived market. I have D different assets, all of them have the same expected return, mu, all of them have the same volatility, sigma. And the correlation between the assets is, is equal to 0. So each of the assets is basically identical, and now let's think about 2 different portfolios. In one portfolio, x, I invest everything in asset 1. In the other portfolio, I equally distribute my initial dollar over all the assets, so in every asset, I invest 1 over d. Both of these are portfolios. The expected return of the first, of the first portfolio which is x, is simply the expected return of asset one which is mu. The expected return on the other portfolio, y, which equally invests in all the assets, is going to be the average of the returns of all the assets, since each of them has the same return mu, the average is also going to be mu. So if we were just looking at the expected value, the two of these, these two portfolios cannot be differentiated. They both give me the same expected value. We should be as happy investing in X as we should be investing in Y. But if we are as we should be interested in reducing incertainty, perhaps these 2 portfolios are different. So if you look at the variance of the returns of the portfolios, what do you get? Sigma x squared Which is the radiance of portfolio x. We know that, that just invests in asset 1. So it's nothing but volatility squared, sigma squared. What happens to the variance of portfolio y? If you plug in the formula, every one of them has over d invested in it. So it's 1 over d squared, sigma squared. There are b terms. So ultimately you get that the variance associated portfolio wide sigma squared over d. Think about d of the order of 100. Okay, I'm interested in the s and p 500 index. So in the one case, I get volatility sigma square. In the other case my volatility has dropped down 100 fold. So just by diversifying between assets, identical assets, now I have been able to reduce my volatility a lot. The mean-variance portfolio selection problem, in the end, generalizes this idea. Here I'm taking a very simple. Problem All the assets have the same return. All the assets have the same variability, and I know that equal spreading is the best thing. Now what I want to do it sprea, move this idea to, to a case where the mean returns are not the same, variances are not the same, the covariance may not be equal to zero. How does one think about this problem? How does one compute efficient portfolios meaning portfolios that have A good mean invariance properties is going to be the main focus of these sets of modules. So, in 1954, Markowitz proposed a portfolio selection strategy. In his model, he suggested that the return. And the return has been put in quotes. I wanted to read this more as the benefit coming from a portfolio, to be the expected return of that portfolio. And risk associated with that portfolio to be the volatility of that portfolio. And what he suggested was that these are the 2 quantities that are going to be interesting to investors. They would want to increase their return and decrease their risk. So what I'm plotting over here are the returns on some random portfolios. In the, in the next module I'm going to show you a spreadsheet which shows you how these random returns were generated. I have, I have 8 different assets, the details of which will be in the spreadsheet. I've randomly generated positions on these 8 assets, figured out what the return is going to be, figured out what their volatility is going to be and then plotted a point. So all of these blue dots, Dots, are actually verious portfolios randomly generated. And the efficient frontier, this line over here, is genearted by the following procedure. We pick particular value of relativity, of risk, and try to compute the largest return that you can get on a portfolio. Here that has risk no larger than particular bound. So let's say sigma bar is the bound here. Figure out a portfolio. Compute a portfolio. And I'll show you the spreadsheet, how these portfolios are computed. Which has the largest return, with risk not exceeding sigma bar. And that point will be right here. And similarly, you take different values of these sigmas, compute out what is the maximum return that you are going to get, and this blue line is generated by computing the maximum return for a given value of risk. That frontier Is called the efficient frontier. Why is it a frontier? Because all portfolios, all feasible portfolios must lie below. This is all the part that is feasible. For any portfolio that you choose, its risk and its return values must be below the line. All of this space is unachievable. You cannot create a portfolio whose return and risk point lies in that region. Why is that? Just the way it's computed. I take the value of sigma, which is the risk, I compute the maximum possible return that I can get, and that's how I get this point. This return up here is not achievable. So everything above the frontier is not achievable. Everything below the frontier, below or equal to the frontier is achievable, but I would never want to be below the frontier. If I have a point over here, its risk is some quantity over here. Let's called it sigma 1. My frontier tells me that I can create another portfolio, a different portfolio from the one that generated that point, whose return is going to be right here. It's going to be on the frontier. So I would never want this portfolio. I only want portfolios that lie on the frontier. Above the frontier, unachievable Below the frontier inefficient. Right at the frontier is the place where I want to be. So the question that we will answer in the next few modules, is, how does one characterize this efficient frontier? How does one compute efficient. Or sometimes I'm going to call it optimal portfolios. Portfolios that lie on this efficient frontier. There are three different ways in which you can compute. The mean variance optimal frontier, that line that I showed you before, which tells you the maximum return for a particular value of risk. One way is to minimize risk for a target return. You can set the target return that you want. You want to make sure that the expected value on the portfolio has to be greater than or equal to R. And among all portfolios that satisfy that, you want to minimize the variance, or minimize the volatility, which is EQ1. If you expand this optimization problem, you can write it as sum of XI is equal to 1. So this is a portfolio constraint. And here you're saying that the expected return on that portfolio must be greater than equal to r. And this expression here just expands out whatever is written over there. And for those of you who are, mathematically sophisticated, this expression is nothing but the vector x transpose, a matrix of covariance times x. And what is this matrix? It's sigma 1 squared, sigma 1 2, sigma 1 3 and so on. Sigma 2 1, Sigma 2 squared and so on. So this is the variance-covariance matrix. And this expression there is simply x transposed variance-covariance matrix times x. An equivalent way to get the entire frontier is going to be to maximize return for a given value of risk, maximize mu of x such that sigma squared of x is below some target number sigma bar squared. If you write this in terms of the x i's it becomes some of the x i's must be equal to 1, again the portfolio constraint. X transpose sigma x, ir sigma ijxij summed must be less than or equal to sigma bar and you want to maximize the expected return. There is yet a third way of trying to get the entire frontier. And that is, to maximize a risk adjusted return. So maximize over portfolios, x. Mu of x, the expected return minus tau, which is for the risk aversion parameter, sigma X squared. So the risk aversion parameter is always greater than zero. You don't like risks, therefore you want to subtract from the extracted return a certain quantity that depends upon risk. If you again this expression, you get a sum of XI is equal, from XI must be equal to one, which is the portfolio constraint. This is just mu of x and that is sigma x squared and that's the tau there. What do I mean by saying all these three will generate the same frontier? There are parameters and there are three parameters in all of this, all of these formulations, r, sigma bar squared and tau. And as you Crank up these parameters for different values of these parameters you will write out the same curve.

### 002. Introduction to Mean Variance in Excel

In this module, I'm going to show you how to construct portfolios in Excel, how do you compute random portfolios, their returns, their volatilities and to plot the efficient frontier corresponding to the data in one of the worksheets. And what are we going to do is set up the optimization problem that we talked about in the theoretical modules and show you how you can compute the efficient frontiers, and the efficient portfolios on these frontiers using a solver optimization program. In this particular spreadsheet, I'm going to have eight different asset classes: US Bonds, International Bonds, US Large Cap Growth, US Large Cap Value, US Small Cap Growth, Small Cap Value, International Developed Equities and International Emerging Equities. And the mean returns for these different assets are 3.5, 1.75, -6.39 and so on. And these are all in percentages. This matrix down here is the variance-covariance matrix. So the variance of US Bond with itself is 0.001. So this quantity is the variance. The volatility of the bonds is defined as the square root of this quantity and the variance times 100. So it's 3.17%. The covariance between US Bonds and International Bond is 0.0013. The variance of International Bonds is 0.0073. Written in percentages, the volatility is 8.53%. So all I've done here is I've taken the diagonal quantity, took the square root of it and multiplied by 100. I'm going to use this spreadsheet to randomly generate portfolios and then try to find out what the returns and variances or returns and volatilities of that portfolios are going to be. And as we walk through this mean variance optimization module, I'm also going to tell you how to compute the efficient frontier, how do you compute efficient frontier when there is a risk free rate and so on. So here's just placeholders for the portfolios x1 through x8. And each of these portfolios' values are currently being generated from a random distribution. So this is randomly generated. And since x1 through x8 is a portfolio, all I've done is I've taken x8 and written that to be one minus the sum of x1 through x7. That just guarantees to me that this entire thing sums to one, and this quantity here is just a double check. It's summing all the components from x1 through x8, and it's indeed equal to one for the random value that has been generated here. What is the rate of return on this portfolio? It's simply the sum product of all the components here multiplied by the mean return over there. Mean returns are in percentages. The portfolios here are just in straight numbers, and therefore, the number that you end up getting here is actually rate of return in percentages. What about volatility? Volatility of the portfolio is simply 100 times the square root of the variance of the portfolio. How do you compute the variance of the portfolio? You have to take this. It's going to be Sigma_IJ, which is the covariance of asset I with asset J, times x_I times x_J, summed over IJ going from 1 through 8. Take the square root of that and multiply by 100. Now, a mathematically concise way of doing this, and we'll see this later on in the modules, is to take this vector X, take its transpose, multiply it to the covariance matrix and then left multiply with the same quantity. So if you look at this, what I'm doing is I'm taking this vector, I'm taking its transpose and multiplying it to the matrix which is the variance-covariance matrix. If I do that multiplication, I get a vector which is a column vector. I multiply it again by row vector. I get a number, which is the variance of the portfolio. I take its square root and multiply it by 100. And I end up getting the volatility. So that's how the volatility numbers are computed. So what I want to show you over here, all I'm doing in this particular case is randomly generating portfolios. So if I do have nine, a new portfolio comes up there. It has an associated return value, associated volatility value. Again, here's another sample, volatility return. I'm going to do it one more to hope to get a positive return note. There. We get a positive return of 13.67%, but the volatility associated with that is 41.23%. So these volatility numbers and the random returns was randomly generated by creating a portfolio, looking at what the random return is, looking at what the volatility is, and all I did was put them in increasing order and plotted these red dots here. Now, what I want to show you is how I computed this efficient frontier. The frontier which tells me what is the maximum possible return for a given value of volatility. In the module on mean variance analysis, we said that the frontier can be computed in three different ways: either by maximizing the return for a given value of volatility or risk, or minimizing volatility for a given value of return, or maximizing the risk adjusted return. In this particular case, our volatility numbers are given. And for each value of volatility that are randomly generated, I want to compute the maximum possible return. And I'm going to show you now in Excel how to compute that using solver. So we're going to go back to the data sheet. Here's the data sheet. And remember, I showed you that this cell here B22, this particular cell actually has the value of the mean return for a particular portfolio, randomly generated portfolios. Here is the volatility for the given portfolio. And what I want to do is make sure that this volatility number is less than sum budget that I'm going to specify in this orange cell. And I also want to make sure that the quantities that I choose for x1 through x8 is actually a portfolio, which means that if I sum them up, which is what is the numbers in this cell, it must equal one. So orange cells are data that I'm going to provide. This one here simply says that it's a portfolio. This 85.94 is a risk budget that has been given a particular random risk budget. So let's clear this for the moment, and let's try to compute what is going to happen. So I'm just going to clear the contents. Don't worry about this value here because it's zeros, it doesn't like it. And I'm going to show you how to set up an optimization problem to solve it. So here's solver. I'm going to set an objective. I want to maximize the cell B22, which is the net return in percentage. I want to maximize that quantity by changing the portfolio values. These are numbers B20 through I20, x1 through x8. And I want a constraint which says that the volatility number that I'm computing in cell B24 must be less than equal to the budget that I'm going to specify in cell D24, which is what this constraint down here is. The next constraint, J20 equal to L20, simply says that J20, which is the sum must equal one, which is the number that I'm going to specify over there. This is not the constraints. The values involved here are nonlinear. Remember, the volatility is a square divided by square root, and so I'm going to choose an optimization algorithm which is GRG nonlinear, solve and wait for the answer. So it's cranking numbers. It's going up. You say okay. You ended up getting that the maximum possible return that you could get for a risk budget of 85.94 is 58.25. And in order to receive this value, 58.25, this is the fraction that you need to invest, 5.02. You are to take a leverage of five times up there. Short International Bonds, shorts US Large Cap Value, short US Small Cap Value and so on for this particular set of data. So like I said, I don't want you to think that these are representative numbers. These are just some numbers taken from a paper. And if you look at this particular data set, the optimum return for that particular risk level, let me go back, 85.94. The randomly generated bond was -8.73. The best possible return is 58.25, which is exactly what we just computed. So next thing I want to show is that in many cases, you might want to just have long positions, not short positions and go to the solver. And here I'm going to just click 'make unconstrained variables non-negative.' For those of you who are watching this, I want you to pause this for a moment and think to yourself whether the number that I'm going to get, the maximum return that I'm going to get at this point is going to be larger than 58.25 or smaller. And the way I want you to think about is that the constraints, I'll put more constraints and what should that do to the maximum value. So let's solve it and see what you end up getting. So the maximum possible return that you can get if you decide to give yourself a budget of 85.94, and you say that the only thing that you can do is go long on all the assets, is you're going to go to the US Bonds and put all your money there. You're not allowed to short so you cannot increase the investment in US bonds, and you just take the return of that which is 3.15% and take the volatility which is 3.17%. So it's within the budget, but you were not able to use all the budget. So you can only use the budget if you're allowed to have short positions. Okay.

## 002.Efficient Frontier

### 003. Efficient Frontier

In this module, we are going to define the efficient frontier for a mean version portfolio selection problem. We are going to walk through how to compute the efficient frontier for a 2-asset market, and then for a general d-asset market. And the main punchline is that the d-asset market is no different from a 2-asset market. If you remember what we said was for a given level of risk, the efficient frontier gives you the maximum possible return. So, this is the efficient frontier, this, this particular point corresponds to the return of a portfolio, which is an efficient portfolio, or it's a frontier portfolio, all of these things are synonymous. It's a, it's a portfolio that for a given level of risk, gives you the maximum return, or another way to look at the same point is that for a given value of return, this portfolio gives you the minimum risk. So, any investor wanting to hold a certain amount of risk or wanting to hold a certain amount of return, will want to be on this efficient frontier. And in this module, we're going to walk you through the calculation of how this, this particular curve is computed. We're going to work with a very simple example first, just of two assets, two risky assets. And then, in the later part of the module, we'll show you that, that is the most general. In fact, if you have any number of assets, you will end up using only two mutual funds to construct the efficient frontier. So, here's my problem. I want to do mean-variance optimal portfolio selection for a 2-asset market. Asset 1 has mean return mu 1, it has variance sigma 1 squared. Asset 2 has mean return mu 2 and variance sigma 2 squared, and the correlation between the two assets is rho. What's nice about a 2-asset market is that the portfolio constraint is very simple to write. A portfolio, remember, was the fractions invested in the different assets. So, in a 2-asset market, there's only one unknown x. Suppose, x is the fraction that you invest in asset 1, then 1 minus x will be the amount you will invest in asset 2. And therefore, the return of this portfolio x1 minus x is going to be the mu 1 times x because that's the amount that you invest in asset 1, mu 2 times 1 minus x because that's the amount that you invest in asset 2. What is the variance of this portfolio? It's going to be sigma 1 squared times x squared, that's the variance coming from asset 1, sigma 2 squared times 1 minus x squared which is the variance coming from asset 2 plus 2 times rho sigma 1 sigma 2. And if you go back, this is nothing but the covariance sigma 1, 2 between the two assets, times x, the amount invested in asset 1, times 1 minus x, the amount invested in asset 2. It's very simple. It's one-dimensional in the sense that the only thing, only unknown is x. And that's why 2-asset markets are very easy to describe. So, I want to solve minimize risk formulation for the mean-variance portfolio selection problem. So, what I want to do is specify a target return. And then, find a portfolio that achieves the target return, but has the minimum risk corresponding to that target return. This is the return of the portfolio that's, this is mu of x. We wanted that to be greater than or equal to r. Here, we are saying that this is exactly equal to r. So, there's a difference between these two. We wanted it to be greater than or equal to r, and we are now wanting it to be equal to r. The reason we made it equal to r because it's now, it's very easy to compute. One equation, one unknown, I can solve for x. I can plug that x into the form, into the expression for the variance, and I'll get the efficient frontier. But this fact that I wanted equal to r will come and affect us in the final solution and we'll have to reinterpret what that means. So for now, let me erase all of these so that it becomes clear what we are trying to do. What we're saying is, among all those portfolios that give me a return exactly equal to r, find me one which has the minimum variance. For a 2-asset market, this becomes trivial because there's only one unknown x, and I can solve for it. So, there's only one portfolio that gives me the desired return r. And what's the value of x? It's simply r minus mu 2 divided by mu 1 minus mu 2. You simply solve this one-dimensional equation and you'll get the answer. So, I know the portfolio x that is going to give me the target return, I'm going to plug it into the equation for the variance. So, if x is r minus mu 2 times mu 2 minus mu 1, 1 minus x, which is the amount that you invest in asset 2, is going to be mu 1 minus r divided by mu 1 minus mu 2. You can just do the algebra and it'll turn out to be right. So, what I've done in this line, is that here I've just set x, so it's sigma 1 squared x squared. Here I, put in 1 minus x so it's sigma 2 squared 1 minus x squared. This is x, this is 1 minus x. If you plug in the answers, you'll exactly get this expression. If you expand it out, you'll end up getting that sigma r squared is ar squared plus br plus c. So, these are just numbers that depend on sigma 1, mu 1, and rho, and sigma 2, mu 2, and so on but these are numbers, r is the only unknown. So, what does this tell me? It tells me two things. If I know the target return r that I want to get to, the variance, the minimum variance corresponding to that target return is explicitly given by a formula. In fact, it's by, given by a parabola. So, what am I drawing here? I'm taking the value of r, and how was this computed? I plugged this value of r into that formula. I calculated out what sigma 1, sigma r squared is going to be, took a square root of that. That's going to be volatility. So, I'm plotting r in percentages here. I'm plotting volatility in percentages. And this is exactly for the same set of assets that I showed you on the spreadsheet. When we are down to this module, I'm going to go back and show you how to do the same computation on the spreadsheet. I compute out what sigma r is going to be, it's going to be this number and I'm going to plug this for all possible values of r. Notice on this slide, I'm plotting two different curves, one in blue, one is red. The red curve is not efficient. If you take a point here, this has a return of minus 2%. It has a volatility of, let's say, approximately 8%. We can get another portfolio with the same risk level, 8%, with much higher return. This particular portfolio up here has the same risk level, 8%, and has much higher return than this minus 2. So, this entire red curve, in fact, is not efficient and that is what we marked out, it says, it's inefficient. So, why did we end up getting it? We ended up getting it because when we set up the optimization problem, we insisted that the target return should be exactly equal to the return that I specify. If I had made it greater than or equal to, and you have specified a return minus 2, the optimization problem would have discover that for that particular target return, the best portfolio, best risk is this 8%, but for the same 8%, I can give you a much higher return and therefore this bottom line would never have appeared. The bottom line appeared only because of the equality constraints. It's sometimes convenient to put the equality constraints because we can solve the optimization problem simply, but later on, we'll have to come back and then argue that certain parts of the curve cannot be efficient. Alright. Now, I want to extend it to a d asset problem, and see how far can I push it. So, here's a mean-variance problem that I want to solve. Same thing, I want to minimize my variance, but now here's the expression for the variance. It's the covariance matrix sigma ij times xi and xj. I need to make sure that the x's that I consider is a portfolio, so the sum of the x's is equal to 1. And again, as before, instead of putting greater than or equal to r here, I am putting equal to r, for the same reason because I have equality constraints and I can solve this more efficiently. In the prerequisite modules for nonlinear optimization, we had introduced this idea of Lagrange multipliers. The problem with this optimization problem is that it has two constraints and I don't know how to deal with these constraints effectively. So, the easiest way to do it is to construct something called the Lagrangian and the way to construct the Lagrangian is to take the objective function. So, this box here is just the objective function, take the constraints. So, this particular constraint is the target return constraint except that the r, which is on the right-hand side, I said, is equal to minus r inside the bracket. This constraint is the constraint that says that the some of the x's should be equal to 1, that is, they must be a portfolio. And again, the 1 on the right-hand side, I moved it into the left-hand side with the minus 1 and then I multiply it by two multipliers, u and v, which I call the Lagrange multipliers. Now, having put the constraints into the objective by multiplying by the Lagrange multipliers, I'm going to completely ignore the constraints. I'm going to say that this is now an unconstrained problem. And we know that for the optimal solution of an unconstrained problem, we have to compute its gradient and set it equal to 0. Now, this particular objective function, assuming that u and v for the moment are just multipliers, they are not unknowns. The, the decision is in terms of these x's and there are b of different x's so I have to take the partial derivative of this expression with respect to all of them, and set it equal to 0. If you take the partial derivative with respect to i, you'll get two times sigma ij, xj, that's the derivative that's coming from this term. You'll get v times mu i, which is a term that is coming from here, and minus u, which is the term that's coming from there and then set it equal to 0. I'll have one equation for all i's going from 1 through d. So, I get d equations from here. I have two other equations from here. I need to make sure that my portfolio satisfies the target return. And I need to make sure that it satisfy, it's a portfolio. So, I have two equations here, I have d equations here, and how many unknowns do I have? I have actually d plus 2 unknowns. Why the 2 extra unknowns? The 2 Lagrange multipliers, u and v. So, here are the original set of unknowns, here are the new unknowns that I introduced, I have d plus 2 unknowns, d plus 2 equations I can solve. And in the next slide, I'll show you how to set up the linear equations to solve it. Here, I'm going to encapsulate this story into a theorem which says that a portfolio x is mean-variance optimum, if and only if its feasible, it satisfies the constraints, and there exists u and v. Multipliers u and v would satisfy these constraints star, which satisfy all of these gradient conditions. And this will become important in a few slides. Alright, so here, all I've done is I've taken these equations that are there, these d equations, and the extra two conditions on the portfolios, and set them up as one large matrix. So, up here, all of these equations are the gradient equations. This equation is the target return equation. This equation is the portfolio equation. So, there are d plus 2 equations here, d plus 2 unknowns. All these zeros corresponds to the gradient conditions that they must all be zero, this r is, of course, the target return, and this 1 is the fact that it's the portfolio 1. So, that's some vector b this is some, I'm just calling this matrix A and we, just simple Linear Algebra tells me that if I take all of these portfolios this vector, I can compute it by simply taking the inverse of A and multiplying it to this vector b. Done. In the rest of this module, what I want to do is give you a little bit more structure of what do these portfolios look like. Is there any interesting structural properties underneath, which we'll use later to derive something like the capital asset pricing model? So, we got to walk through a couple of slides, which will end up showing something called the two fund theorem. The two fund theorem says, that the entire efficient frontier can be generated by just looking at two portfolios or two mutual funds. So suppose we fix two different target returns, r1 and r2, and I go and solve for the optimum solution for r1. What do I mean by solving from the optimum solution? I go to this set of equations, plug in r1 over here and compute the optimum portfolio. That's port, optimum portfolio, I'm going to label it as x superscript 1. And when I solve for that portfolio and also compute out the corresponding Lagrange multipliers, v and u, I'm calling them in this light, v1 and u1. I take the other return r2, do the same thing. The optimum portfolio, I'm going to label it as x superscript 2 and the Lagrange multiplier as v2 and u2. Okay, now, we take any target return r that we want. I'm going to arbitrarily create for you another position y and argue to you that this position y, in fact, is the optimal solution for that new target return. And here's how it's going to be constructed. You take a target return and you choose a number beta, which is r minus r1 divided by r2 minus r1. And if you remember back, we, in the 2-asset market, the x was simply r minus mu 1 divided by mu 2 minus mu 1. So, this should somehow give you an idea that we are going back slowly to this 2-asset market, which is effectively what this two fund theorem says. I'm going to create a new position y. I don't know whether it's a portfolio for now. And the way I'm going to construct this y is I'm going to take 1 minus beta times x1, which I know, and beta times x2. I'm going to add them up. This will give me some positions in all the b assets. And let's walk through and see what, what happens. The first thing that I'm going to do is compute out the sum of all the components of y. Sum of this yi is nothing but 1 minus beta, the sum of the corresponding coefficients of x1. Beta times the corresponding coefficients of x2. X is a, x1 is a portfolio, x2 is a portfolio. So this sum is equal to 1, that sum is equal to 1. 1 minus beta times 1 plus beta times 1 if you add it up, you get 1. So, after this calculation, we know that this y, which was just a position right now, is now a portfolio. It's a set of numbers that adds up to one. Now, let's calculate out what is the expected return on this portfolio y. That's mu i times yi, expand it out again, it's 1 minus beta times mu i times x1 i. Sum from i equals 1 to d, beta times the sum of mu i times x2 i sum from 1 is to d. This one, remember, x1 is feasible for a target return, and so it's actually equal to r1. This quantity is feasible for a target return r2, so it's equal to r2. So, it's 1 minus beta times r1 plus beta times r2. Plug in the value of beta that it was computed, you get exactly equal to r. And if you connect back to the one-dimensional or the 2-asset case, this is exactly saying 1 minus x times mu 1 plus x times mu 2, must equal r, which is exactly the equation that we solved there. Now, we are going to argue in the next slide, that this y, in fact, is optimum. And how are we going to do that? I am going to use the theorem which says if I can find multipliers u and v for which the equations hold, then y must be optimal, because y is feasible, it is a portfolio, it has a right target return if I can find u multipliers such that all the gradient conditions hold, it must be the optimal portfolio. So, I know v1 and v2. So, I take a guess, and say that the v variable corresponding to this new position is just the same multiplication. 1 minus beta times v1, beta times v2. 1 minus beta times u1, beta times u2 is going to be u. Here's my sigma ijy, ij minus v mu i minus u. This is the gradient condition that corresponds to asset i. So, this is the partial derivative of the Lagrangian with respect to the asset i. I plug in the values for what y, this is nothing but a plug in for what yj is going to be. Here, I'm plugging in my guess value of v. Here, I'm plugging in my guess value of u. You rearrange them. Take all the 1 minus beta terms together. You end up getting something that just depends on the asset 1, the multipliers, v1 and u1. But x1 was optimum, therefore, all of this bracket must be equal to 0. Similarly, if you collect terms for beta, you'll get terms that correspond to x2. But x2 was optimum, so therefore, this must be equal to 0. 1 minus beta times 0 plus beta times 0, gives you zero. So, I have constructed for you multipliers, v and u, v and u, such that all the gradient conditions hold. Therefore, y must be optimal for the target return r. And we have this theorem which says, that all efficient port, portfolios, all the portfolios that are there on the efficient frontier can be constructed by diversifying between any two efficient portfolios with different expected returns. The only condition that we needed on x1 and x2 is that they have different returns. So, everybody, whoever is going to be investing in this market, they're happy if I just give them two mutual funds and say, okay, you just invest what you like on these two mutual funds. So, why are there so many mutual funds in the market? There are over 6,000 of them floating around. Why are they there? You might want to pause your video here for a second and think about it. So, the reason those different mutual funds are there is because we're assuming in the background here that all the investors have the same expected return, mu, and have the same covariance matrix sigma. What do I mean by they have? Meaning they estimate what is going to happen in the future by the same mean vector and the same covariance matrix. That's never going to be true. So, even if they are all mean-variance investors, they might have different estimates, which means that their efficient frontiers would look different, which means that a portfolio or a mutual fund which will be efficient for one investor may be completely inefficient for another investor. There's also no reason to believe that everybody is a mean-variance investor. This is another topic that we are going to talk about towards the very end of this module. And so, although this, this theorem is very interesting and important and, in fact, led to the development of the industry as a whole you should take it with a, a grain of salt that there is a gap between what theory is and what practice its going to be. Alright, returning back to the theory. The theorem says that all efficient portfolios being constructed by diversifying between two efficient portfolios which means effectively, it's a 2-asset market. If I'm talking about investors, they don't need more, anything more than two assets. And therefore, since y star can be written as a combination of x1 and x2, all I've done is rearranged terms. I took the r outside, I put x2 minus x1 divided by r2 minus r here. Call this a new position g, call this a new position h. So therefore, every component can be rewritten as r times gi plus hi. Plug it into the expression for variance and you'll end up getting again that the efficient frontier has a same structure as a 2-asset efficient frontier. And therefore, we'll just end this module by showing you that the efficient frontier looks the same. Again, the same story. This bottom is enef, inefficient. And the reason we had this because instead of putting target greater than or equal to r, we set target equal to r. And this, this equal to ends up giving this the inefficient frontier at the bottom and we'll stop.

## 003.Mean Variance with a Risk-free Asset and Risk-free Frontier in Excel

### 004. Mean Variance with a Risk-free Asset

In this module, we are going to walk you through how to construct the efficient frontier for a market with a risk free asset. We're going to see that we're going to define a new portfolio called a Sharp Optimal Portfolio. That's going to play a very important role in this module as well as in the next module on capital asset pricing module. So, we have a new asset. It pays a net return rf, with no risk. It's completely deterministic. And we're going to label this asset as x0. And again, I want to construct the efficient frontier. But this time, I'm going to use a different formulation of the mean-variance optimal portfolio selection problem to construct the efficient frontier. If you go back two modules, we had set up three different ways of doing efficient frontiers. One was by maximizing the return for a given value of risk, another was to minimize the risk for a given value of return. And a third one was to maximize a risk-adjusted return. And that's the formulation that I'm going to use. So here's my return, r f times x0 is the return on the zero asset, which is the risk-free asset, and this is stuff that we have seen before. Mu i times xi sum from i equal to 1 through d is the return on the risk-free asset. This here, is the variance of my return. And the thing that I want you to focus on the fact is that here the indexes go form i equals 1 to d. So, i equals 0 is absent. And why is this absent? Because i equal to 0 corresponds to the asset that gives me a deterministic return, it doesn't have a variance. Down here is a risk aversion parameter. And we also know that the entire frontier can be computed by just taking different values of tau. As you go from tau, tau must be greater than equal to zero. It cannot take negative values. But as you crank up the tau, from tao equal to zero to tau equal to infinity, the entire efficient frontier is going to be computed. What's down here? Just a portfolio constraint. Now I have d plus 1 assets. And therefore, the fractions invested in this d plus 1 asset must be equal to 1. So x0 plus, so I can solve for one of these using that. And it is what I'm going to do in the next calculation. One thing to keep in mind is that this entire mean variance calculation is meaningful only for target returns r that are greater than equal to rf. Again, I would like you pause here and convince yourself that you will never want to consider a return less than rf. Alright. So now, we have this equation that relates x0 to the other x's. So, I'm just solving for it. I'm substituting x0 equal 1 minus the sum of the x's and plugging it back into this equation. The nice thing is that this equation does not involve x0 at all so it remains the same. The other ones do involve x0. So, what I've done is that this one gets multiplied by rf, so that's that one over there. These minus xi's also get multiplied by rf so they are sitting over there. So it's mu i minus rf times xi. So, one thing that immediately falls out of this calculation without looking further into what happens to the efficient frontier and so forth is that the relevant quantity. When you have a risk-free asset in the market, the relevant return that you're interested in is the excess return on the asset. So mu hat i, which will play a role later on, is mu i minus rf. It's the excess return on asset i. It's the returning excess of the risk-free rate and that is what going to determine what the portfolio is going to be. We have an expression, now let's just optimize it. This time we are lucky because this expression that we have here has no constraints, no constraints on x. Why? Because there was only one constraint which was a portfolio constraint and we used that constraint to set the value of x0. So, we just take the derivative with respect to all the xi's and set it equal to 0. If you take the derivative of the first term, you'll get mu hat i. If you take the derivative from the second term, you'll get minus 2 tau, sum of j going from 1 through d sigma ij times xj, and that must be equal to 0. So, d equations, d unknowns, I can solve. What I've done is rearrange this equation in a matrix form. I said 2 tau times this matrix V, x, this is a vector of x must be equal to mu hat. You invert it, and you end up getting that for a given value of risk aversion tau. So, the only thing that I'm trying to emphasize here is that x is a function of the risk aversion parameter. So, you give me the risk aversion parameter, and I will compute out what is going to happen to the portfolio. So, it's going to be 1 over 2 tau V inverse mu hat. So, what is the family of frontier portfolios? Remember, I said that all the frontier can be generated by changing the value of tau. So, the family of portfolios that sit on the frontier are simply x'd out. But this x'd out was only the risky part of the portfolio. So, what is the amount that was invested in the risk-free part of the portfolio? It's just 1 minus the sum of all the components. So, this is essentially x0 tau, the amount that you invested the risk-free asset, x tau is exactly that. And this is called the risky part of the portfolio, the risky portfolio. And as you crank up your tau for all values of tau going greater than or equal to zero, you'll get a family of portfolios. All of these portfolios are going to sit on the efficient frontier. That's great, but again, we're going to do an exercise very similar to the two frontier. I want to understand the structure of this frontier better. So, let's focus just on the risky asset in the frontier portfolio. X is 1 over 2 tau v inverse mu hat. This is just a risky position, therefore it does not add up to one. So, the first thing that I'm going to try to do is construct another portfolio, meaning that components add up to 1 from this position which doesn't add up to 1. And the easiest way to do it is to take a position x, because if they don't add up to 1, and divide it by the sum of the components. And call a new position s star. But now, if you look at the sum of s star i, i going from 1 through d, that is nothing going to be the sum of i going from 1 through d of xi divided by sum of i going from 1 to d of xi. They will cancel and you will end up getting the sum of this components of this vector s star is equal to 1. So, s star in fact, is a portfolio. So, what's special about this portfolio is if you plug in the value of x for any value of the risk of urgent parameter tou. So, x is 1 over 2 tau, we inverse mu hat. In the denominator, I'm adding it up by the same, same position, so you get 1 over 2 tau here. So, the 2 tau's cancel. Which means that if I look at the risky positions that an investor is holding for any value of the risk aversion parameter, tau, and construct a corresponding portfolio, meaning normalize it, so that its components add up to one, I get the same portfolio as star. It doesn't depend on tau. Which means that I can look at the efficient portfolios are reparametrize them, think of them differently. Essentially, what everybody is doing is taking a certain amount of their dollar x0 and putting it into a risk-free asset and the remaining about 1 minus x0 is the amount that they are investing in s star. Everybody in, investing in the same portfolio s star. So, the family of frontier portfolio now is very simple. Put the money into the risk-free, take the rest of the dollars and put it in, invest it into s star. So, we end up getting this theorem which says that all efficient portfolios in the market with a risk-free asset can be constructed by diversifying between the risk less asset and the single mutual fund, s star. And in the next few slides, we're going to try to give you more structure as to what is this portfolio, s star. Before we get there, let's just construct the risk, the efficient frontier in a market with the risk-free asset. Everybody invest in s star. Let mu s star be the expected return on this portfolio and sigma s star denote the volatility of the portfolio. And the return on the generic portfolio is going to be x0 times the risk-free rate plus one minus x0 times the return on this portfolio s star. And the volatility will simply be 1 minus x0 times sigma s star. Why? Because a risk-free asset does not have any volatility associated with it. So, let's take two points. The point down here, which has no risk, zero volatility, and will give you a return rf. Zero volatility will correspond to x0 equal to 1. 1 minus x0 is equal to 0. And therefore mu of x, that portfolio will have a return rf. Take another point over here, which corresponds to the portfolio s star. That corresponds to volatility s star, which means x0 is equal to 0. And mu x therefore turns out to be just mu s star. Now, if you look at this curve as I changed my x0, it will trace a straight line. And therefore the efficient frontier will simply be a straight line that goes from the point that corresponds to the risk-free asset, goes to the point that corresponds to this special portfolio, s star, and it's a straight line. And because if you can get a return rf with no risk, you will always want to demand a higher return than rf if you are asked to take a risky position. So, that's going to be the efficient frontier. Now, what we want to ask is how does this efficient frontier relate to the frontier with only risky assets? And is there and economic interpretation for this very special portfolio s star? So, here's what's going to happen. Here's the, the green line here is the efficient frontier with the risk-free asset in place. It's that straight line that we talked about. I know that the point sigma s star mu s star belongs to that efficient frontier. Now, rf0, this is the point that corresponds to a risk-free asset, also belongs to it and that's a straight line. And this blue line denotes whatever is the frontier that corresponds to just a risky asset. So, my claim is that s star must be an efficient portfolio, efficient risky portfolio. Meaning that it must lie on that. Suppose it's not. This is the counter-factual. That maybe s star is actually here. Here, we know that the efficient frontier for a market with the risk-free asset must go to s star. So, the efficient frontier will look something like that. But that cannot be the efficient frontier. Why not? Because all of these points lie within the efficient frontier, for just the risky assets. So I can, if you give me a point over here, which has a particular amount of risk, I can give you a better return. So, holding this point here cannot be efficient. And therefore, whatever that s star is, it cannot be at a point such that the straight line that goes through s star. Enters the region which is feasible but not efficient. And yet, s star is a portfolio of just a risky asset, and therefore it must be somewhere in the region that is feasible. It cannot be in sight. It cannot be on the boundary such that the line goes through it. Therefore, the only thing it can do is that the line must be tangent. And that's exactly the picture that's drawn here. So, let me just clean up the story here. For the moment, I'm going to clean up my drawings so that you can go back to seeing what the picture is. So now, I know that this s star, whatever it is, must lie, must be such that it's tangent to the efficient frontier, right? Everything that's in the efficient frontier, everything that's down here, can be computed by diversifying between risky assets. So no, now I want to understand what is go, how this s star is going to be computed. So, let's look at this angle, theta. My claim is that s star is a portfolio that maximizes this angle or equivalently maximizes the tangent of that angle. Let's write out what the expression for the tangent of that angle is. Take any, any point, any feasible portfolio here for the moment. So, just do fixed ideas. Let's say here's a particular point that corresponds to a particular portfolio, it's volatility is sigma x and it's return is mu x. So, what is the corresponding angle there? Let's call this angle sum theta of x. The tangent of that I take the y-value. Y-value is just mu x minus rf, which is what is written over here. This expression is noting but mu x minus rf. What is the x-value? Which is nothing but sigma x. So, the angle that is cast over here by any portfolio which has volatility sigma x and return mu x, the tangent of that angle is simply the excess return of that portfolio divided by the variance or the volatility of that portfolio. This particular s star portfolio is the one that maximizes this angle. So, it maximizes the ratio of the expected excess return to volatility. This has a name. The Sharpe Ratio of a portfolio or an asset is the ratio of the expected excess return to its volatility. The Sharpe optimal portfolio is a portfolio that maximizes the Sharpe ratio. The portfolio s star is just argued maximizes the tangent of that angle. The tangent of the angle is the Sharpe ratio. Therefore, s star is a Sharpe optimal portfolio. Everybody in a market which a risk-free asset diversifies between the risk-free asset and the Sharpe optimal portfolio. The name Sharpe comes from the fact that this was, that this portfolio was identified by Bill Sharpe, who got a Nobel Prize together with Markowitz and Lintner. Alright, the last bit. Now, the investment in the very risky assets are in fixed proportions. All the investors in a mean-variance market are diversifying between the riskless asset and this particular Sharpe optimal portfolio. And therefore, the demand for the different assets will be perfect synchrony to each other. And which means that if the demands are proportional, then the price and the returns should be correlated. This should be just a one-dimensional quantity that should just tell me what the returns on all the asset in the market is going to be. Why? Because everybody holds the same portfolio. This inside will lead to the capital asset pricing model in the next module.

### 005. Risk-free Frontier in Excel

In this module, I'm going to show you how to compute an efficient frontier with a risk-free asset in Excel. And then using the solutions from this optimization problem, I'm going to show you how to construct a sharp optimum portfolio. And from the sharp optimum portfolio, I'm going to show you how to compute the capital asset pricing model, and the security market line that. That goes with the capital asset pricing model. We're going to work mainly with two worksheets. One of them is labeled Risk Free Frontier; this is where we're going to do the calculation for the Risk Free Frontier. And the other one is labeled Sharpe Portfolio; this is where we're going to do a calculation for the soft, Sharpe Optimal Portfolio and. This security market line. We're going to work with the same 8 asset classes that we had introduced in the previous Excel module. Here are the expected returns on these eight risky asset classes. Here are the variance, covariance elements for the eight risky assets. I've also listed the volatility but we won't be directly using it. Now In my portfolio there actually nine positions. The eight risky positions from before and another position x zero. Which is the position that I'm going to be holding in the risk free asset. Now all of these nine positions should add up to be equal to one Which is what is there in this gray cell. This simply adds up the 9 positions from B21 through J21. The orange cell here is a constrained cell that we're going to be using. When we set up the solver for optimizing for the efficient portfolio. The misc free rate that I'm going to be using in this problem is 1.5 %. I'm going to be using the risk adjusted return formulation for constructing in the efficient frontier and in that formulation I need the risker version parameter which is, given over here, that's 0.1. This cell just gives you the return on the portfolio. It you click on that cell, you will see just some product of the risky positions times their expected return plus the risk free rate times the position that I'm holding in the risk-free asset. The expression for validity is the same from before. I take the risky positions and multiply that by the variance, covariance take the square root multiply that by 100 in order to represent the volatility in percentages. This orange cell now lists the objective that I'm trying to maximize this is going to be the expected return on my entire portfolio that is including both the risk free part and the risky part. And I'm going to subtract from it the risk free aversion parameter tau times the variance, which is only associated with the risk free part. If you click on that one, you will notice you will get its B27, which is the return on the portfolio minus tau, which is the risk aversion parameter times probability squared. And this is what I want to maximize, with the constraint that the position that I hold in both the risk-free and the risky asset should add up to one. That is it must be a portfolio. So now let's go to solver. If you go to solver, here's the optimization problem that has been set up. The objective is the orange cell B31. I'm going to maximize that by changing the position that I am holding, subject to the constraint that T21, which is the sum of the positions, must equal M21, which is just. Set to be equal to one. You solve this, and you end up getting that the optimum position is what is listed over here right now. I put 32% of my initial dollar in the risk-free asset, and the remaining. 68 percent is the dollar amount that I'm going to be spending in the risky assets. So in the module, in the theoretical module we said that no matter what tau is the only thing that the investors are going to do is select a certain amount to put in the risk free asset. Take the remaining amount and put it into one particular portfolio that I was calling the sharp optimal portfolio. So in this work sheet I'm going to numerically show you that this is indeed what happens. So in the rows b 34 through 39, what I have done Is I've taken the risky positions. So here, the green cell here, is simply a repeat of the risky positions. It's B21 all the way up through I21. This is, this is the position that's there in the last risky asset. I'm taking the sum of those positions, so here's just some of the whiskey positions and remember the codes the total saying risk[UNKNOWN] must add up to one I know that I put 32 cents of my initial dollars into the risk three assets and therefore 68 cents what must be sitting in the risky asset is exactly what this number is. I'm going to take these risky positions going to normalize them by the sum to get a portfolio. And this is the sharpe optimal portfolio. I'm going to run this optimization again to convince you that no matter what tau is the optimal portfolio, the sharp optimal portfolio that I end up getting from the calculations exactly the same portfolio. So lets do that and then I'll go forward and show what happens with the sharpe ratio and so on. Okay, so I'm going to change the tao perameter to something larger. So let's say we may get to .2. So in the risk inversion parameter tao goes up. I don't like risk and therefor I'll Tend to put more money into the risk-free asset. So this 0.32 should go up. But the portfolio that, of the risky asset that I'm going to hold should remain the same. The only thing that should change is the amount of dollars that I put into the risky asset versus the risk free asset. So let's do this optimization. We'll call solver again. Click on solve. It crank up and now it gives you an answer. So instead of 32%, now we are putting 66% of your initial dollar into the risk free asset because your risk aversion parameter went up. 34% is the amount that you're going to put in the risky assets. The risky asset positions have changed. But once you normalize it by the sum of the position of the risky asset, you again get back the same portfolio. These numbers have not changed. So here I'm numerically verifying for you what I theoretically told you, that all that people are going to do in a market where there is free asset, is to diversify between the risk free asset and the Sharpe Optimal Portfolio. Now let's just do some calculations on the Sharpe Optimal. Portfolio. Here I'm listing the excess return on the sharpe optimal portfolio. I simply take the positions in the sharpe optimal portfolio multiplying them by the expected return on the various aspects and subtracting from their, form that sum the risk free rate. Here is the volatility, same expression as before. And the ratio of the excess return to volitility is the sharp ratio. So the sharp ratio for this market turns out to be .76. So the point of this particular worksheet was to show you how to construct the optimazation problem for a market with a risk, Risk free asset. Argue to you numerically, that the Sharp optimal portfolio always remains the same regardless of what Tau is. In the next worksheet I'm going to repeat some of these calculations. And then show you how to compute a security market. See is again the same story. I have the assets and now I'm ignoring completely all the calculations that we had done and shown you, going to show you a direct way of getting to the sharpe optimal portfolio. Here's the risk free rate, here now are the excess return. Mu hats as I'm going to call them in my, text modules which is as simply take the expected return and subtract the risk free rate. So that's what I'm doing over here. In order the calculate the Sharpe optimal portfolio, I know that the position that I'm going to hold are going to be V inverse mu_hat. So the quantity over here is just in-, v inverse mu_hat, that's the calculation that is being done here. If you click on this, it's going to be the inverse of this matrix times mu_hat that will give you the answer. So that's the positions, still not a portfolio. I take the sum of those positions. And I end up getting 1364.93. I divide out by this sum to get a portfolio. And the portfolio that you end up getting, exactly the same one that we saw in the risk-free frontier version. Mean excess return volatility is the optimum Sharpe ratio to be 0.76. Now what I've done here is computed the betas. What is the BETA? Beta is the correlation between the asset, and the shop optimal portfolio. If you work through the calculations, what it's going to be doing is taking the corresponding, the rule of the variance, co-variance matrix, or equal. Equivalently the column of the variance co-variance matrix corresponding to that particular asset and multiplying it to the sharpe optimal portfolio. So if you look at this cell what has been done is its taken the column, I take the sharpe optimal portfolio, multiply them together that'll give me the co-variance between the particular asset and the sharpe optimal portfolio. Divided by the volatility of the shop optimal portfolio, that gives you the beta. Now why am I doing this with respect to the shop optimal portfolio whereas in the notes I'm going, I was telling you that the beta is defined in terms of the market portfolio? This is because I've already argued to you in the theoretical part of the module that the shop optimal portfolio is in fact the market portfolio. And therefore in the theoretical calculation that we want to do in this sheet. I might, might as well replace the Sharp optimal portfolio for the market portfolio, that's what I've done. I've computed the beta by looking at the covariance. Of the particular asset and the shop optimal portfolio divided by the volatility of the shop optimal portfolio. These are the not, these are the different betas, some of them are positvely correlated, some of them are negatively correlated. Here is a positive correlation. Positive and all of these are negatively correlated to the market. What do I do in the next line? I look at the implied return, how do I look at the in-flight attorney nine use the security market line's. You click on any one of them. If you look at the excess return must be equal to the excess return of the sharp optical portfolio or equal to the market portfolio times the beta of the assets so the implied returns should simply be B33 which is the beta times the excess return in the market or equally in this particular case the excess returned shopped optimal portfolio. I'm going to compare that with the excess return that I'd previously computed So it's 1.65. If you look at this error this is going to be what is the applied return, minus the excess return. And that's what I'm putting in this cell down below. And it turns out that for this particular market, all these numbers turn out to be zero. For those of you who have been carefully looking at my numbers that I plotted in the text module you'll see that for asset one and asset seven it doesn't follow the line exactly but here you're getting all the values to be equal to zero.the difference between these two is thoughtful I showed you in the notes were based off of Matlab in math lab has a higher precision than Excel It actually brings up an interesting question. If the precision of the program that you're using to compute numbers can make a difference between whether a particular asset is efficient or inefficient. That's a very non-robust or fragile way of thinking about mean variance portfolio selection. It tells you that mean variance portfolio selection, in some way when you implement it, you have to be very careful. You have to make sure that numerical errors don't play a role, you have to make sure that the statistical estimation errors don't play a role. And that's something that we're going to come to in the modules that refer to the practical Details of mean variance portfolio selection. There's one thing else that I w-, I want to mark out here before we leave this excel module. If you look at the sharp optimal portfolios, some of them are positive components, 1.25 0.12, 0.2, 0.04. But then they have negative components. Minus .11, minus .05, minus .1 and so on. Now, I have argued to you if the markets are in equilibrium, if everybody's a mean variance optimizer, then everybody holds a sharp optimal portfolio and therefore the market portfolio is a Sharpe Optimum portfolio. Now if everybody constructs their portfolio using the sharp optimal portfolio then everybody is going to short in this particular case international bonds and say US small cab growth. If everybody shorts these 2 assets the market can never be in equilibrium. So here is an example of data. Which gives you a Sharpe Optimum portfolio that cannot market in equilibrium and if this data is representative of the market you could easily argue that one of the basic assumptions besides capital asset pricing model which is that the market should be in equilibrium is violated..

## 004.Capital Asset Pricing Model

### 006. Capital Asset Pricing Model

In this module, we're going to bring together all the results that we have generated from mean variance portfolio selection from market with a risk-free asset. And use that to define a model that constructs prices for assets. And this model is going to be called a Capital Asset Pricing Model. So, in order to connect the Sharp optimal portfolio. There's something that's happening in the market. Let's define a new portfolio. And the portfolio that I'm going to define is something called a market portfolio. The market portfolio is defined as the portfolio where you take the Ci. And then you normalize it by the sum of all the capitalization. So, the i-th component of the market portfolio is simply Ci divided by the sum of all the Cj's, so these all add up to 1. In fact, they are all greater than equal to 00 as well. Let mu m denote the expected net return on the market portfolio. It's simply mu I times XMI summed, of I going from 1 to D. And let sigma M denote the volatility of the market portfolio, as before it's this quadratic function, take the square root. Now let's connect up how this market portfolio relates to what investors are doing. Suppose all investors in the market had mean variance optimizers. And all of them will invest in the Sharp optimal portfolio as starred. Let w super k denote the wealth of the k-th investor. Let x0 k denote the fraction of the wealth that the k-th investor puts into the risk free asset. Then the total capitalization of the i-th risky asset is simply going to be the wk, the wealth of the k-th Investor 1 minus x0 k. This is the fraction that is going into the risky assets. Times s star i, why s star i? Because I'm looking at the capitalization over of just the i at asset. And what are the summation k over? This is over all investors. The thing that I want to do focus on, is the fact that this, this summation here, over all investors, doesn't depend on the s star. So, if I write it differently. I can simply take that s star i, and pull it out of the bracket. So, this s star i, I can pull it out of the bracket and just write it over there. What does that mean? That means that if I do this calculation to compute the market portfolio, I will get that the market portfolio is nothing but the Sharpe optimal portfolio. This should not be a surprise. Everybody's investing in the same Sharpe optimal portfolio, and therefore the capitalization should be completely related to the Sharpe optimal portfolio. If I re-normalize the capitalization to get the portfolio, I should get back the Sharpe optimal popular portfolio. This is great, why is this important? This is important because the sharpe optimal portfolio depends upon expended returns, depends on covariances. These are quantities that are hard to compute. On the other hand xm is a market portfolio. They're relatively easier to computer. I can go and calculate out the values of the various capitalization. And it'll give me a portfolio that will have, will have some insight about the efficient frontiers. Okay, now we want to go further and see what that means. So, capital market line is another name for the efficient frontier. Now what we're going to do is remember in the last module we showed that the efficient frontier was a line that goes from the risk free asset through the shop optimal portfolio and all the way through. Now, it's a line that goes form the risk free asset through the market portfolio and all the way through. This efficient frontier is going to be the excess return on the market portfolio, divided by the volatility of the market portfolio. Previously, we had computed this slope as the excess return on the sharp optimum portfolio, divided by the volatility of the sharp optimum portfolio. It's also the maximum achievable shopping operation. This quantity is also frequently called the price of risk. Everything that is efficient, must lie on this line. And if you take on a certain amount of risk, this capital market line tells you what is the, that you must demand. It can be used to compared projects. Here's a simple example, suppose the price of a share of an oil pipeline venture is $875 right now. It's expected to yield $1000 in one year, but the volatility is 40%. It's very high volatility. The current interest rate is 5%, the expected return, rate of return or the net return on the market portfolio is going to be mu M equal to 17%. The volatility of the market portfolio sigma M equals 12%. The question is, is this oil pipeline worth considering? Should one invest in it? Another way of asking the same question is, is this oil pipeline venture on the efficient frontier? Because if it's not, I should not be interested in it. So what's the return that I get, what is the net return that I get on this oil pipeline venture? It's 1000 divided by 875 minus 1, it's approximately 14%, what is the return that I should demand for taking on the volatility? Sigma is the volatility of this oil venture, this is the slope of the capital market line. The capital market line starts off from the point RF. Just to remind you, it's a straight line, starts from the point RF and has a slope M. So if I look at some point sigma, I should demand this return, which I'm labeling as R bar in order for it to be efficient. Plug in the numbers. Rf is given. R, r, this shouldn't be on rm. But mu m, mu m is given. Sigma n is given. If you plug in all of this, then in order to take on the risk of 40%. You should be compensated at a rate of return or a net rate of return of 45%, which is way higher than the 14% that the oil venture is giving. Therefore, the oil venture is not efficient and should not be considered. Now what we want to do is take this idea that the market portfolio is there and try to inffer asset returns from the market returns. So the way we going to do it is think about the fact that every asset is in fact a portfolio. If you look at the j at asset, it's a portfolio. It just corresponds to investing the one dollar in the j at asset, and nothing everywhere else. For now let's consider, the set of portfolios that I could generate by diversifying between the j at asset. Okay, and the market portfolio. So I put an amount gamma into the j at asset and amount one minus gamma into the market portfolio. The return on this portfolio is going to be mu gamma, is an expression that gives you gamma here, is the volatility of the portfolio, gamma squared. This is the, this is the volatility that's coming from asset j, this is from the market. This is of course volatility that's coming from the market and the portfolio. So what have I plotted on this first? I plotted the green line, which is the efficient frontier with the risky asset. The blue line, which is the efficient frontier, frontier with only risky asset. And then this dotted black line is the efficient frontier. It's the frontier that is generated by diversifying between the J asset and the market portfolio. So this dotted line must lie below the efficient frontier of just a risky asset because the market portfolio is just a risky asset, the j at asset is just a risky asset, so everything that's going to be here is going to be below that. But now what happens? Notice that for gamma equal to 0, this, the dot, the red dot belongs to the efficient frontier corresponding to this black line, because gamma equal to 0 gives you the market portfolio. The market portfolio is an efficient front, an efficient portfolio. It also lies on the efficient frontier of a market with a risk-free asset. So all of these three curves are tangent at the same point. I know the slope of the green line. That I, also know that the same slope must be equal to the slope of the blue line must also be equal to the slope of this dotted black line and I am going to use that to compute what the returns are going to be. The firmer the market, the capital market line is clearly noted; just mu r divided by r j divided by sigma. Now we want to compute the slope of the frontier generated by the asset j in the market portfolio sigma M. So that's the slope of this, this black dotted line that I want to compute. So D mu over D sigma. But I don't know how to directly compute it, so I take, take this chain rule and write it as d mu gamma divided by D gamma, D sigma gamma divided by B gamma. Why do I put this mu gamma and sigma gamma here because these are functions of gamma. The D gammas cancel, I get back the same thing, but this is something I can compute. This expression is exactly equal to this. This denominator is a much more complicated expression, and this is the expression that you end up getting. You're not going to be responsible for computing out what that expression is. This is only for the derivation that I want here. If you compute all these expressions and substitute gamma equal to zero, which is the point that responds to the market portfolio. You'll get an expression that this ratio is just mu J minus mu N, divided by sigma JM minus, sigma M squared over sigma M. If you equate the slope, this slope that you get, to that slope, you end up getting and rearrange the results. You end up getting that the excess return on the j at asset, this is nothing but mu hat j. Must be equal to the excess return on the market, mu hat m. And they are related by a quantity which is the covariance. This is the covariance of the return on the j at asset, with the return on the market divided by the median of the return of the market. And that is called a beta of asset j and this full pricing formula is called the Capital Asset Pricing Model. Towards the end of the last module, I said that returns in this market should be determined by just one return because there's only one portfolio everybody is investing. And this theorem says exactly that return on any asset, the excess return on any asset is determined by just an excess return on the market portfolio. This one thing determines everything. Now let's connect this story, because there's a beta floating around. It seems like it should be connected to linear regression. So let's connect it to linear regression and see what we end up getting. So suppose we take the random excess return. So Rj here will denote the random excess return on asset g, not the expected return and regress it on the excess market return, which is Rm minus Rf. Here's the regression formula. On the left hand side is the even variable that I'm trying to regress. On the right hand side is the variable r minus r f on which I'm trying to regress it. Alpha is the intercept, beta is the coefficient, and this is the residual noise. The coefficient beta is exactly the beta that we computed sigma i m square divided by sigma m squared. The in, intercept alpha j, there's an expression for it. It's simply going to be the expected return on the asset to get expectation on this side, to get expectation on that side, subtract it, whatever you get, that's going to be the alpha, because the expectation on the residual noise is zero. So mu j minus rf minus beta mu m minus rf. Residual sigma epsilon j and r m minus r f are uncorrelated. The correlation between them is 0, so all of this is just regression theory. I've not added any financial economics or financial engineering there. Now I'm going to add it in. I know that capital asset pricing model is true. What does that mean? That means that this difference is exactly equal to 0, which means that the alpha j on every asset is equal to zero. And the effective relations here that I end up getting is at the random return on asset j, excess return on random J is beta times the random excess on the market plus epsilon j. So now let's look at the variance. The variance of this quantity is nothing but the variance of just the f of j because Rf is a constant. Epsilon j and the excess return are uncorrelated, so therefore you end up getting beta squared, variance of rm minus Rf, which is nothing but the variance of the market, plus the variance of the residual. Now let's, for a moment, compare this expression. So here's the expression for risk. The expression for return says mu hat j, which expected return on asset j must be beta times new hat m. You are taking two components of risk here. The total risk to your portfolio has two components, has one component which correlates with the market because of the beta And that's called, market risk. The rest, the leftover risk, is called residual risk. And if you look at what return that you're getting for that amount of risk it just depends on the market risk, just the beta part. The residual part you don't get compensated for it. What does that tell you? It tell you that this residual risk should somehow be diversifiable by looking at a, a properly diversified asset we should be able to get rid of this. Because if we couldn't get rid of it and we had to take on this risk. The market should have compensated us, for, for taking on this risk. But the market does not, which means that this residual risk is diversifiable. The market risk is not, here's another way of looking at what CAPM tells you. We did that in the capital asset pricing model, via the capital market line. Here's another way of looking at the inside accounts from the capital asset pricing model. This is called a security market. This says that if I plot the historical returns of an asset, with respect to this other quantity. I should get a straight line, why? Because we just said that mu j, must be equal to rf plus the beta of that particular asset, times mu m minus rf. So this shouldn't be rm, but mu m and therefore we expect to get a straight line. And if you dig the 8 asset classes that were there in the spreadsheet that was given to you and [unknown] out the quantity over here. And in a separate module, I'm going to show you how to compute this line using the data in the spreadsheet. You'll end up getting that this is exactly, that those assets fall pretty much under straight line. The line there's one asset that falls below. What does this insight tell you? You might want to pose the video here for a moment to try to understand what is, what is the information over here? The story is, all of these assets are going to be on the straight line, because they are all efficient. The 7th asset, and, to some extent, the 1st asset, is inefficient. And therefore, it falls below the security market line. You only want to hold those assets that fall on the line, or sometimes above the line. So why the discrepancy? Because mean, cap m and mean variance is not always true. So the security market line can be used to identify inefficient assets, and assets that might be mispriced. The assumption that are underlying CAPM are all investors have identical information. Not true, all investors are mean variant optimizers or at least their returns are normal. Not true, the markets are in equilibrium. Again, not true, all of these assumptions are not true, and therefore you don't expect that all the asset should fall in the security market line. Many of them will, but some might lie below, some might lie above. And so, how does one leverage deviations from the security market line? There are two ways of looking at it. One way is to compute the Alpha for particular asset. Remember We said a few slides before that if CAPM is true, the alpha is equal to 0. If alpha is positive, it means that, that asset is, has been mispriced low. And therefore, we should buy it. Because we expect to get higher than expected returns from that asset. Alpha is negative means that mis, asset that as it has been mispriced high, and we must short sell it. Because later on the return will catch up and will make a difference. So alpha, alpha positive will correspond to this space. Alpha negative will correspond to this space. So alpha positive here alpha negative here, we don't like the asset down here we need to short them. The asset over here we like them we have to hold them long. Another way of getting to the same concept of alpha is to look at the sharp ratio of a stock. We remember a few slides before we have said that the market portfolio gives you the highest Sharpe ratio and therefore the securities market line corresponds to the highest slope. Now, if the assumptions behind CAPM are not true the there might be instances, short periods of time where things are not in equilibrium for example where some asset might be mispriced and may actually have a higher sharpe ratio In the market. Those assets we want to hold long. Those assets with sharp ratios below, we want to short. The final slide here I want to show you how to use CAPM as a pricing formula. Suppose there is payoff from an investment in one year, is some random quantity x. And I want to compute what the fair price of this investment is, then there net return from this investment is simply x over p. The beta of x is the covariance of rx with rm and sigma m squared. If you plug in the expression, you will get, there is a covariance of the pay of x with rm divided by the variance of the market times 1 over p. So this p is actually unknown, we are trying to compute out what the price is going to be. Supposed CAPM holds, then mu x, which is the expected return must lie on the security market, that line. So mu X must be equal to RF, plus beta of that payoff X, RF minus RF. I plug in the formula. I have one unknown P. I have one equation. I solve for it by rearranging terms, I end up getting that P must be equal to the expected value of the payoff, discounted back, which kind of makes sense. This is what you would have said, even if you didn't know CAPM, take the expected value of the payoff, discount it one period before, one year before, at the risk free rate. Plus another term which correlates with returns on the market. And this again, this shouldn't be Rm but Mu M. It's going to be the expected return on the market. But the thing that I want you to focus on is the fact that the price goes up, when the correlation, of the payoff is negative with the, with respect to the market return. Which means that if the payoff is such, that, it pays on, in, in situations where the market is low. Then the price that somebody can demand for that payoff turns out to be high. Does that make sense? You might want to pause and think for a moment. So in situations where the market return gives you a very high return, there's very low demand for this particular asset. If it's positively correlated with the market, the asset will not have a very high demand because I could simply invest in the market portfolio and then do not take on any of the residual risks. So it's efficient for me to just put my money into the market portfolio. On the other hand, if there is a particular asset that gives me returns in situations where the market gives me low returns, which means that the payoff from partic-, this particular asset is negatively correlated with the market, then I might want to hold that asset, which means that the demand for that asset is going to be high, which means that the price that the seller could demand is going to be higher. And that explains why negative correlation with the market results in a higher price for that particular asset stop here.

## 005.Implementation Difficulties

### 007. Implementation Difficulties with Mean Variance

In this module, we're going to walk through and identify some im, implementation difficulties with mean-variance portfolio selection. We're going to walk through 3 main ideas, one, what happens when there are parameter address. Two, what happens when you have to take negative positions and you want to avoid short positions. And three, what happens when variance is not really the best measure for risk. There are many aspects of the implementation details of mean-variance that one could focus on. We chose to focus on the three most important ones. First, has to do with parameter estimation. The parameters that go into a mean-variance portfolio selection problem in practical situations is never known. The true mean vector and the true covariance matrix of the assets is unknown. All we have is historical data, and we will have to estimate these parameters using these historical returns. And as a consequence, we end up making statistical errors. For the mean vector, the data is often sufficient, but when you start estimating the covariance matrix, the data is never sufficient. The reason is, that this covariance matrix has ordered d squared independent parameters. In order to have sufficient data to estimate these d squared parameters, you have to collect returns over a very long period, and over this long period, the market parameters shift. So, you sort of are playing a game where you can never able to get enough data to estimate these parameters sufficiently. Moreover, the portfolio that you compute to allow to be very sensitive to estimation errors and we'll focus on this in one of the modules. We're going to show you why this happens, how you could correct for it, and what are the current state of the art on taking estimates and constructing portfolios from them. They're also going to focus on how does one get negative exposures in the Excel module, that goes with the mean-variance theoretical module which showed you that very often, the optimal portfolio has short positions. Taking on short positions is very dangerous particularly because it has an unlimited downside. You can lose a lot of money because the price could suddenly jump very high and you end up losing a lot of money on the short positions and it's for this reason that it's not very often allowed for wealth managers. One way to get negative exposure is to use a leverage exchange traded fund, or a leveraged ETF. But if you use leveraged ETFs, you have to be very careful. And in one of the modules, we're going to focus on how do ETFs work, what are the difficulties associated with ETFs, how should you interpret the returns of ETFs? Finally, we're going to talk about whether variance itself is a good measure for risk. Mean-variance portfolio selection focuses on variance as a risk measure or equivalently volatility as the risk measure. Does it make sense to use this risk measure? What, what are the limitations of variance? What can you do to mitigate some of these limitations is going to be the focus of another module. In this module, we will mainly focus on the issues associated with parameter estimation. And the starting point of this module is that the true parameters that we are after, which is the mean vector and the covariance matrix of the assets is never known. And we are going to use historical returns to compute estimates for mean var, mean return, and the covariance matrix. And the easiest way to do that is to estimate the mean return by the sample average of the returns over some period N. Once you have the sample average for the mean, you can compute the covariance matrix by just substituting instead of the true mean, the estimated mean, to get an estimate for what the variance is. What I've done on this plot that goes on this slide is I simulated the returns using the mean vector and the covariance matrix given in the spreadsheet that goes with these modules, I simulated 60 months of data. And using those 60 months of data, I estimated the mean. Each of these green dots on this plot are an estimated value of the mean using one particular simulation of 60 months worth of data. I'm only plotting the estimated mean for asset 1 and asset 2. The point that I want you to focus on is that the estimated mean can often be very far away from the true mean. The true mean has been plotted on this plot with a red square. Here's where the true mean is. This is a valid estimated mean generated from 60 months of data. And as you can notice, it's very, very far away from what the true mean is going to be. What we do know is that if I estimate the mean and I construct the 95% confidence interval around it, so here is one particular value of the estimated mean, here is the 95% confidence interval around it. And because we are talking about two assets, this interval becomes an ellipse. It's a 95% confidence ellipse. Then, with probability 0.95, the true mean lies in the ellipse. So, in this particular case, the true mean barely makes itself into the 95% ellipse. So, the question you should ask yourself is, does parameter error matter? And in this slide, I want to tell you that parameter error is often very serious for mean-variance portfolio selection. And what I'm describing on this is the same experiment that I described in the last slide, taken one step further. I estimated the mean and the covariance matrix using 60 months of data. So, I take one sample from all those green dots that I showed you in that slide. I have a mean vector. I have a covariance matrix. So, I can construct an efficient frontier using that data. I'm going to call that the estimated frontier. So, the green line here on this slide, this one, is the estimated frontier. It's the frontier that has been computed using an estimate for the mean and estimate for the covariance matrix. The blue line is the true frontier. This is the frontier corresponding to the unknown true mean and the unknown true covariance matrix. The red line is, is labelled the realized frontier. What that means is I take a frontier portfolio, on the green estimated frontier, compute the true mean return on that portfolio and the true volatility of the portfolio and plot it. And the line that I get from doing that is the red line. So, this diamond here actually gets moved to this diamond when you replace the estimated mean with the true mean and the estimated covariance matrix with the true covariance matrix. And as you can notice, there is a big gap between what the estimated return on that portfolio is going to be and what the true return on that portfolio is. The estimated return is around 6.4%, and the true return, or the realized return if you were to use that portfolio in the market, would be close to 4.4%, a good 2% drop. Why does this happen? Is this generic or did it happen just for one of the samples? In this slide, I'm plotting the estimated frontiers corresponding to 5 different simulation runs. I simulated 60 months of data 5 different times, computed the estimated mean, the estimated covariance matrix and I've plotted the corresponding estimated frontier. The green lines on this plot are five different estimated frontiers and as you can see, these frontiers are extremely unstable. Not only are the frontiers unstable, the difference between the frontiers and the estimated frontiers and the realized frontiers can also be very large. So, we want to understand why this happens. Why is there such a big gap between what happens in the estimated frontier and what is actually realized? Why is the estimated frontier so unstable and is there anything that we can do to remove this gap and remove this instability? Why is parameter error so serious? In order to understand this, let's walk through a very simple example. Suppose I have two identical assets with mean mu and covariance sigma squared and correlation equal to 0, then the optimal investment for these 2 assets would be to take half a position in asset 1 and a half a position in asset 2. That's what would give you the least volatility. Suppose now that the estimate for these returns are slightly off their true values. So, I estimate the return on asset 1 to be slightly larger than the true value so it's mu plus epsilon. I estimate the mean return on asset to be slightly smaller than the true value, mu minus epsilon. So, on average, I'm making zero error. On average, the estimator is very good. So, if you were thinking about the properties of a statistical estimator, you would say that whatever the estimator is been used here, is pretty good. Across the assets, you're not making a lot of error. But the problem with mean-variance portfolio selection is that after I estimate these parameters, I'm going to optimize my portfolio using these parameters. So, what happens? I've estimated that the return on asset 1 is slightly larger than the return on asset 2. And therefore, I will overweight asset 1 as compared to asset 2. If I'm allowed short positions, then I'm going to short asset 2 and actually start investing more, take more leverage on asset 1. But this is precisely the wrong thing to do. If I take the portfolio that I compute which overweights asset 1 and underweights asset 2 and put it into the market, I would get a return where the overweighted asset is going to perform worse than expected, the realized return is going to be mu, below mu plus epsilon. And the undeweighted asset, which is asset 2, will perform better than expected. So, instead of having a return mu minus epsilon, this asset, asset 2, is going to have a return mu, which is an espilon larger than the expected return which is mu minus espilon. And this performance, this gap between the estimated performance and the realized performance will become worse as more and more shorting is allowed. This is what accounts for the big difference between the estimated performance and the realized performance. The main difficulty is, we take the estimated parameters and then optimize. And this optimization procedure inflates or maximizes the statistical errors in the parameters. There is a quote which sort of sums up the situation. Mean-variance results in error maximizing investment irrelevant portfolios. So, we have to do something in order to make mean-variance portfolio selection practical. So, one idea that might come out of looking at this slide is that the performance becomes worse as we allow more leverage. So perhaps, the idea would be to limit short positions, not allow short positions at all. And then, let's see what happens to the performance. In this slide, I'm plotting what happens to the estimated frontier, which is the green line, and the realized frontier, which is the red line, when you have a no-short sales constraint. And as you can see, that the realized frontier becomes very unstable this has a large part of the curve down here which is actually inefficient. And the reason behind this is because the feasible region for the portfolios now has a corner. So, if this is x1, that is x2, you want x1, x2 to be grater than equal to 0, so you end up getting a corner in the feasible region and this corner causes problems in portfolio selection, it causes instabilities in portfolio selections. As you add more constrains, maybe you have some asset sector constraints, maybe you have some constraints on how much money a particular sector can have and so on. All of these become linear constraints. All of these induce more corners and more instabilities. If you want to get at what the no-short sales constraints was doing, which is to limit leverage, the better thing to do is directly put a constrain on leverage. And if you put a constraint on leverage, you end up getting performance shown up in this curve. Now, the realized performance of the portfolio is pretty close to the expected performance. The gap between these two is small. But the gap between what is expected and what is realized, this gap is still very large. So, I expect to perform on the green line based on the data. I get the real, realized performance is going to be the red line. Remember, this blue line is actually not known in practice so even though the true performance and the realized performance are very close, I have no way of knowing how well I'm performing. So, leverage constraints do work well in practice but still, the estimated frontier is very bad and so there's needs to be some work in trying to bring that down. The state of the art right now is something called robust portfolio selection. In the robust portfolio selection, what one does is removes the target constraint, which is imposed with respect to the estimated value of the mean and replaces it by a target return constraint which is with respect to the worst possible mean in the confidence region. So, let Sm denote the confidence region for the mean. A few slides back, I showed you that the confidence region is an ellipse. So, instead of using a target return constraints, which says to take the estimated value of the mu transpose x and in, insist that, that should be greater than equal to r, we'll going to replace it by these constraints. And what do these constraints say? It says, you choose your portfolio x, the return that you're going to get is going to be the worst possible return in the confidence region. Any point in the confidence region is possible and, therefore, this worst return is something that you could possibly see in the market. And now, instead of that constraint on the target return, I'm going to put a constraint that this minimum value must be greater or equal to r. I can do portfolio selection with this constraint. It's a little bit harder but not much harder. And now, the picture I end up getting looks like the plot here. The estimated frontier starts coming down. Why does this happen? This happens because now, I'm putting the worst case. So, I have estimated value of mu, this could be the estimated portfolio performance. But because now I have put the worst case constraint, this gets dragged down. The realized performance also becomes bigger than expected. So, that starts getting pulled up and therefore, the gap between these two starts to become very small. There are issues with this technology. You can sometimes get portfolios which are not very interpretable and therefore it's having a little difficulty getting fraction. But over time technology either directly or some version of this technology is likely to become very practical. All of these methods were focused on trying to improve the optimization strategy. There is a flip side to this methodology, where one tries to improve the estimation strategy. So, here's, are some methods that people have used to improve parameter estimate. One of the most popular methods are so-called the shrinkage methods. And what one does in these shrinkage methods is that one shrinks to some global quantity. These were introduced by Charles Stein in 1961. There's a paper by James and Stein, and more recently, Ledoit and Wolf have extended this to the case of covariance matrices in other circumstances. So, let's take the case of the mean. Earlier, I would have estimated each of the asset means separately. So, mu est i stands for the estimated mean for asset i. Now, in the shrinkage technology, instead of just estimating this asset mean, I'm also going to estimate a global mean, global average mean on the assets. And there is a reason why I put this estimation outside this bracket. And the reason for that is when I estimate this quantity, I don't simply take the estimate for all of the d assets and add them up. I assume that all the assets have the same expected mean and use the data of all the assets to estimate that mean. As a result, I have more data when I'm estimating the total mean, than when I'm estimating a given assets mean. As a result, I expect that the error in this global mean is smaller. So, error is smaller. And the error is larger in individual means. Now, this shrunk estimate, what it does is it takes the estimate for a particular asset, estimate for the global one, let's just call it mu bar and it moves on this line, some element alpha. When alpha is equal to 1, it's up here. When alpha is equal to 0, it's down here. For some intermediate value of alpha between 0 and 1, it's some point over here. This one has a very small error. That one has a bigger error. And when you shrink, you end up getting that the error at this point would be smaller. The tradeoff is as you, as you decrease alpha and start coming closer to the global mean, you have less information about what the asset is going to do, but you have less statistical error. As you increase alpha, you have more information about the asset is going to do, but you have more estimation error. So, somewhere in between is the best thing. The next expression is a same kind of idea applied to the covariance matrix. So here, there shouldn't be estimated, but shrunk. This should be estimated down here. So, we have a shrunk estimate for the covariance. All it does is takes the estimated value for the covariance matrix and shrinks it towards another covariance matrix where all the assets have the same volatility or the same variance. Again, the idea is the same but if I want to compute one variance for all the assets, I have a lot more data, I can estimate it better, and if I shrink the estimated covariance matrix towards this global covariance matrix, I end up getting a better estimate, meaning an estimate with lower errors. Another way to improve parameter estimates is to use subjective views and the most popular way of doing that is the so-called Black-Litterman method. Recently, people have been starting to use non-parametric nearest neighbor like methods to estimate performance and this is because people have started going away from parametric models like mean-variance and going towards more data driven models. And the idea here is to observe the current return here r, go back into the past and find all those times t where the return is close to the current return. So, this is the current return, this is the return at some point t in the past. You want to make sure that it's pretty close to the current return. And for all those times t, find out what happened to time t plus 1 and use that as sample of what is going to happen in the future. These non-parametric methods are currently at a very theoretical level, but there is a possibility that these methods will provide a better way of doing portfolio selection in the future.

## 006.Negative Exposures, Leveraged ETFs, and Beyond Variance

### 008. Negative Exposures and Leveraged ETFs

In this module we're going to talk about how to get negative exposures in the context of mean variance portfolio selection. And in doing so, we'll introduce the idea of exchange traded funds and leveraged exchange traded funds. Short positions can often result in very high returns. But short positions are very risky. A long position has a limited downside. The lowest price an asset can take is 0 and therefore the largest amount of money that one is exposed to lose is the amount invested. Short positions, on the other side, have unlimited downsides. Short positions are created by selling assets borrowed from a broker and these have to be repurchased and returned to the broker at a later date. Since the price of an asset can become arbitrarily large, the potential loss from a short position can also be arbitrarily large. So we need a product that has negative exposure, meaning it gives me, it behaves almost as if it was a short position, but has limited liability, limited downside. One such product is something called an exchange traded fund. Exchange traded funds are products that track the returns on stock indices, bond indices, commodities, currencies, etc cetera. This table is something that I took from bloomberg.com and which gives you some idea of ETF's that are tracking various indices in the world. So SPDR S&P 500 tracks the S&P 500 index. Ishares Russell 2000 is another one which tracks the FTSE. The QQQ, Japan, and so on. You can have exchange traded funds on any number of different things. Commodities, currencies, and so on. If you go to Bloomberg and look for ETFs, you will see lots of different ETFs. So these ETFs that are shown on this particular slide track the daily return on the underlying index. So the daily return on the S, spiral, S&P 500 would be the tracking the daily return on the SMP500 index. Etfs also allow you to leverage the returns indices. Leveraged ETFs produce daily returns that are multiple of the daily returns on the index. Bull ETFs will return beta times the daily return on the index and beta could have values 2 and 3 and so on. So po, pro ultra share as in P500 is a bull, ETF on the under, underlying index which is acid P500. Pro SHORT is another ETF which is a leveraged ETF, but it turns a negative number times the daily return. So an inverse EDF returns minus beta times the daily return and beta can then take values 1, 2, 3, and so on. An inverse EDF is a product that can a negative exposure to the index ...with a limited liability. And why is the liability limited? It's because you tend, you're only exposed to the amount that you bought. You bought a 100 dollars worth of an inverse ETF, you can only lose a 100 dollars and yet at the same time get a negative exposure. But one has to be very careful when one uses leveraged ETFs in constructing a portfolio. In the next few slides, I'll go over what kind of risks are associated with leveraged ETF's? Before we get down to explaining, the source of the trouble with leveraged ETF's lets understand what happens, to the returns on an ETF. And return on an ETF is the return on the underlying index compounded daily. So on a long ETF, it's simply a, the return, the cumulative return or the gross return on an ETF will be a product of each of the daily returns, just like a stock. The return on a leveraged ETF will be the daily return multiplied by beta. So if you have a beta ETF and beta can take values plus 2 and 3 or minus 1, minus 2, minus 3, The way you compute the gross return is you take beta times the daily return on the underlying index, that gives you the daily return. On the ETF, you multiply it all the way through and you end up getting the gross return over TPS. The return itself is actually constructed by investing in the derivatives which are on the index rather than buying the stock s in the index. This daily compounding has consequences that are not immediately obvious. On the next slide, I'm going to work through and explain to you, how, depending upon whether the ETF is simply a long ETF. Where it a leverage EDF often have an intuition about daily returns can go wrong. So, here's a simple example. Suppose you have an index. The index value today, let's time t is equal to 0 is 100. At time t equal to 1, let's say day 1, t equal to 1. It goes up to 105, and at time t equal to 2 which is day 2, it comes back to 100. So if you look at what happened over this period, nothing changed. You went up or, and then came down. So it really there was no level shift. The only thing that you experienced over this period is volatility. It went up and down. So if you had bought the index you would have bought the index at 100. The value would have gone up to 105 and then come down. If you had bought a long ETF what would have happened? Suppose the current value of the ETF or the index or Is 100. Then on day 1, the price of the index would have been 100 times 1 plus R 1, which is 105. Perfectly tracking what is going to happen, so it should be 100 here, it would have gone up to 105 and what happens on day 2? The ETF will go down by 105, which is the current price times the return on day 2 and you will drop back to 100. So, so far when you're looking at what happens to just a plain vanilla long EDF and the index they're tracking. Now, let's see what happens to a bull ETF. A bull ETF let's say in this particular case we take beta to be equal to 2. Twice bull 8 ETF. The current price of the index is 100. Over the 1st day the index returned 5%, so the bull ETF will go up 10%. So it now, on Day 1 it's value will be 110. It would have been increased by 10% instead of 5%. On Day 2, the index went down 4.76%, so R2 was minus 4.76% and therefore, the, the amount by which it's going to go down, this should be 110. The price, the ETF will go down by 110 times 1 plus 2R2. So this time it's going to drop down and the net value that you'll end up getting here is 99.52. So we'll, you will not come back 100, you will go below it. So the bull ETF, over the 2 day period, actually lost money. Now, if you look at the mechanics, it's not the case that bull ETF is returning something that they did not promise. But if you were to interpret as if a bull ETF was holding a twice leveraged position, then if the index went up from 100 to 105 and came back to 100, you expect to come back again. And that intuition is wrong, you end up losing money because in every day you're compounding by twice. So if you make money and next time you lose double, you end up losing much more than what you made over the first. Now let's see what happens to a inverse ETF. So in an inverse ETF, you start form 100. On the first day, you end up making money on the index. So the r one was 5%. And therefore, the inverse ETF will lose money, so it'll come down to 95, by the same percentage but now it's come down. On day 2, the return is minus 4.76 %, and therefore the inverse ETF is going to make money, it's going to be 95 times 1 minus R 2. You'll end up getting to 99.52. Again, you have lost money. You started from 100, you ended up to only 99.52. Moreover, the two times ETF and the negative ETF both ended up at the same position. Intuitively, we would have expected something which is twice the ETF. And something which is negative ETF should not end up at a different position. One of them making money, the other one losing money and so on. But here we end up getting to the same position. The index did not lose money. The long ETF did not lose money. But the leveraged ETF as well as the inverse ETF Ended up losing money. All of this happens because the daily compounding leads to some unintuitive results. All the computations that I've shown on the slide are correct in according to the rules of what the EDF returns are, but they do not conform to the intuition that we have for these products. In this slide, we are going to work through the mathematical expression for the return of a leverage ETF. The gross return on the static leverage position in the underlying index is simply going to be beta times s capital T minus beta minus 1 as 0 times 1 plus rt, so this entire expression. It's coming because we have to borrow beta minus as zero amount of money and time 0 and the funding rate is R so this is the amount of money that I have to return at time capital T. So, that's the amount that I have to remove from what I would gain from selling my positions in the underlying text. Therefore, the return that I end up getting is approximately beta times. St over SC. Now, that should think of almost as a simple interest rate analog. So when I invest in a beta leveraged ETF, I know that the returns that I'm going to get on this ETF is going to be compounded daily. So I expect to see some sort of a compounding effect. So it will be S1 over S0. So I should expect a term like S1 over S0 to be the power of beta. S2 over S1 to the power beta and so on. And therefore all of these terms should cancel and it will end up getting approximately S capital T over S 0 to the power beta. This is what I should expect based on the daily return. Now, what truly happens with EDFs is that you get a term which corresponds to this compounding effect, which is S T over S 0 to the power of beta. You get a term that corresponds to the expense ratio which is sort of similar to this term up there. You get another term which is an expense associated with the ETF itself which is FT and then you get a third term which corresponds to, the volatility, of the wa, of the returns over the period 0 to T. Si over Si plus 1 squared, sum it from i equals 0 to n minus 1. And the reason I'm using N here and not capital T is because N is the number of daily observations between time zero and time capital T. So this term over here corresponds to the volatility. And unless the term beta squared minus beta is equal to 0. This extra term which corresponds to the volatility drags the return down. So, there's a minus sign in front and that minus sign drags the return down on the leverage EDF. Effectively, the leverage EDF is short on volatility and so in markets that are associated with high volatility, we expect that the performance of EDF will be much worse than the compounding rate that we expect take and therefore we think we should expect that in markets with high volatility leveraged ETF's are not going to preform very well. Etf's are generally designed for short terms plays on an index or a sector and should be used in that way. Over long periods, leveraged ETFs do not work as one may expect, especially in volatile markets. In this slide I'm just going to show you a simple example illustrating this point that leveraged ETFs during volatile markets do not perform as we expect them to do. In the first half of this slide, I'm showing you the returns on pro ultra shares. Oil and gas which is at twice ETF on the underlying oil and natural gas index and DUG which is a Pro UltraShort oil and na, natural gas which is minus 2 times leveraged ETF. So if you look at what happened to the daily returns on these 5 days, they are roughly opposite of each other. And there's a little bit of a gap between them because of the expense ratio. Because of the funding rate and so on. But roughly they're going opposite of each other. And so if the intuition over data returns carries over, then we expect that these ETF should give me opposite returns over a large period of time as well. But if you look at what happened to the returns on these or the price of the returns on these EDFs from September 2008 to February 2009, the blue line corresponds to DUG which is the same thing up here. The red line, or brown line, corresponds to DIG, which is the same thing up here. Up here, DIG and DUG are running opposite each other. Down here because of the volatility, both dig and dug get dragged down. The price of these, both of these ETFs get dragged down. And this is because ETFs, particularly leveraged ETFs, are short volatility. They do not perform very well when the volatility is large.

### 009. Beyond Variance

In this module, we're going to introduce ideas of value at risk and conditional value at risk that define tail risk and, in doing so, we are going to move beyond variance as a risk measure. Problems with variance. Variance is a risk measure which is appropriate for normal and other elliptical distributions. By elliptical distributions, we mean, those distributions whose level sets of probabilities are ellipses. This is certainly true of normal but it's also true of other distribution. It does not, variance does not capture larger deviations from the mean. And in order to do that, we would have to use higher moments, like [unknown] and so on. It's also a symmetric measure, it equally penalizes deviation above and below the mean. And that's okay for normal and elliptical distributions because their distribution is symmetrical around the mean. But for other kinds of distributions where there are, the distributions are not symmetrical, variance will not provide a very good representation of the risk of the portfolio, and we need other measures that can capture some of this. Meaning, they can capture larger deviations form the mean and they can capture asymmetry about the mean. The value at risk is one such risk measure. The value at risk of a random loss L at the confidence level p is defined as the pth quantile of the loss. So, if you refer to this figure down here, I'm, on this axis, I'm plotting the loss, on this axis, I'm plotting the density of the loss. So, the magenta line is actually the density of the loss. The 95% value at risk for this loss is going to be the value here, it's approximately 9.5 and so on, such that the probability beyond it is at most point, not 0.95 but 0.05. So, the probability on this side is 0.95. The probability beyond it is 0.05. And therefore, this point itself is 0.95 quantile for the value at risk. Value at risk, as you can notice, it only looks at the tail probability, and therefore, it's a tail risk measure. It's increasing in p, so the value at risk at the 0.99 level is going to be greater than 0.95. So, value at risk at 0.99 will be somewhere down here. This will be the 99% quantile and therefore its an increasing in the p, the value of p that you provided. The conditional value at risk of a random variable L, is the expected loss beyond the value at risk level. So here, here are all the losses that are beyond the value at risk. When you compute a conditional value at risk, you take this loss, compute the conditional probability of these losses, and take the expectation according to it. So, in an expression, it's the integral from value at rest to infinity x times fx dx. So, this is just a plain expection of the tail and then I divided by the probability that things are going to be in the tail. So, this is approximately that expectation from value at risk to infinity, x fl x dx divided by 1 minus p. It's also a tail measure. It's very easy to show that, in fact, the conditional value at risk is greater, always greater than or equal to the value at risk as you can see on this slide. The value at risk is the blue dotted line. The conditional value at risk is the red dotted line. And, in fact, this is, it's all you can theoretically prove that they are going to be larger. Just like the value at risk, the conditional value at risk is also increasing in p. Other names for conditional value at risk is tail conditional expectation in expected shortfall. For a normal distribution, we can easily compute the value at risk and the conditional value at risk. The value at risk is simply the mean value times the volatility and phi inverse p and what is phi here, its the CDF of a standard normal random variable with mean 0, and volatility equal to 1. The conditional value at risk of a normal random variable is also can be written in terms of the mean vector and the volatility, it's mu plus sigma times the integral of the inverse CDF over the tail from, going from p to 1, normalized by 1 over 1 minus p. The value at risk and the conditional value at risk of a normal random variable is completely defined in terms of the mean and the volatility. Should this be a surprise? You might want to pause and think for a moment. The value at risk and the conditional value at risk are some properties of the underlying distribution. For a normal random variable, the distribution is completely defined if you tell me what the mean lecter is, or mean is, and the volatility. And since mean and volatility completely define the distribution, they completely define the value for value at risk and conditional value at risk. One of the reasons value at risk and conditional value at risk have become very popular is because you don't have to make distributional assumption. As long as you have access to samples of the underlying loss distribution, you can compute value at risk and condition value at risk from these samples. So, here's what you do. You take some capital N samples, IID sample of the loss, put them in an increasing order. So, L paren 1, L1 is now the smallest value that you saw among these N samples. L2 is the next larger value that you saw in the N samples. Ln is the largest value that you saw at N samples. So, these are simply samples sorted in increasing order. Now, find an index Kp, which depends on the probability and is defined as the ceiling of the probability times the number of samples that you took. So, if the probability was 0.95, the number of samples N was 1,000, then Kp would have been 0.95 times 1,000, ceiling, which is 950. Ceiling, but since it's an integer, it doesn't matter. So, the index is 950. So, you take your losses, put them in increasing order, compute this index Kp, then the value at risk is approximately equal to the loss, the Kpth term in this increasing sequence, it's the Kpth term in the sort examples. What about the conditional value at risk? You take the sum of all the samples starting from Kp all the way through the N, divided by N times 1 minus p, and that is what is going to give you the answer for the conditional value at risk. So, there's another term N that is going to show up here. So, the sum of the N minus Kp plus 1 samples divided by 1 minus p times N. In the next couple of slides, I'm going to show you what happens as you change the underlying return distribution. The experimental setup that I'm using is as follows. I computed the sharp optimal portfolio corresponding to just the risky assets in this spreadsheet. I computed 10,000 samples of the loss or equalently negative of the return for three different distributions. The first distribution was a normal distribution with mean mu and covariance V. And mu and V were those that were specified in the spreadsheet. The second distribution that I use was a student's t distribution with mu equal to 12 degrees of freedom. I kept the return vector the same as mu but I've rescaled the covariance as mu minus 2 divided by mu. The reason I rescaled the covariance is that after this rescaling, the variance of the losses remains the same as V. So, both distribution a and distribution b, both the normal distribution and the multivariate t distribution have the same mean and the same covariance matrix. The difference comes in is that the t distribution has fatter tails, has higher moments that are not represented in the normal. Finally, I took a third a distribution was a mixture, a 75, 25 mixture of two normals. The first normal has a little bit lower variance, and the second normal adds actually one point time, 1.5 times higher volatility. And these numbers, 0.75, 0.25, 0.76 and 1.5 are chosen in such a way that if you looked at the mean vector in the covariance matrix for this mixture of normals, you end up getting exactly mu and V back. So, all three distributions have the same mean and the same co-variance. The only difference is how is the return distributed beyond the first two normals. Students see distribution has fatter tails than normal, particularly when the decrease of freedom are small so we expect the value at risk and the conditional value at risk to be larger. The normal distribution with a covariance of 1.5 squared times V has all of the volatilities 50% larger. And we expect that it will have a very large value at risk and conditional value at risk. This mixture model models a situation where there's about a 25% chance of having very high volatility and we want to capture and see what happens to the return distribution. So, this is the last histogram for the normal distribution. The 95% value at risk is 1.67%, everything is in percent. The 95% value at risk is 3.5, 3.15%. The value at risk is larger than the, the conditional value at risk is larger than the value at risk and the numbers are as they are shown in the slide. For the t distribution, the 95% CVaR is 4.58. If you compare it to 3.15, it's larger. And you can sort of, as I skip between these two slides, you can immediately see that the data is getting fatter. The 95% VaR also goes up to 226. What happens about the mixture of normals? The conditional value at risk is 5.6. And again, if just flip between these two slides, you will see that the data is becoming larger. And 95% VaR is at 1.93. So, what's interesting here, that if you compare these three numbers, the value at risk is 1.67 here. For the t, it's 2.36, larger value. But the VaR actually goes down for the mixture distribution to 1.93. So, if you just focused on VaR, just focus on where the pth quantile is. You would prefer the mixture of normal distribution to the t distribution. If value at risk was the risk measure to use which is a mandated risk measure in a lot of regulations, you would prefer to use the mixture of normals as compared to t. But if you look at the distribution of the losses for the mixture of normal and compare it to the t, you are expect, you are likely to see very high losses in the mixture of normals, which is captured in the fact that the conditional value of risk of the mixture of normals is a lot higher. And this is the reason why, one of the reasons why we are moving away from value at risk and going to conditional value at risk. Value at risk is only sensitive to the probability of losses. Conditional value at risk is sensitive to both the probability of the losses and the actual location of losses. Where does the loss happen in the tail? As a result, it turns out to be a better measure. It's also a measure which has some very nice properties associated with diversification, and it's a risk measure, which falls into the class of risk measures called coherent risk measures, and these risk measure have some nice properties. In later module on risk management, we are going to focus on the exact properties of value at risk and the conditional value at risk. What are the advantages and disadvantages, and you'll get more into the details of how to do portfolio selection with that. I'm just going to leave you with some properties of VaR and CVaR, proves of this, that this value at risk is that it captures the behavior. It can robustly estimated from the date, data, because it's a quantile rather than an expected value, it's not susceptible to outliers. It's, I've already pointed out that it's, susceptible only to the pth quantile and not the distribution beyond it. And that is one the bad parts of value at risk. And it creates incentive for something called tail stuffing. The value at risk is not sub-additive therefore, diversification can sometimes increase the value at risk, which is a problem when we're trying to do asset allocation. What about conditional value at risk? It all captures tail behavior, it's sub-additive and therefore, diversification actually reduces conditional value at risk. The mean conditional value at risk portfolio selection can be formulated and solved very efficiently. And more and more, we are moving in this direction as opposed to mean variance. The bad part is that the, the conditional value of risk is defined in terms of an expectation and therefore, it can be very sensitive to outliers. We'll return to this topic again in the risk management module.

## 007.Statistical Biases and Potential Pitfalls

### 010. Statistical Biases in Performance Evaluation

In this module we're going to discuss statistical biases in performance evaluation. The goal here is not to build realistic models but rather stylized models, so simpler models, but models that nonetheless will help explain to us that biases do arise, and that biases can be significant. When we are evaluating the performance of fund managers. Let's get started. Some fund managers claim to have special skills. What do I mean by special skills? Well for example they might claim to be very good at picking stocks or they might claim to be very good at timing the market. And what do I mean by timing the market? I mean the following. Maybe they know a good time to enter into the market, in other words when to invest in the S&P 500 or the Euro stocks, or whatever. And also they might claim that they know a good time when to get out of the market, when is a good time to sell. So, that's what timing the market means. This skill is often referred to generically as alpha. And the term comes from the capital asset pricing model. If you recall the cap end that you'ld seen in the previous module. We know that the expected return on an asset is equal to the risk free rate plus beta times the expected return on the market minus the risk free rate. I've added in here this additional term here alpha. So this can be viewed in the context of the capital asset pricing model as the excess returner, the skill if you like, that a manager can earn on an investment. I don't want you to think that alpha is necessarily associated with account fund. It's a generic term used to evaluate skill, whereby a manager can earn excess. Risk adjusted returns. Why is this important? Well, a fund manager who has alpha, or who has skill, can often charge substantial management fees. And so what we want to know, is whether or not the skill is real. In general, it's very hard to tell, but you can still do some interesting analysis, and that's what we're going to do in this module. We're actually going to look at this question from three different perspectives. The first two perspectives, will require the binomial distribution, and so we're going to review a little bit about the binomial distribution now. If you recall, we say that x is a binomial distribution. Or we write x tilde Bin n p, if the probability that x equals r equals n choose r, times p to the r, times one minus p to the n minus r. And so x might represent for example, the number of heads in n independent coin tosses, where p is equal to the probability of a head. The mean and variance of the binomial distribution are given by these quantities here. The expected value of x is n times p, and the variance of x is n p times 1 minus p. You can also see from one that the probability that x is greater than or equal to r is equal to the sum of the probabilities that x equals r, x equals r plus 1 up to x equals n. And that's given to us by this summation here on the right hand side. So, to see our first perspective on this problem, consider the following situation. Suppose a fund manager has a track record of ten years and that this fund manager has outperformed the market in nine of the ten years. The fund manager claims to have great skill and that his fees should reflect this. What we want to know is, well how can we assess his claims? Does he really have great skill? So first analysis might assume the following, in a given year he outperforms the probability p and under performs with probability 1 minus p. And by the way, when I say outperform, I mean outperform relative to the risk the manager is taking on. So I'm talking about risk adjusted returns here. Outperformance or underperformance is assumed to be independent across years. If the manager has skill, then p is greater than a half. Otherwise p is less than or equal to a half, and the manager has no skill. So the first question that now comes to mind is the following. How likely is such a track record if the fund manager had no skill? Well to answer this, let x be the number of outperforming years. If the fund manager has no skill, then x is going to be binomial, with n equals 10, and p equals a half. We said that the fund manager outperformed in 9 of the 10 years. So, a track record as good as this would corresponds to x being equal to 9 or indeed x equals 10. So we want to compute the probability that x is greater than or equal to 9. Assuming the manager had no skill. In other words, assuming p is equal to a half. That is given to us by our binomial probability we saw in the previous slide. We can evaluate this easily in Excel or some other piece of software, and we find the answer of 0.0107. So therefore, if the fund manager has no skill, then the probability of having a track record as good as his, or better, is only 0.0107. So at this point, you might think it's fair to conclude, that the fund manager does indeed have skill. After all, you could think of this in a statistic setting, for those of you who are familiar with the statistics, you'd be aware of the concept of a p value. And usually a p value that's less than or equal to 0.05 would be assumed to be significant. So we've got a p value here if you like, of 0.0107, this seems significant. It seems unlikely in this case that the fund manager is no skill. Given the track record of 9 successful years out of 10. So that's the first perspective we're going to take. Here is a second perspective, suppose instead that there are M fund managers and that the manager who claims to have skill has the best track record of these managers. The questions that now arises is, does this change anything in our analysis? Should it change something in our analysis? To answer this suppose we start with the hypothesis that none of the fund managers have skill and that track records of fund managers are independent. There are two possible questions now that arise. The first question is, how likely is the third manager to have such a track record if all fund managers have no skill. Well, in this case, if we've identified the third manager in advance, then the first perspective gives us the answer. It would actually. Actually be 0.0107, as we calculated beforehand. The second question or possible question to, to ask, is how likely is the best manager to have such a track record if all fund managers have no skill? And now, what is the appropriate question here? Which of these two questions is more appropriate? This actually depends on our prior hypothesis. What do I mean by that? Well let's come back to this slide here. We've actually identified this manager here, this is the third manager. And this is the best performing manager of the M managers. And so what I mean by prior hypothesis is the following. Did we identify this third manager in advance? Maybe this third manager was our friend, or a cousin, or somebody else we specified in advance before we saw any data. If that is the case, then this question is the more appropriate question. We've seen the manager in advance, we're interested in his performance, not because he was the best performing manager, but because he was the third manager or some manager we've seen in advance. However, if we're interested in the third manager because he was the best performing manager, and that's why his track record has come to our attention, then the appropriate question is actually the second one. How likely is the best manager to have such a record, if all fund managers have no skill? And this is because the reason we're interested in the third manager is not because he was number three in the list. But because he was the best performing out of all m managers. And that's why he came to our attention. So, it really depends on our hypothesis. Why are focusing on this manager? Is it because he was the third manager, we'd pre-selected him in advance? Or is it because he was the best manager, and that's why the manager's track record has come to our attention. Depending on which hypothesis is correct, we get a very different answer. With the first hypothesis, we see it's 0.0107. With the second hypothesis, for our interest in the manager is because he's the best performing manager out of M, the second hypothesis is the more appropriate. So let's answer this second question. We're going to assume none of the managers have skill. We're going to let z i be the event that the ith manager out-performs in r years or more out of the n years. We're going to let v be the event that the best manager outperforms in r years that event, or more. Then what we're interested in is the probability of v. The probability of v is equal to 1 minus the probability of zed 1 bar up to zed m bar. Now what is zed i bar? Zed i bar is the complement of zed i. So zed i is the event that the ith manager performs in r years out of n, so zed i bar is the event that the ith manager outperforms. In less than r years out of n, so it's the complement of zed i. So therefore just to make sense of this, if the best manager is to outperform in r years, the event that the best manager doesn't outperform in r years and more. Is equivalent to all managers. All m of them outperforming in less than r years out of n. And that's this quantity over here. Because we're assumption that these z, zed i's are independent, and IID. I can write this as just the probability of zed 1 bar. Times the probability of zed q bar, up to the probability of zed m bar. Just keeping these separate. And these are all IIDs, so this is, there's m of them. And so I get the probability of zed one bar to the power of m. Now, recall, the probability of zed 1 bar. Zed 1 bar is the event that's the compliment of zed 1. So therefore, the probability of zed 1 bar is equal to 1 minus the probability of zed 1. And therefore, I can plug in the numbers. I'm assuming, in this case, I believe, that m is equal to 20. And I know that the probability of zed 1 is 0.0107. Because I actually calculated this. Onto our first perspective. So this is for a fixed single fund manager. The probability of zed 1, we found to be 0.0107. So we need the probability of zed 1 bar, here, which is 1 minus that. Take it to the power of m, we get this number here, 0.1942. And actually you can easily see what happens. As m gets bigger, as we increase m, the number of fund managers in the marketplace. Place then actually probability of v will actually increase to one as m gets very large. What are our conclusions. Well our conclusions are as follows. If there are a lot of fund managers in the market, then the, the fact that one particular fund manager has a fantastic record, does not, in and of itself constitute evidence that, that fund manager has skill. After all, we have shown here, that with just 20 fund managers we would expect the best manager to have a record of outperforming in 9 years. Or more out of 10 to recover probability 0.1942. And that's not a very small number. If we take m equal to 30 or 40, this number will get bigger. And so even though we've assumed all the fund managers have no skill here. The fact that we're focusing on the best manager's track record. Suggests that the best track record, will be good. So we haven't established evidence to suggest that a particular fund manager has skill just because he's got a great track record. It all depends on the hypothesis. How did we identify this manager? I should also point out that while we have focused on the best manager here, we could also have focused on the second best manager or the third best. Manager and so on. If n gets sufficiently large, we're not going to just expect the best manager to do well. The second best manager will also have a very good track record. The third best manager will have a very good track record. And so on. As long as m gets sufficiently large. And this is true even if all of the fund managers have no skill. Here's another perspective. This is our third perspective. Suppose again that all fun, fund managers have no skill. At the end of every year, fund managers who have out performed the market that year, survive. And fund managers who have under performed in the market that year, get fired. Here's a question. After one year of this experiment, what would be the average track record of fund managers in the market? Well. It's got to be perfect. Only the fund managers that have a good year survive, so they will have a perfect track record. The fund managers that have an imperfect track record, in other words they under performed that first year, well they've been fired, so they're no longer available, they're no longer in the marketplace so we won't see them. And so their performance does not enter into our calculation of the average track record. And indeed you can look at this after 2 years, or 3 years you'll only see perfect fund managers in the market. So only perfect fund managers survive, and they appear to have a perfect track record. And yet it's clear that in fact, that these fund managers have no skill. You could also generalize this in fact, as follows: you could imagine that fund managers who've outperformed in a given year will stay in the market with some probability p. And that fund managers who've underperformed in the market will be fired with a different probability. And we can assume that fund managers who've under-performed get fired more frequently than fires, than managers who've over performed. You could do that type of experiment, you could simulate that kind of system and what you'll still see is that the average track record of fund managers in the market would actually be greater than a half. So actually they will appear to be a level of skill in the market, even though that skill isn't really there. This is an example of what is called survivorship bias. The reason being that some people have survived, they're the people who have outperformed in the market, and they actually make the market look better. They look like the, the collection of fund managers look better than they really are. They've just survived because the poor and unlucky fund managers have actually Under performed and lost their, and lost their jobs. So this is an example called survivor bias or survivorship bias. Its a very common phenomenon in finance and beyond and we're actually going to see some more examples of survivor, survivorship bias very soon. Now some final thoughts here. I've been assuming up until now that the fund manager or the fund managers have no skill. And you might ask the question, well, is that fair? Is it fair to assume to begin with that fund managers have no skill? After all, in practice there are some managers with skill. And that's absolutely true. There are some managers in practice with skill. I don't there are too many of them and certainly lots of fund managers may think they have the skill but the reality is quite different. Nonetheless it is true that there are some fund managers out there with skill. That having been said, I don't think we're being unfair in assuming to begin with that fund managers have no skill. And that's because it is the responsibility of the fund manager to convince us that they have skill. After all, fund managers with skill try to charge fees to manage our money. So it's up to them to convince us that they have skill. It's not up to us to give them the benefit of the doubt and assume they have skill. So it's perfectly reasonable to start off with the assumption that they've no skill, and then to see where that takes us. And if we can find such a manager, is the resulting out-performance sufficient to justify the management fees? That is not clear as well. If the management fees are too large, then those fees are going to dominate the out-performance. That the manager provides and so in that situation we wouldn't want to invest with the manager anyway.

### 011. How Should Average Returns be Computed

In this module we're going to discuss a varied topic of problem. Namely, how should average returns be computed? We'll see why this is an important question and why there can be different answers to this question. We'll also see what answer is more appropriate to investors. Here's an example. Suppose an investment fund delivers the following performance. In year 1, they returned 20%. In year 2, they returned minus 10%. What is the average annual return of the fund? Well, it's going to be 20% minus 10% divided by 2, which is equal to 5%. So we can say the average annual return is 5% here. But suppose I change things just a little bit. Actually, I won't change anything, I'm going to give you a little bit more information. Consider this example. The exact same fund, the exact same performances in years 1 and 2, plus 20% and minus 10%. But now I also tell you what number of dollars were invested in the fund. In year 1 there was 1 million dollars invested in the fund. In year 2, there was 10 million dollars invested in the fund. Now I'm going to ask you the same question. What is the average annual return of the fund again? Well, it's not clear any longer because there's two possibilities. We could say it's 5% as before where we just take the average of 20 and minus 10. Or we could choose to compute a dollar weighted average return. If you look at this, you can see there's 1 million dollars, which received an average return of 20%. And there's another 10 million dollars which received an average return of minus 10%. So if I look at the average return to each dollar, then this is the correct answer. It's 1 million times 20% minus 10 million times 10% divided by total of 11 million and I get minus 7.27%. So in this case the average annual return is actually much smaller. So we can see 5%, or minus 7.27%. And the question is which return is more compelling if any? Why is this important? Well it is important because investors care about returns to their dollars. And so in fact you could argue that at the aggregate level, investors should be caring much more about a dollar weighted return, in which case this number is more significant. And so to emphasize this claim, consider the following two situations. If you're an aggregate investor, in other words if you take all investors together and you asked them which would they prefer, would they prefer this situation? Let's call this situation 1, or situation 2. The difference between situation 1 and situation 2, is that in situation 1, 1 million dollars was invested in year 1 and that earned 20%. And $10 million was invested in year 2, and that earned minus 10%. Or the reverse of that is situation 2. 10 million dollars in year 1, earning 20%. And one million dollars in year 2, losing 10%. While I think investors in aggregate would per, far prefer to be investing in this situation here, because this is what will happen to their dollars. Investors care about dollars invested, what's going to happen to their dollars. They don't necessarily care about average annual return of 5%. If in years where the returns were very high, they didn't have any dollars invested. And years in which returns were very low they had lots of dollars invested. What they care about is the return on their dollar. Here's another reason why investors should care about the total number of dollars invested. In financial markets, expected returns often decrease as the dollars invested increase. This is because the liquidity of a market, or the so called capacity of a trading strategy is not unbounded. Now this isn't always obvious to the small investor who only invests in liquid markets and therefore does not move the market. So, what I'm getting at here is a small investor might buy some shares in an S&P 500 ETF. Or maybe they buy some foreign exchange. Those markets are extremely liquid, so a small investor trading in those markets is not going to move the markets. In other words, the act of their trading is not going to have an impact on the market price of those securities. This is not true in general for large investors. The larger they are, the more they tend to move a market. The more liquid the market, the more they move it. And in this case the cost per security increases with the number of securities they buy. And the cost per security decreases with the number of securities they sell. So this implies that returns decrease on average as dollars invested increases. Let me give you an example. A simple example which is, might be a gambling example. Suppose we've got 2 teams. We've got team A, and team B. Let's suppose, that the odds of team A beating team B are 50%, and the odds of team B beating team A are 50%. And let's suppose that the market agrees on these odds, maybe you're going to Vegas and you want to bet on team A versus team B, you see these odds in the casino. You however think that the probability that team A will win is 75% and the team B will win is 25%. So in this situation you'd like to bet on team A. But you won't be able to bet an unlimited amount. Maybe it's not Vegas, may your friend is giving you these odds. So your friend is giving you these odds of 50% and 50%, but they'll tell you, sure you can bet but I'm not going to accept a bet of more than $10. Well in that case the most you can bet is $10. And so in this case it's a very ill liquid market. There's not much capacity in the market, the capacity is $10, after which there's no ability to trade anymore. So believe it or not, financial markets behave like that as well. The more you trade in some of these markets, especially for big investors, the more you move the market against you. And so what happens is you tend to see decreasing returns to dollars invested. Now the question of how to compute average returns is important. Depending on how you answer it, certain types of investing can seem more or much less attractive. An example of this is the hedge fund industry. On aggregate, they would prefer to report average returns over time. And in fact they do so. Now that's not to say the hedge funds are being dishonest, they're certainly not. One can just view it as being good marketing. Every industry markets and the hedge fund industry is no different. So if they wish to report their returns as being average returns over time, then that's fair enough. However, we as investors should be aware of this and be aware that from our perspective we care more about average net returns per dollar invested. So if we measure returns this way we might get a far different average return than that reported by say the hedge fund industry. And it's important to be aware of this, because there are very different, different ways of computing returns, and you get very different answers depending on how you compute them. This has actually caused some controversy and debate. There are some financial blogs out there that discuss this topic. A nice blog and a nice discussion of this topic can be found at this URL here. And I'll encourage you to take a look at it and read this discussion. Here's another problem with averages. It's not a financial example but it is a nice example because it demonstrates how people can be easily confused by the way a question is worded. Sometimes the confusion becomes very apparent once it's explained, but in everyday conversation, sometimes this, these issues go by us we don't really notice we're calculating the wrong quantity. So here's a question. Suppose I wish to estimate the average number of children per family in the US. And to compute an estimate I do the following. I sample n people randomly, maybe n will be a very large number. Maybe it's a 1000 or 10,000 or 50,000. And for the i th person I determine x i, which is the number of siblings in his or her family. My estimate, c hat say, is then given by the following. C hat is going be some of the XI's plus 1. So, this extra 1 is for the person that I sampled. So, the number of children in that family will be the number of siblings plus the person I sampled. So that's x i plus 1.and then I divide by n. So, that's my estimate of the average number of children per family in the US. Now let's ignore any minor problems that you might see with this sket sampling. There's a bigger question here. And the bigger question is does the sampling scheme have a fundamental problem? If so, in what way will c hat be biased? And how does this problem compare to the average return problem? So these are some other questions we are interested in as well. To explain to you why there's a problem with c hat, consider the following situation. Let's assume there's a universe of 5 families. So this is family. We've got family number 1. This is the number of kids, or children, in each family. So family number 1 we'll assume has 4 children. Family number 2 we'll assume has 3 children. Family number 3 has 2 children, family number 4 has 3 children, and family number 5 has 0 children. So this is our universe. The total number of children is 12 and so the average number of children per family is 12 over 5 which is equal to 2.4. So this is the correct answer. 2.4 is the average number of children per family in this universe. But if I use the sampling scheme in the previous slide, where I sampled by child or by kid, I'm going to get a different answer. To see this note the following. There's a total of 12 children. So if I sample by child, then 4 out of 12 times, I'm going to sample 1 of these 4 children. Each of these children will say 3 siblings plus themselves will lead to 4. I've got 2 families with 3 kids, so that's a total of 6 kids. So, 6 out of 12 times I'm going to sample a child from here or from here. Each of those children will say they've got 3 fam, 3 kids in their family including themselves. 2 out the 12 times I'm going to sample 1 of these 2 children. And each of these 2 children will say they have 1 sibling. So, 1 plus themselves will equal to 2 so I get an answer of 2 here. And then 0 out of 12 times, I'll sample from down here and a reported number of siblings will be 0. So, I'll get a total here equal to let's see, it's 16 plus 18, 34. 34 plus 4 is 38 over 12. And 38 over 12 is equal to 3 and 1 6th. So in this case, the way I compute the average here, by sampling by child, I'm going to get an average of 3 and 1 6th, and this is the wrong number. The average I want is 2.4. So what I've done here is I've actually calculated the average incorrectly. I want to know the average number of children per family. So what I should be doing is sampling by family. Which is effectively what I'm doing down here. Instead, the sampling scheme I gave to you on this previous slide, I'm sampling by person, or by child if you like. And by doing that, I'm getting this average over here. And in fact, I'm getting a number that's too large. And in fact, that's how c hat would be biased. I'm more likely to sample children from large families, as we saw here, so those families will over report themselves. They'll have, we'll see higher average numbers as a result. We'll get 3 and 1 6th in this case. And in fact, an easy way to see this is to note the families with 0 children will never be sampled. So if we're ignoring all families with 0 children it should be clear that our bias is upwards. And here's another problem that has been very topical recently. It concerns the controversy surrounding waiting times to get through immigration at Heathrow Airport In London. This was a big news story last year when many people who were entering Heathrow airport, and had to wait a very long time to get through immigration. So a lot of newspapers were writing in about, writing about this problem at the time. It was definitely a source of controversy in Britain. And so people were interested in estimating the average waiting time of travelers at immigration at Heathrow airport. One way in which this est, in which this average waiting time is estimated was as follows. Sample 1 person every hour, compute that person's waiting time and then take the average of all these people. So maybe there is 16 hours in a day. We get x 1 up to x 16. We sample 1 person from each hour, find their waiting time, and take the average. And then report this as the average waiting time to get through immigration. The question here is, is this a good scheme? I'm not going to answer this question, but you can think about it. I will give you a hint, it's a bad scheme. And it has a fundamental problem which is similar to the problem on the previous slide where we discussed ways to compute the average number of children per family.

### 012. Survivorship Bias and Data Snooping

In this module, we're going to discuss Survivorship Bias and Data Snooping. We've already discussed survivorship bias in an earlier module and we'll talk a little bit about it again here. Consider the following investment. We're going to purchase an equi-weighted portfolio of the top 20 stocks in the S&P 500. Note that the stocks are chosen and fixed today. In order to get an idea of how this portfolio would perform, we decided to back-test it using historical data as follows. We're going to get the last 20 years of data return data for each of the 20 stocks. On the first day, that is the first day 20 years ago, we're going to set up the initial equi-weighted portfolio. If the stock didn't exist back then, for example Google, then omit it from the portfolio and just form an equi-weighted portfolio of the stocks that did exist that day. Every month we're going to rebalance the portfolio so that it remains equi-weighted and we're going to take transaction costs into account. What we will then do finally, is that we will plot the annual net returns that is rt against t, where rt is the net reutrn to time t realised over the previous year. So we have the following question. Do you think the plot will be representative of the future performance of the investment? Well, we're going to get a plot like the following. So we're going to have time down here. So this is today, this is 20 years ago, so this point is 20 years ago, this is also the 0% return so we've got r1, standing for R one year so the one year return over here and, so any point in time are going to get some sort of plot like this and for example at this point, the value here which is some value over here. This corresponds to the realized return a day t over the previous year. So back to t minus 1 year. The question is, do you think that this plot will be representative of the future performance of the investment? Well the answer is certainly not. Why not? Well, what we've actually done is we've introduced survivorship bias into this problem, and we've introduced an enormous amount of it because what we've done is we've picked our portfolio today here, and we picked the 20 best stocks in the S&P 500. Now we go back 20 years ago, and what we've done is we're back-testing the performance of an equi-weighted portfolio of these 20 stocks, but we've actually chosen those stocks by implicitly looking into the future. We've gone forward 20 years to today, pick the best performing stocks. After all, the top 20 stocks in the S&P 500 have surely performed very well over the last 20 years. And so we've actually introduced an enormous amount of buys into our back-test. This is equivalent to today to going 20 years into the future, picking the best 20 stocks in the S&P 500, 20 years into the future and actually trading those stocks today, that's an example of survivorship bias. It's an extreme example of survivorship bias, and it should be clear to everybody what we have done and why it is wrong. But actually survivorship bias crops up an awful lot in finance and not always as obviously as we've seen in this example here. So it needs to be born in mind by investors, risk managers and so on. People always need to be on the, on the lookout for it. So here's another example of survivorship bias in action. It's called the football game scam. Sometimes it's called the horse racing scam, when the context is changed to horse racing. We're going to stick with the football person. On each of 10 consecutive Wednesdays you receive a letter predicting the winner of a big football game the following Sunday. We're going to assume here that a football game is either won or lost, and that there are no ties in a football game. Each week the prediction was correct. In week 11 however, a letter arrives but this time it seeks payment of $10,000 before revealing the prediction for the next game. The question is what should you do? Should you pay the $10,000 or should you ignore it? Well this is a, this is an example of a scam the answers you should ignored and the reason is as follows. So what's going on here is the following. The scam artist, the person perpetuating the scam has, playing the following game. In week 1, the scam artist had a total population of 2 to the power of 10 people. To half of this group he sent a letter saying team A would win, and to the other half he sent a letter saying team B would win. For week 2, let suppose that team A won, this means 2 to the power of 9 people saw a prediction in week 1 that was correct. He now splits this 2 to the power of 9 people again into two groups, half of them get a prediction for week, for team A winning, the other half get a prediction for team B winning. If you come to week 3, and now you've got 2 to the power of 8 people remaining, who actually were correct, or have got the correct prediction on week 2. And you keep going on like this until week 1, week 1 there's only 2 to the power of 1 people remaining or rather week 10, I should have said. So in week 10 there's 2 to the power 1 people remaining which is equal to 2, you were one of them. You received a letter saying team A would win, another person received a letter saying team B would win. Presumably team A won which meant that after week 10 you were the only person and there's just one person remaining and that is you. So you're the ultimate survivor here, you're the one survivor out of 2 to the power of 10 people who see the correct prediction 10 weeks in a row. There is no skill here, no skill whatsoever. And so this is an example of extreme survivorship bias, where you see the track record of only one person and that track record is perfect, and it's your track record 10 weeks in a row of perfect predictions. We're now going to discuss an example of data snooping. Data snooping arises in many context not just in finance but beyond finance and very often the problem with data snooping are quite subtle and hard to spot. So we're going to see an example here. A bank has 4 years worth of daily historical returns data, on the Dollar. British Pound exchange rate. It employs the following mechanism for generating a trading strategy. It first normalizes the entire return data so that it has mean zero, and variance one. Now just to point out here, normalizing data is a standard and well justified statistical technique in general. We're going to use 75% of the data for training, 75% of the data actually corresponds to approximately 750 returns. And that's because there's approximately 250 trading days in the year. So if you take out holidays and weekends. We find that the typical year has about 250 trading days. So if you take 75% of 4 years, you're going to get approximately 750 trading days, or 750 returns. The remaining 25% of the data set, which corresponds to one year, so approximately 250 days, is kept at what's called a hold-out test set. We're going to use this test set to evaluate whatever strategy is yielded by the training data. The trading strategy appears to be a great success. On any given day it uses the returns of the previous 20 days to forecast the direction of the next day's return. However, the trading strategy performs very poorly in practice. The question is, why? So let's think about this for a moment. What we have done is we've split up our data set into training data and test data, so let the following be our training data, so we have about 750 observations in our training data. So starting from one up to 750. So this is date 1, date 2, date lets say t minus 20. We've 20 days in between up to day t. Now imagine the following, so we said that the trading strategy is based on the previous 20 days of returns. So suppose we're here at day t, this is day t plus 1, and we want to know the return from t to t plus 1. Let's call this mean return, mu t to t plus 1. We've seen, let's say, mu t minus 20 up to t. So we know at day t, we know this quantity here. This is known as a day t. ,Suppose for example that this is greater than 0, maybe much grater than 0. What does that tell you about mu t to t plus 1. The return you expect between dates t and t plus 1. Well if you think about it you should see that this implies that mu t to t plus 1 will be less than 0 on average, why is that? Well the reason is because of this normalization we did. We actually normalized the 1000 data points that have mean zero, so if all 1000 data points had mean zero, and I've got 20 data points here which have got a strictly positive mean, in fact I said here that it's much greater than zero. Then that means the remaining data points must have a mean return that's less than zero, in particular the return from t to t plus 1, must also be less than zero. And so in fact, this trading strategy we've determined will tell us maybe that we should sell on day t, knowing that we expect to make money from t to t plus 1, because the mean between t and t plus 1 will be negative. So, this might seem to be a small bias. But it is a bias, nonetheless, and it can actually mess things up. Now, this is what's happened with the training data. Because of our normalization process, we've actually introduced a bias into how we determine this trading strategy. So now, what about the test set? Well, the test set is meant to be an independent set of data. It has 250 returns, and the idea behind the test set is, that it should be completely unpolluted, if you like. It should not have been polluted by the act of coming up with a trading strategy. However, it's subtle, but it has been polluted. And the reason is as follows. Suppose I test my trading strategy, which I've determined up here using the training data. Suppose I test that strategy on the test set. Again let's say I'm at date t, I go back to date t minus 20. My trading strategy says, look at what's happened on the previous 20 days. So I'm just summarizing the previous 20 days by the mean return over those 20 days. There's other factors inside these 20 days as well that could also be part of the strategy. But let's suppose then on, on this particular day t, this mean over the previous 20 days, let's say it's less than 0. Well, what does that say for days t to t plus 1? Well, it says in this case, that mu t to t plus 1, the return you expect from t to t plus 1 must be greater than 0. Why is that? Well, the reason is because the test set was part of the overall normalization scheme. We actually included the tests set and training set, combined them together and normalized that data, so that the mean of all the training and test data is zero. That means, that if this mean over these 20 days is negative, even though it's only 20 days out of the total of 1,000 days, it does mean that the rest of the data must have mean greater than 0. In particular, the return from t to t plus 1, we would expect to be positive, and that's why we have that. And so the trading strategy will be, if you like a mean reverting strategy. If the previous 20 days are negative we buy. If the previous 20 days are positive resale. And so this test set will actually justify the use of the trading strategy. We will see that we'll make money on this test set. And the big problem here is the following. We normalized the entire return data set, and this was a mistake. A test set should have had nothing to do with the trading strategy. It should of been kept entirely separate from the entire process of finding the trading strategy. Only when we find the trading strategy, do we bring the test set in and use the test to evaluate the trading strategy. But we didn't do that here. We made the mistake of actually including the test set when we normalized the data. It might seem like a very small issue, but it is a real issue and it will introduce a real bias. It will make the strategy look better than what it really is. And the test set will have failed here because it would not have been an independent test set. It will have been used as part of the learning process. The learning process being the process used to generate a learned, good trading strategy. What we should have done is just normalize the training set. If we just normalize the training set, then the test that would have been completely uncorrupted or unpolluted. And over here, this behavior which are identified would not have been true. And so presume-, presumably the test that would have found out that there was indeed a problem with the trading strategy would be determined on the, on the training set. These examples crop up an awful lot in finance. Many banks and funds over the years have looked for trading strategies in similar manners and introduced small but still significant biases into their trading strategy's and into their learning strategies for developing trading strategies in this manner. The conclusion is, one always needs to be aware of introducing these biases, and when you're keeping a test set, the test set must be completely independent of the process that was used to generate the trading strategy. There are many other examples of statistical biases and difficulties that arise in finance. Survivorship bias and data snooping are everywhere and one does need to be aware of this. There are many other examples that we can discus, we don't have a great deal of time to do so in this course. And let, let me just mention a couple of other examples where biases arise here or statistical difficulties arise. Here's an interesting question, just how likely is a 25 standard deviation move? Now the reason I bring this question up here is that at the beginning of the financial crisis in August 2007. There was a very large move in the market, some funds lost an awful lot of money. And some participants reported that they actually saw a 25 standard deviation move and they used the size of this move to justify the size of their losses. Well, in fact it did more than that, in fact said they saw 25 standard deviation move, not just once, but several days in a row. So, a quick question, how likely is a 25 standard deviation move? Well, let me tell you. You can easily estimate this using Monte Carlo, and using something called, a partial sampling of Monte Carlo. A 25 standard deviation move, assuming a normal distribution. So the probability done a normal distribution. Let's say it's n zero one, but it could be n mew sigma squared. It doesn't matter that I'm assuming zero one. Probability that this is greater than or equal to 25. Which is 25 standard deviations, is approximately equal to 3.05 by 10 to the power of minus 138. So just to emphasize this is equal to .000305 and yes, there are 137 zero's in this expression. So the probability of a 25 standard deviation move is absolutely infinitesimal. To give you some sort of comparison, the number of particles in the observable universe. Depending on who you ask it's something on the order of 10 to the power of 78 or maybe 79, or 80. But it's some sort of number like this. So, this is an enormous number. But it is in fact dwarfed by 3.05 by ten to the power of 138. So you can see that this number is extremely small. So if somebody reports a 25 standard deviation move, you have to ask the question. Were they just exceedingly unlucky, or perhaps their model was wrong? I think the, I think the answer is self evident. How likely is a 25 standard deviation move several days in a row? Well making the heroic assumption that these moves are independent, you would end up with a number like 3.05 by 10 to the minus 38. And it it's 3 days in a row say, well you have to cube that, and if you cube it you'll get an answer like 2.7 by 10 to the minus 413. So I thing it is fair to say that in August 2007, it was inaccurate to say you saw 25 standard deviation move several days in a row. It much more likely that your model is wrong and very wrong at that. Alright, another example versus the [unknown] problems arise is in the are of retailed structured products. I'd like to be able to see more about structured products. Products in the course but we don't have time. So I'll just state the following; retail structured products are if you like exotic securities that are sold to retail investors. So these could be investors with just $10,000 or 10,000 Euro to invest. Their bank manager or their financial advisor suggests a structured note. And a, a structured note works like a bond, there's usually a payoff after 3 or 5 years where you redeem your principal. Maybe you spend $10,000 on day 1, 5 years later you get your $10,000 back and in-between you get a coupon. And this coupon is tied to the performance of another asset, often the equity markets. Why do I say there are biases in statistical problems here? Well these structured products are often designed to look better than they are. They tend to inverably back-test very well. So for example, any structured product that is long Apple. In other words, maybe what I'm saying here is that the coupon that you get increases as a function of the returns on Apple. Well, in that case, any structured product that is long Apple will presumably back test very well from 2000 onwards. Why is this? Well, this is a, a plot of the return on Apple. Actually, from 1985 up till today. But from 2000 onwards, I think, was around $7 at this point. And you see it's gone up to $700, almost $700 at 1 point, now it's below 500. But either way, there's been a massive run up in Apple over the last 10 years. And so, if you hold Apple in your structured product. Or rather, your the coupon that you received from your structured product depends on the performance of Apple. Well then, it 's going to look very good when you back-test that. There is also hidden risks that investors and structure products they're often exposed to often exposed to volatility risk we haven't reset much about volatility yet to the end of the course. Obviously the rose the area of pricing options which is on the binomial model but we didn't explicitly talk about volatility risk. We'll talk about that later in the course. Investor's structured products were often exposed to credit risk as well. You're relying on the credit of the issuer of the structured note. If you think this is insignificant, then there's two words for you. Those two words are Lehman Brothers. Lehman Brothers also issued structured notes, and sold them on to retail investors. Well, many people lost money when Lehman Brothers went under. So there is, there can be significant credit risk here as well. Another problem with structured products is that there is no secondary market available to them. So if you purchase a structured product or invest in a structured product. Then, you better be able to hold onto it until maturity. Because if you can't and you need to sell it. Before maturity, there would be no secondary market. The only person you'd be able to sell it to is the bank that issued it to you in the first place. They'll know you're looking to sell and you will not get a good price. So, there's a lot of problems with structured products maybe they've got 1 or 2 positive aspects, but overall they're, they're I think investors should be very careful about investing in them for all of the reasons I mentioned here. Finally, we're going to end with a, a toy example or a play example. It's called the Monty Hall problem. I don't mention it here. This, it's got nothing to do with finance, however, even just a couple of years ago was discussed quite a lot in the Financial Times. There were some articles and letters written to the Financial Times about this problem. It often raises a great deal of confusion. And so we'll discuss it here too, because it provides a great example of how a seemingly simple problem can confuse people. So it should serve to highlight the fact that while statistics and issues with averages and biases, don't require advanced mathematics, not advanced mathematics at all. It comes to be very confusing, and one does need to be aware of these issues in practice. So what is the Monty Hall problem? The Monty Hall problem is as follows. There are three closed doors. A goat lies behind two of the door. And one million dollars lies behind the other door. You don't know which door has the one million dollars and so you have to guess the door. If you guess correctly, you actually are going to get the one million dollars. If you guess incorrectly and you open the door with the goat behind it, then you're going to get the goat. Before the door is open, Monty Hall opens a different door. So what happens here is maybe you guess door number 1. At this point, Monty Hall comes along and opens one of the other two doors. And the door he opens will have a goat behind it. And this is always possible, because two of the doors have goats, so even if you've guessed incorrectly, then one of these two doors will have the goat. And so Monty Hall will open that door. Okay, so Monty Hall opens a different door. The door always has a goat behind it. And now he gives you the option to change your mind and pick another door. The question is, should you change your mind? So, just to be clear here, suppose you start off, you guess door one. Then Monty Hall opens door three and shows you a goat behind it. You now have the option of changing your mind. You can stick with door one or you can change and go with door two. The question is, should you change? Well, I'm not going to give you the answer to that question. I'll let you think about that. There is a definite answer. If you're not sure, let me give you a hint. Consider the situation where there are 100 doors. One, two, up to 100 doors, and that there's a goat behind 99 of these doors. The game plays, the game is paid as follows. You pick a door, and then Monty Hall opens 98 doors, all of which have goats behind them. Should you change your mind them? The answer to that question is the same answer to the question of the three door case.

## 008.Review of the Binomial Model and the Black-Scholes Model

### 013. Review of the Binomial Model for Option Pricing

In the next sequence of modules we're going to discuss equity derivatives in practice, but before we get on to discussing equity derivatives in practice, we're going to spend some time in this first module discussing and reviewing the binomial model. So we'll call again our pricing of a European call option in the binomial model We're going to assume an exploration of t equals to 3, a strike of $100 and a gross risk free rate of r equals 1.01. So the pay off of the option is given to us by the maximum of 0 and st minus k which is 100. So we see here the pay off of the option. Its 22.5, 7, 0, 0 and recall how we priced this option. We computed our risk neutral probabilities, which are given to us down here, q u and q d and then we work backwards in the binomial ladder. So for example the value 15.48 is the value of the core option at this node and is given to us by one over the risk free interest rate, 1.01 Times the expected value of the payoff of the option one period ahead. So we can work backwards in the lattice and price the option that way. Note also that when we price using this mechanism here, we're guaranteed to have no arbitrage by construction. And that's as long as D is less than or less than U. Remember that this is our new Arbitras condition in the binomial model. And it ensures that QU and QD are both strictly great in zero as we have down here. And of course what that means therefore is that in a price like this It's impossible to have an arbitrage because it would be impossible to get a payoff here and here, which is strictly positive, and have a value that's strictly negative here, for example. And that's because qu and qd are strictly positive. So this is how we price securities or derivative securities in the binomial model. We ensure that this condition is satisfied to ensure no arbitrage, and then we work backwards in the lattice as usual. And so we can continue on in this fashion. Compute the price of the option at every node, working backwards until we find an initial option price of 6.57 dollars. Now, we can also write the option price, or compute it in one shot. When one calculation, using this expression here. So, this just reflects the fact that the option price is the expected value under Q of the discounted payoff of the option. The discount factors won over are acute. And these are the probabilities, so for example, 3Q squared times 1 minus Q, while this is equal to 3, reduced to. Times Q squared times one minus Q to the power of three minus one. So this is a binomial probability, it counts the number of ways in which the stock price can go up into periods and fall in the third period. And in fact, this is equal to three here, and we know that there's three ways to get up to this point, so down one and up two, up one, down one, and up one, or up two and down one. So we can also basically combine all the one period probabilities into three period probabilities given to us by here, and compute the value of the option in this manner. We also discussed, trading strategies in the binomial model. So let's quickly review again what we did there. St is going to denote the stock price at time t. Vt denotes the value of the cash account at time t, without any loss of generality we assume that b0 equals one dollar, so that bt equals r to the power of t. So now we're explicitly viewing the cash account as security. We let xt denote the number of shares. Held between times t minus one and t. We also let yt denote the number of units that the casher account have between times t minus one and t. Then theta t equals x t y t as the portfolio held immediately after trading at time t minus one and therefore is known at time t minus one. And immediately before trading at time t. So, basically, if this is t minus 1, and this is time t, then we know theta t at this point, and this represents the portfolio that's held immediately after trading at time t minus 1, until trading at time t. So theta t is a trading strategy. We also discussed the value process associated with a trading strategy. It is defined to be vt equals xtst plus ytbt for t greater or equal to one. So this, if you like, is the value just before, trading, at time t. And a t equal to zero, well we can't talk about trading just before time t equal to zero, because time t equal to zero is the beginning of our horizon. So this is equal to the value of the portfolio just after trading at time zero. We also have a definition of self financing strategy. Self financing trading strategy is a trading strategy where changes in VT, are do entirely to trading games or loses, rather than the addition of withdrawal of cash funds. In particular self-financing trading strategy satisfies this condition here. And of course we know that this, is equal to the value. Of the portfolio, just after, trading at time t. So basically, what we're saying here, is that a portfolio, or a trading strategy, is self-financing. If it's value just before trading is equal to its value just after trading. And what that means is that no funds have been deposited or withdrawn at time t. In other words, it is self-financing - it finances itself. No new cash injections at time t, no cash withdrawals at time t. We also have the following proposition. We said if a trading strategy theta t is self-financing, so s.f. is self-financing, then the corresponding value process vt satisfies the following. So this is the profit and loss from the trading strategy between times t and t plus one, so if we like, this is our p and l At time t plus 1. It's equal to x t plus 1 times the change in the stock price between t and t plus 1 plus y t plus 1 times the change in the cash account between times t and t plus 1. So a valid question at this point is why do we care about self financing trading strategies. Well, we care for multiple reasons. In the multi-period binomial model, we can actually construct a self-financing trading strategy that replicates the payoff of the option, or, indeed, any derivative security. This is called dynamic replication. And the initial cost of this replicating strategy must equal the value of the options, otherwise there is an arbitrage opportunity. The dynamic replication price is of course equal to the price obtained from using the risk-neutral probabilities and working backwards in the lattice. Indeed this is exactly how we computed the risk neutral probabilities in the first place, we initially considered a one period model, and actually with the way we computed QU and QD was by replicating the payoff of the option at this node, and this node. So if we recall, we solve two linear equations and two unknowns. What we were doing at that point, is replicating the payoff of the security, in this one period model. So the risk neutral probabilities came from a replication, in this one period model, and you can actually splice all the one period models together, to construct a multi-period model. And use the replicating strategies in each single one period model to construct a dynamic replicating strategy for the option. And so over here we find the replicating strategy for a European option. This is the option we began the module with, so for example, we see up here Up here we see 0.802 times 107. 107 is the value of the stock. 0.802 is the number of shares that we hold in the stock immediately after trading at this point. So 0.802 times 107 plus minus 74.84 times 1.01, which is the value of the cash account at that node. Is equal to 10.23 here, the value of the option at that node. We could also check that in fact this is also equal to 0.598 times 107 plus Minus 53.25 times 1.01. Now where does this come from? Well, 0.598 is the number of units of the stock held between times 0 and time 1. So 0.598 is the value here, and the minus 53.25 is the value here. And what we're seeing is that up at this node, the value of the option is 10.23. So this must be equal to the value of the replicating strategy at this node, which is this value here, but this must also equal the value of 0.598 times 107 minus 53.25 times 1.01 And that's because the replicating strategy is self financing. This here is the value of the self financing strategy immediately before trading at this node and this value here is the value of the self financing strategy immediately after trading at this node and those two value must be the same and they must equal the value of the option which is 10.23. So that's the end of our review of pricing in the binomial model and replicating strategies in the binomial model.

### 014. The Black-Scholes Model

In this module, we're going to review and discuss and Black -Scholes model in geometric boundary and motion. Black and Scholes used this model way back in their paper in the early 70s to derive European coal and production prices. We're going to review them here. Because we're going to be using the Black-Scholes model in later modules, when we discuss the Greeks. The Greeks are the partial derivatives of the option price with respect to the model parameters. Such as the underlying security, time to maturity, the implied volatility, and so on. So, it's very important that we know what the Black-Scholes model is and that we know the assumptions behind the Black-Scholes model as well. Recall that the Black-Scholes model assumed a continuously compounded interest rate of, or they assumed geometric Brownian motion for the dynamics of the stock price. So that the stock price at time t, as little t say, is equal to the initial stock price times e to the mu minus sigma squared over 2 times 2, plus sigma wt. Where Wt is a standard Brownian motion. The stock price is assumed to pay a dividend yield of c, and it also assumed that continuous trading is possible with no transactions costs. And that short-selling is allowed. So, this is a geometric Brownian motion model. Here are some sample paths of geometric bounding in motion. So, these are simulated paths of the geometric bounding in motion between times t equals 0 and t equals two years. All three paths assume an initial stock price s is zero of $100. Wanting to keep in mind here is that the paths of the Brownian motion, while they're very jagged, they never jump. So in other words, you can't have a path with Brownian motion going like this, and then jumping down to another point here. So, the Brownian motion, and therefore, the geometric Brownian motion moves continuously in time. In comparison, here's an example of a binomial model with n equals 26 periods. And here, I have shown you three simulated paths of the stock price here. So there's a red, a blue, and a green path. Now, it might not look very similar to Brownian motion or geometric Brownian motion at this point. But imagine that instead of having 26 periods, that I have 260 periods. It's, or 2600 periods. Well then, in that case, these simulated paths are going to look much more jagged. And in fact, they will begin to look like these paths of geometric bounding motion. And indeed, that is one of the properties that we mentioned before about the binomial model. It can be viewed as an approximation to geometric bounding motion. And indeed, if I let the number of periods go to infinity, keeping the time horizon, T fixed. Then, the binomial model will converge in an appropriate sense to geometric bounding motion. We know in the binomial model that the the call option price is given to us by this expression here. It is equal to i equals, the sum from i equals 0 to n, n choose i times qu to the power of i times qd to the n minus i times the maximum of 0, u to the power of i and d to the n minus i, S0 minus k. And so, in our binomial model, this is actually the fair value. I'm ignoring the discount factor here, this should be an e to the minus or t in here. But I will omit it because there's not room in the page this, but assuming it's here. Then, this expression here is equal to the price of the call option in the binomial model. Now, we also mentioned before that we let the number of periods and we go to infinity, then we're going to actually get the Black-Scholes formula. In other words, this expression here will converge to the Black-Scholes formula here. And this Black-Scholes formula is arguably the most famous formula, the most important formula in all of economics and finance. I say arguably becasue I'm sure some people might disagree with that statement. But nonetheless, it's certainly a very important formula with widespread applications in practice. Now, a couple of things to keep in mind. Note that mu does not appear in the Black-Scholes formula. This is just analogous to the fact p, the true probability of an up move in the binomial model. Does not appear in the risk-neutral probabilities we calculated for the binomial model. Now, this is certainly surprising, at least initially. In fact, before we ever studied options pricing, if I was to ask you what parameters the call option price depends on, well, you might have said the following. You would have probably have said that the call price depends on the following. S0 the initial stock price, the strike K, the time to mature, T. Maybe there the risk-free interest rate for discounting, the volatility sigma, the dividend yield c, and maybe I'm guessing you would of said mu as well. And that's fair enough. The vast majority of us would also agree with you, and I've assumed that the call option price would also depend on the drift mu of the geometric Brownian motion. But in fact, it's not true. The call option price in the Black-Scholes model, actually depends is, only on the first six parameters here. So in fact, it depends on S0, K, T or sigma and c. So, mu does not appear in here. That said, imagine for a second that some really positive news came through to the markets about the stock price. So that mu became very large, maybe mu became very, very large so that the market was anticipating that the stock price will increase a lot. Well, what would happen in that situation is that many people would buy the stock immediately in anticipation of this good news. And therefore, the stock price would increase. So, the way I like to think about this is the following. The option price does not depend directly on mu, but I think it is fair to say that S0, the stock price, now does depend on people's views about the prospects of the stock. And so, I like to write this as S0 of mu. So, I do believe that mu does enter implicitly into the value of the call option. It enters implicitly in the sense that the stock price depends on mu. And so that, for me, is how to resolve this apparent contradiction that mu does not enter in the Black-Scholes formula. Black and Scholes obtain their formula using a similar replicating strategy to the strategy we used in the binomial model. However, they did not use the binomial model. The binomial model only came about a few years after Black and Scholes wrote their original paper. So, Black and Scholes actually did their replicating argument in the context of a geometric Brownian motion model. If you want to prize European put option, then you can simply use put-call parity, put call parity is given to us here. We've seen it a few times now. So, if we know the call price, then we can just bring this term over the right side to get the put price. As I mentioned on the previous slide, the Black-Scholes formula is arguably the most important and famous formula in all finance and economics. It is used extensively in the financial industry. It has also led to an enormous amount of acadmic work since it's publication. What we're going to do is we're going to see how this is used in practice. But we will emphasize now that the geometric Brownian motion model is not a good approximation of security prices. And indeed, everybody in the marketplace knows there are many problems with geometric Brownian motion and the Black-Scholes model. Nonetheless, it is used extensively and it is very important that people understand the limitations of Black-Scholes, and how it is used in practice.

## 009.The Greeks

### 015. The Greeks  Delta and Gamma

In this module, we're going to use the Black-Scholes formula to compute the sensitivity of option prices to the underlying parameters. The underlying paramenters include the underlying security price, the underlying volatility paramenter sigma, as well as the time to maturity. We're going to focus on to the so-called Greeks in this module. The delta of an option, and the gamma of an option. The delta of an option is the sensitivity of the option price with respect to the price of the underlying security. The gamma is the sensitivity of the delta with respect to the price of the underlying security. So we're going to discuss the delta and gamma in this module, and see how they behave as time to maturity changes and as the underlying security price changes as well. So recall the Black-Scholes formula for the price of a European call option with striking and expiration capital T. It is given to us by this quantity here d1 and d2 were given over here. And, capital N refers to, to the cumulative distribution function of a standard normal random variable. R is the risk free interest rate, c is the dividend yield, and the stock price St, is assumed to satisfy or follow geometric Brownian motion dynamics for Wt as a Brownian motion. The Greeks refer to the partial mathematical derivatives of a financial derivative security price with respect to the modern parameters. So I emphasize here that we've got the word derivative appearing in two different contexts. Sometimes we refer to it as security, a derivative security price, and sometimes it's going to refer to the mathematical derivative. So the Greeks are very important part of derivatives they're used an awful lot in industry. They refer as I said here, to the partial mathematical derivatives of the financial derivatives security price with respect to the model parameters. The first Greek we're going to consider is delta. The delta of an option is the partial derivative, again it's the partial mathematical derivative of the option price with respect to the price of the underlying security. The delta measures the sensitivity of the option price to the price of the underlying security. And so the delta for European call option price is given to us by this, iIt's delta C, delta S. Now, given the Black-Scholes formula over here, we can easily calculate delta C delta S. It comes out to be e to the minus c times capital T, times N of d1. Where if you recall, N is the cumulative distribution function for standard normal random variable. Now this follows from 5, but it actually requires a somewhat tedious calculation. If you just look at this expression, then it does indeed appear to be the case. The delta C, delta S is equal to e to the minus cT, N d1. And indeed that is what we have over here, but don't be fooled by this, actually there is a little bit more work involved, because d1 itself depends on S and therefore, d2 which appears over here also depends on this. So in order to calculate delta C delta S, we actually have to take derivatives within this N d1 term, and indeed within this N d2 term as well. If we do that, using the chain rule and so on, and then simplify everything down, it turns out that indeed we get delta C, delta S is equal to just this expression here. The delta of a European put option is also easily calculated, one way to do this is to use Put-Call Parity. So, if you recall, Put-Call Parity implies that P0, the initial price for a put option is equal to C0 plus Ke to the minus rt, minus S0e to the minus cT. And so therefore delta P, delta S is equal delta C, delta S minus e to the minus cT. So once we know the delta of call option, which is given to us here. We can easily calculate the delta for European put option as well, thatâs given to us over here. So here in this figure we have plotted the delta for a call option and a put option. So we've assumed, although it doesn't state it on the slide here, that the stripe is K equal to 100. The first thing to note is that, the call delta is always between 0 and 1. And the delta of a put is always between minus 1 and 0. Now, if you think about it, this makes sense because the payoff for a call option. So for a call, the payoff at time t is equal to the maximum of St minus k and 0. And the payoff for a put option at time T is equal to the maximum of K minus sT and 0. So a call price, a call option. The value of a call option clearly increases as S increases and that's why the delta of a call option is greater than zero. Similarly, the value of a put option will increase as S decreases, and that's why the delta of a put option is less than zero. Something else to keep in mind here is the following. Note, that as the stock price, the current stock price moves away from the strike. Then the delta moves towards either 1, or 0 in the case of a call option or towards minus 1 or 0 in the case of a put option. Now, what's going on here? Well, the easiest way to see why this is happening is the following. We know the value of the call option is given to us by the Black-Scholes formula. However, it is also true and actually, one can check this mathematically with the Black-Scholes formula. That the following is also true. It is equal to, and this is approximately and I'm ignoring interest rates and so on here. So thats why I'm using the approximent sign here, this is approximately equal to S minus K. If S is very large, and by very large I mean it is bigger than K, and much bigger than K. And indeed, it is so much bigger than K, that it becomes very unlikely that you wouldn't exercise the option at maturity. Likewise, it is equal to 0, if S is very small. And by very small, I mean S is much smaller than K. And in particular, it is small enough that the chance is of exercising the option are approximately 0. And then otherwise, where intermediate values of S, well, we can calculate 0 as been just a BlackâScholes formula. The important thing to note here is that delta C delta S is therefore going to be equal to 1 which is delta S delta S. For S very large, and it's equal to 0 for S very small, and indeed that's what we have here. It's 0 for S very small and a 10 towards 1 for S very large. The exact same argument also holds true for the put price. We know that the put price, of course, is given to us by the Black-Scholes formula of a put options. Well, we can also write this as being approximately, and again, ignoring interest rate factors and so on. This is approximately equal to K minus S, for S being very small. And that is approximately 0 for S being very large, and for intermediate values of S we would actually use the Black-Scholes formula. So I'll use BS for Black-Scholes formula, and here for intermediate values of S. The important thing to note though is for S very small, then I can use this expression here. And the derivative of this with respect to S is minus 1 and that's why I'm getting minus 1 down here. Similarly, for very large values of S, the put price is 0, or approximately 0. It's partial derivative with respect to s will be 0, and indeed that's what I have up here. So, we see that for extreme values of S, the delta of a call option is either 0 or 1 or approximately 0 over 1. And similarly the delta for a put option, is approximately minus 1or 0. Here, we've plotted the delta for three different European call options. The three options all have the same strike, k equal to 100. But they have different times to maturity, T equals 0.05 years, so approximately two and a half weeks. T equals 0.25 years, so approximately three months and T equals 0.5 years corresponding to the six month expiration. So we see here the deltas. Notice again, as in the previous slide, for S sufficiently large or small, the delta is going to go to 0 or1. But notice that they go to 0 or 1 faster for smaller time's maturity. So in other words, if we'd look at the case where t equals .05 which corresponds to two and half weeks. We see that S doesn't have to be too far away from the strike of 100. Before it's delta goes to 1 or 0 and that's because with only two and a half weeks to maturity. There's not much chance for the strike to either get into the money if its down low, or to fall out of the money if its up high. And therefore the delta quickly goes to 0 or 1 depending on whether or not the current stock price is below the strike or above the strike. And so that's why we see the red curve corresponding to T equals 0.5 years. Moving to 0 or 1 faster than the options with maturity T equals 0.25 years and T equals 0.05 years. And the same argument of course also implies that the T equals 0.25 year option. The delta of this also goes to 0 or 1 faster if you like than the option that T equals 0.5 years. Another way of seeing this is, looking at the delta, not as a function of the stock price as we did on the previous slide but as a function of time to maturity. So now we have time to maturity down here. So, 1 corresponds having one year to maturity, 0.5 corresponds to six months to maturity and 0 corresponds to having 0 time maturity. We've got three different options. We have at-the-money option, so at-the-money has K equal to the current value off the stock price, ITM stands for In The Money. So a 10% in the money option, means that S0, is equal to 1.1 times K. So therefore, it is in the money and the 10% out of the money, OTM option stands for an option with a strike that satisfies S0 equals 0.9 K. And so, what we are seeing in this case makes sense. We see that for the option that is out of the money, it is 10% out of the money, so 0.9k, the current stock price is less than K. So if the option were to expire today, you'd get nothing. And therefore, what we see is that the delta decreases, and it decreases toward 0 as the time to maturity decreases toward 0. Similarly, the in the money option, where S0 equals 1.1k. So therefore, remember the payoff of the option is equal to the maximum of ST minus K and 0. So if S, T, is equal to 1.1 k, well this would be equal to 1 K, so it's in the money. And what we see here is, that, as the time to majority goes towards 0, the delta of this in the money option, goes towards 1. And that be, and that is because as the time to maturity goes towards 0 would become more and more likely to exercise the option. And so the option behaves more and more like ST minus K, because this maximum is going to be equal to ST minus K as the time to maturity goes to 0. And of course, the partial derivative of this expression here is equal to 1 and that's why the delta goes to 1. On the other hand, down here in the 10% out of the money case well then this is going to behave like 0. If we're out of the money, it's going to behave like 0. As the time to maturity goes to 0 and therefore, the partial derivative of this will be equal to 0 and that's what we're seeing here. Perhaps the more interesting case is when the option is at the money and K equals S0. Well, then in that case, and I'm talking approximately here, the chances of exercising approach 50%. So, basically, there's a 50% chance of exercising and 50% chance of not exercising. And it turns out and it can be confirmed by differentiating the Black-Scholes formula, or calculate the expression we saw on the earlier slide that the delta actually approaches 0.5. The gamma of an option is the partial derivative of the options delta with respect to the price of the underlying security. So, the gamma measures the sensitivity of the option delta to the price of the underlying security. The gamma of a call option is therefore given to us by delta 2C delta S squared, and again it's somewhat tedious but it can easily be calculated using basic calculus. We can take the partial derivatives of the BlackâScholes formula to calculate the gamma. If we do that we will find a sequel to this expression here. E to the minus C time T, N of d1 divided sigma S square root T. How about the gamma of the European put option? Well that's easily calculated from put-call parity. So put-call parity is given to us here. So therefore, we can actually say that P, is equal to C, plus e to the minus rt times K, minus e to the minus cT times S. So we can therefore, see the delta 2p, delta s squared is equal to delta 2c delta s squared. Well, plus 0 minus 0 because the second partial derivative of this is equal to 0. And the second partial derivative of this with respect to S is equal to 0. So therefore, we see that, see that the gamma for put option is equal to the gamma for a call option. So, once we know the gamma for European call option we therefore we have the gamma for European put option. And in fact, you can see that this expression is always greater than are equal to 0. So the gamma for European options is always positive. this is due to what's called option convexity. Here is the plot of the gamma for European options is, as time to maturity varies. So, the gamma here is a function of the stock price, and we've got three different times to maturity. 0.05 years, 0.25 years and 0.5 years as we saw before. Notice that the gamma is steepest for the shortest maturity. So, in this case, for T equals 0.05 years i.e approximately two and half weeks to maturity, we see that the gammas are very steep around the strike of K equals 100. But we also see that it falls away to 0 much faster than the option when T equals 0.25 or the option when T equals 0.5 years. The reason is as follows, the delta of the European option when T equals 0.05 years, well, it's going to be a half, or approximately a half when the stock prices at the strike K. But as the stock price goes up, the delta's going to move towards 1 and it's going to move towards 1 much faster than the options with the higher time to maturity. Similarly, as the stock price falls below the strike of 100, the delta of the call option is going to move towards 0. And it's going to move towards 0 much faster than the delta of the options with times to maturity of 0.25 and 0.5 years. So this actually is, another, this plot here is just another way of looking at this plot. In the option, where T equals two and a half weeks or 0.05 years to maturity. We see that when S eqauls 100 that delta is approximately 0.5. But for small moves of, of S above 100 the delta quickly goes towards 1. And for small moves of S below 100 the delta quickly goes towards 0. And does it does much faster than the options with larger times to maturity. So we're seeing without the option which is two and half weeks to maturity has a much higher gamma than the option when T equals 0.5 years or T equals 0.25 years to maturity. And another way of looking at this is to now plot the gamma as a function of time's maturity. So one year to maturity, six months to maturity zero time to maturity. We see that for the option that's out of the money, 10% out of the money or 20% out of the money. I mean this would also be true for options that are in the money, the gamma of those options actually goes towards 0, it falls towards 0. And that's because as the time to maturity goes to 0, we know for sure we're not going to be exercising if we're out of the money. And we know for sure that we are going to be exercising if we're in the money. In other words, delta will be 1 if we're in the money, delta will be 0 if we're out of the money, and so gamma will be 0 in both cases. On the other hand, if we're dealing with an at the money option, where the current stock price is equal to K. So here is where s is equal to K for this blue curve. Well, then as the time to maturity goes to 0, we're going to find that our delta's equal to a half but that the gamma will actually be very, very large, and grow very large. And that's because small moves in s will move the delta to either 1 if S increases, or 0 if S decreases. And so we get a very large gamma for at-the-money options. I should mention as well by the way, that with all of these plots that we're looking at of delta and gamma market practitioners understand this behavior. They understand it at an intuitive level. They know how the delta of a colon European put option behaves, they know how the gamma of these options behave. And so, it's very important, that if you're working with options and practice, that you understand these figures and you understand why they behave, and look the way that they do.

### 016. The Greeks  Vega and Theta

In the last module, we saw Delta and Gamma. In this module, we're going to see Vega and Theta. Vega is the sensitivity of the option price with respective changes in the parameter Sigma, the volatility parameter Sigma. Whereas, Theta is the sensitivity of the option price with respective changes in the time to maturity. So, were going to discuss Vega and Theta in this module. We'll see how they behave as the function of the underlying security price and indeed as the function of the underlying time to maturity. It is very important that we understand how all of the Greeks work. And the Vega and the Theta are very important Greeks in practice. Again, here we have the Black-Scholes formula. Were going to use the Black-Scholes formula in this module to compute the Vega and Theta of an option. So, just remind yourselves, the Black-Scholes model assumes that the stock price follows a geometric Brownian motion, so that the stock price of time LT is equal to S0e to the r minus c minus Sigma squared over 2 times T, plus Sigma Wt, where Wt is a Brownian motion under the risk neutral probability distribution Q. So, this is the formula here. And you saw in the last module what the delta of an option is. We also saw what the gamma of an option is. And we can calculate the Delta and Gamma by taking the appropriate derivatives of this expression here, for a call option. Likewise, we could the same for a put option or if we liked, we could use put-call parity to compute those expressions for put options. So, first let's deal with the Vega. The Vega of an option is a partial derivative of the option price with respect to the volatility parameter Sigma. So, the volatility parameter is this parameter over here. Now, if you stop and think about it for a moment, you might think that as Sigma increases, the value of the option will increase. And indeed that is true. For example, the payoff of a call option, capital T, CT, is equal to the maximum of 0 and ST minus K. While it makes sense the Sigma gets larger, the value of the security will also increase. an easy way to see that perhaps is imagine that S0, the initial stock price, is much less than in, than the strike of K. Well, in that case, if Sigma is very very small, the chances of the stock price growing enough, so that the option ends up in the money, will be zero, or approximately zero. On the other hand, as Sigma gets sufficiently large, the probability that st will be greater than K will actually increase, in which case, the option value will be non-zero. And so it makes sense that the call price, the initial price of the option C zero, should be increasing in Sigma. And we will see that that is indeed the case. The Vega of an option is a partial derivative of the option price with respect to the volatility parameter Sigma. Vega, therefore, measures the sensitivity of the option price to Sigma. And using the Black-Scholes formula, it can easily be calculated. Vega is equal to Delta C Delta Sigma, which turns out to be e to the minus eT, s square root of time to majority times phi of d1, where phi is the probability density function of a standard normal random variable. Now, we can also compute the Vega for a European put option by using put-call parity. So, this is put-call parity here. Remember, so it actually implies. So, it implies that the put price is equal to the the call plus e to the minus rt times K minus e to the minus cT times S. And so, therefore, we can actually compute Delta P, Delta Sigma, we see it's equal to, well Delta C, Delta Sigma. That's the first term here. And then these other two terms don't depend on Sigma at all. So, it's plus zero minus zero. And so, we see Delta P, Delta Sigma equals Delta c, Delta Sigma. And so, the Vega of a European put option is the same as the Vega of a European call option. Here's a question for us. Is the concept of Vega inconsistent in any way with the Black-Scholes model? And the answer is yes. If you recall, the Black-Scholes mo-, model assumes that St, the stock price of any time t, is equal to S zero e to the Mu minus Sigma squared over 2 times t, plus Sigma times Wt, where Wt is a standard Brownian motion. Mu and Sigma are constants in this model. They are not assumed to change. And that indeed was the assumption of the Black-Scholes model. They assumed continuous trading. They assumed that there were no transactions, costs, and that short sales were allowed, and that borrowing or lending at the risk free interest rate, or was also possible. Using these assumptions, they constructed a self-financing trading strategy that replicated the payoff of the option, and that is indeed how they are paying the Black-Scholes formula. Nothing in their model allowed Sigma to change, Sigma was a known constant. And yet when we're talking about Delta C, Delta Sigma, we're implicitly recognizing the fact that Sigma can change. And indeed, in the marketplace, Sigma does change. So, in that sense, the, While, mathematically, one can always define Delta C, Delta Sigma, there's no problem with that. Within the economics of the Black-Scholes model, it isn't consistent to talk about Sigma changing. Because we ob-, we obtained the Black-Scholes option price under the assumption that Sigma could not change. Here are some plots of Vega for options, for European options, as a function of the stock price at time t equal to zero, and as the time to maturity varies. So, we've got three different times to maturity T equals 0.05 years, T equals 0.25 years, and T equals 0.5 years. There are probably two things to notice first. The first observation is as follows. Note that if I pick any one of these options, the Vega goes to 0 as the stock price moves away from the strike, which was $100 here. So, what is going on here. Well, it's very simple. So, again re-, returning to what we did in previous modules, we know the following. Let's take a call option as our example. . We know that the call option price[BLANK_AUDIO] will be approximately equal to, and again, ignoring interest rate factors and so on. It would approximately be equal to S0 minus K, for S0 being very large. And by very large, I mean much larger than K. And sufficiently large, that I'm almost certain I'm going to be exercising the option. It will be equal to zero for S0 being very small. And very small here means much smaller than K. And indeed, small enough that the chances of exercising the option are approximately zero. Well, we can see here that Delta C, Delta Sigma, therefore, must be equal to 0 in this situation because the partial derivative of S0 minus K with respect to sigma is 0. And also 0 down in this situation as well. And therefore, for S0 very large, which is up here, or S0 very small, which is down here, we see that Delta C, Delta Sigma goes to 0. And indeed, that's what we see for each of these three options. So, that's the first observation. The second observation, so let's call this observation 1. The second observation here is that the Vega[BLANK_AUDIO] increases in time maturity capital T. So, we see that the option where t equal .05 years, the blue curve here, is larger than the Vega for the option where t equals 0.25 years and so on. And in fact, this is not surprising because if we go back to the Black-Scholes formula. Over here, we can see that every place where Sigma appears, we find it together with a square root of T. Or if you like, when Sigma squared appears in the Black-Scholes formula, I see a T appearing. So, I've got Sigma square root T or sigma square root T appearing here. So, basically, every time I see a sigma, I'm multiplying it by the square root of T. And, therefore, the impact of a change in Sigma, i.e. the Vega, it would be amplified by the square root of T. And it is, therefore, the case. And, by the way, maybe I should have mentioned or was assumed to be equal to c, was assumed to be equal to zero in these plots here. We can see that the blue curve has, is a factor of square root of 2, which is approximately equal to 1. 4, times higher than the green curve. And the green curve is a factor of the square root of 5, which is approximately equal to 2.2 something, greater than the red curve. And that's no surprise because 0.5 years divided by 0.25 years is equal to 2. So, the square root of 2 is approximately 1.4. And, indeed, we see the green curve reaches a peak of 20 here. 1.4 times 20 is 28. And that's roughly the peak of the blue curve. Likewise, down here, we have the red curve reaching maybe a peak of approximately 8 and a half or 9, 8 and a half or 9 multiplied by 2.2 brings us up towards approximately 20. So in fact, this behavior is entirely predictable. The, the change, the, the Vega for the option is magnified by the square root of the time to maturity. Another way of saying that is, another way of seeing this is by looking at this figure here, where we have plotted the Vegas for three options. And not the money option. A 10% out of the money option and a 20% out of the money option. And in all three cases, we see that the Vega converges to zero as the time ot maturity goes to zero. And the, this would also be true if i showed a 10% in the money option or 20% in the money option. The next Greek I want to talk about is the Theta of an option. The Theta of an option is the negative of the partial derivative of the option price with respect with time to maturity. So, therefore, mathematically speaking, Theta equals minus Delta c, Delta t. And that's for a call option. We can also compute it for a put option, if we actually go ahead and do the mathematics, compute the derivatives of the Black-Scholes formula. We will find that theta's equal to this long expression here, where, phi is the standard normal PDF. So, if you recall, N is the standard normal CDF and phi is the standard normal PDF. Why do we take the negative? Well, we take the negative because in practice, time goes forward. So, in practice the time to maturity of an option decreases. Suppose I have an option right now which is 200 days to maturity. Well, then tomorrow, it would have 199 days to maturity. So, therefore, the time to maturity is always decreasing in practice. And so, it's conventional to take Theta to be the negative of the partial derivative of the option price with respect to time to maturity. Here are some figures. Again, we see Theta for European call option as a function of the stock price. K was equal to 100 in these examples. We assumed r, the interest rate, and indeed c, the dividend yield, was equal to 0%. We plot the Theta here for 0.05 years, 0.25 years and 0.5 years. Notice, number one, that the Theta is negative in all cases. Now, in general, Theta will be negative for European call and put options. It's, it's not always the case that it's negative. There are certain situations where theta could be positive. But in general, most of the time, theta is negative. In other words, when you hold a European call or put option, you lose a little piece of money every day if the underlying stock price does not change. That's what Theta means. Remember Theta is equal to minus the partial derivative of the call option price with respect to time to maturity. So, as the time to maturity decreases, I lose a little piece of the value of the option, the Delta c decreases. Again, another observation, is that as the stock price moves away from the current strike of K equals 100. We see that the Theta goes toward zero. And again, we can use our earlier examples to see why this is the case. We know, and this time we'll say in the case of we have a call option here, so we'll stick with the call option, in the case of a call option, we know that c0 will be approximately equal to, as zero minus K, if S zero is much bigger than K or very large, and it's approximately equal, if S zero is much smaller than K. In both cases, the partial derivative of this term, with respect to capital T, the time to maturity is zero. Likewise, the partial derivative of this term, zero, with respect to time to maturity capital T, is also zero. And so, that's why we see, for large values of S and for very small values of S, we see that the partial derivative with respect to time to maturity is zero. And that's why all of these curves approach zero as S moves away from the strike, K. Why is the theta most negative around the strike for short times to maturity? That is, for time to maturity of two and a half weeks of 0.05 years. Well, one way to see that is the following. Suppose I've just got one day to maturity. So, I've got one day. So, T is equal to one day to maturity. Well, then, and suppose the stock price is equal to K. So, I'm at the money. This means I've got one day to maturity. If the stock price increases, I'm going to exercise the option and make some money. if the stock price decreases over the next day, I'm not going to exercise the money. So, the option value will be none-zero at this point because over the next day, there is a chance that the stock price will increase and I'll be exercising and make me some money. However, imagine rolling time forward one day without changing the stock price. Well, in that case, this is going to go to zero days to maturity. That's zero is still equal to K. And now the option expires worthless. So, when there's just one day to maturity, the Theta is larger, larger and more negative, because I have more to lose over the next day than I would if there was one year to maturity. If there was one year to maturity, I would have 365 days left. Moving time forward, one day isn't really going to impact the value of the option very much at all. However, when I've just one day left to maturity, that one day encapsulates all of the value of the option when I'm at the money. And if I roll time forward one day without changing the stock price, I'm going to expire worthless and, therefore, receive nothing. So, the Theta becomes more negative and peaked around the strike as the time to maturity decreases towards 0. And on this plot, we see the Theta for European put options as a function of the time to maturity. We've plotted here three different option curves. One for not the money option, the blue curve, and the green and red curves for 10% out of the money and 20% out of the money options, respectively. So, in fact, just so we're clear, a 10% out of the money option, in this case, it's a European put option. So, 10% out of the money option will have K being equal to 0.9 times S zero. So, the strike is below the current stock price. And, so, currently it is out of the money. For the 20% case, we will have K equal to 0.8 times S0. So, in these cases, we see this out of the money options that they're Theta is decreasing. Let's take this green curve here. We see Theta is decreasing for a while, that's negative and decreasing. But beyond the certain point, it becomes, it, it turns around and moves toward zero. And that's because it's becoming increasingly unlikely that the option will be exercised. It's value is moving towards 0, and so its Theta will be 0. The partial derivative of 0 with respect to t is equal to 0. So, at this point, the value is moving towards 0 because it's becoming less and less likely to be exercised. The red curve, corresponding to a 20% out of the money option, has actually be turned earlier than the green curve because its 20% out of the money is further away. And so, it's becoming less and less likely to be exercised at an earlier point than this green curve here. And, in case you're wondering, we can easily create these plots, just by using this expression here. This is an expression, so for those of you who are comfortable with Code in R or Matlab or Python. Or indeed in Excel, you could create a table of values for t. Create the, Thetas for these different T values and create a plot. You can easily create these kinds of curves that I'm showing you.

## 010.Risk Management of Derivatives Portfolios and Delta-Hedging

### 017. Risk-Management of Derivatives Portfolios

In this module, we're going to spend a little bit of time discussing how to risk-manage option portfolios. We're going to briefly discuss two methods. First method is based on the Greeks. We're going to use a Delta-Gamma-Vega approximation to hedge against relatively small changes in the underlying security price and the volatility parameter signal. However that method will not work well when these changes in the underlying security price and the volatility parameter are substantial. In that situation, we would use scenario analysis instead and we, we will spend a little bit of time discussing scenario analysis as well. Once again we have here the Black-Scholes formula. I just want to emphasize that the Black-Scholes formula gives us a closed form or analytic expression. For the price of European call and put options in the Black-Scholes framework. That is where it is assumed the stock price follows a geometric Brownian motion with these dynamics where we can trade continuously in time with no transactions costs, and where short selling of the stock is allowed. So Black-Scholes using a replicating argument that we also used in the case of the binomial model showed how to compute the prices of call input options in this framework. And indeed they came up with this, the Black-Scholes formula. In early modules, we saw how we can compute the delta. We know that delta is equal to delta c, delta s. We also saw how to compute gamma. Which is equal to delta 2c, delta s squared. We also saw how to compute vega. So vega was equal to delta c, delta sigma. So these are just partial derivatives of the option price, with respect to the parameters s, and sigma. We also saw indeed how to compute theta which is equal to the negative of the partial derivative of the option price with respect to time to maturity. So it's very straightforward to compute these quantities just by taking derivatives appropriately inside here. And indeed, in the case of a put option, we can also compute these expressions very easily sometimes simply using put call parity. In fact, by put call parity, it is easy to see that the gamma and vega of call and put options are identical. So at this point, we have the Black-Scholes formula and I'm going to assume that we know how to calculate these quantities as well. These are easy to calculate programatically one can do them in Excel, or indeed in Or, Python in any programming language that you like. Let's consider some approximations. We're going to view the option price as a function of s and sigma only. Then the simple application of Taylor's Theorem. Now Taylor's Theorem is a theorem I hope you saw in your undergraduate mathematics class. If you haven't don't worry about it. What it does is the following. It enables us to see what happens to the call auction price. For small changes in s and small changes in Sigma. In particular, suppose we let s go to s plus Delta s, so Delta s represents the change in the underlying stock price. And sigma goes to sigma plus delta sigma. So delta sigma represents the change In sigma, the volatility parameter. Well then Taylor's Theorem allows us to say that this option price at the new parameters, s plus delta s and sigma plus delta sigma is approximately equal to the option price at the original parameters s and sigma plus delta s times delta c delta s. Plus a half delta s squared plus delta 2c delta s squared plus delta sigma times delta c delta sigma. So we recognize that delta c delta s is equal delta. Delta 2c delta s squared is equal to our gamma term and delta c delta sigma is equal to our vega term. So we therefore get that the P&L, remember the P&L would therefore be this term minus c, s sigma so I will bring this over to this side and I get the P&L on the left hand side, P&L standing for Profit and Loss. So P&L would be with the delta times the change in the stock price, plus gamma over 2 times the change in the stock price squared plus vega times delta sigma. And so what we have here, is that the profit and loss on the option price when the stock changes by an amount of delta s and the volatility changes by an amount delta sigma. When that profit and loss is equal to the, a delta component, which is this, a gamma component, which is this, and a vega component which is this. Now I should mention as well, if I wanted to I could also include time to maturities, another parameter. So I could have t and t plus delta t in here. And then I would also have a theta component, so that's perfectly fine as well, and indeed people do this. But to keep things simple, I just want to stick with delta, gamma and vega here. And if fact sometimes people just work with delta and gamma. So if I assume delta sigma equals 0, I will obtain a delta-gamma approximation. So, the p now, in this case, will just be due to delta and gamma. And, this is often used, for example, in historical Value-at-Risk calculations. Now, we go, won't go, anymore, into, into Value-at-Risk, for options portfolios here, but I know you've seen Value-at-Risk elsewhere in the course. Now something else I can do is I can actually go back to this expression here. And just do some simple algebraic manipulations to get the following. I can also say that the P&L is equal to delta s times delta s over s plus gamma s squared over 2 times delta s over s all to be squared, plus vega times delta sigma. Now I can write this. So this is my return, delta s over s, is the return on the stock price. I'm going to call delta, this is, this delta here is delta c delta s. So, delta times s, is often called the esp, standing for equivalent stock position or the dollar delta. Delta s over s all to be squared well this is my return squared and so this quantity here gamma s squared over 2 is sometimes called dollar gamma. So dollar gamma is this expression here. and what I should emphasize, is that in practice, market participants, option traders, or just investors who happen to invest in options, as well as underlying securities, stocks, and futures and so on. What they will do is they will often know what the ESP is of their option. So they will often know, so they will typically know the ESP , the equivalent stock position, they will know their dollar gamma and they will know their vega. And knowing these quantities will help them understand how their portfolio behaves as the underlying stock moves and as the volatility parameter's sigma changes. So, for example, let's consider the following situation. Suppose the ESP, the equivalent stock position is equal to 1 million dollars, now this might come about because maybe S is $100, delta's a half so a half times 100 is 50. But maybe I've got thousands of these options, and altogether they combine to give you the ESP of $1,000,000. Maybe my dollar gamma is equal to let's say 500k, $500,000. And supposed my vega is equal to $100,000 for 1% change in sigma. Now suppose delta s over s is equal to 10%. So, suppose the underlying stock has increased by 10%, may be this is over the next day and suppose sigma goes to whatever the previous value was plus 2 percentage points. Well, then I can use this expression and these quantities here to approximate my P&L. So, in this case, my P&L, my Profit and Loss on my option position will be approximately equal to my ESP which is 1 million dollars times 10%. So it's going to be 1 million times 10%. Plus, my dollar gamma, which is 500k times the return squared. My return is 10%, so 10% squared is 1%, plus my vega which is 100k, per 1%. So it's plus 100k and volatility might doubt, the sigma has changed by 2% so that's times 0.02 and this is equal to the, let's see, it's a 100k plus 5k plus 2k. So that's equal to 107k. And, of course, I should mention that one can get very different options, so one can get options with very different ESP's gamma's, and vega's. What also interesting is that people have used this not just for a single option, but for an entire portfolio of options. What can have an entire portfolio, it can compute the ESP for the entire portfolio, and the dollar gamma for the entire portfolio and indeed the vega for the entire portfolio. And so one will then understand there maybe represent the exposure of the portfolio in terms of the ESP, the dollar gamma and the vega. Typically of course they will also know the data for the portfolio and maybe some of the other Greeks as well, that we have the time to go into. So, the Greeks are very important. People understand their sensitivities, their risk-sensitivities, in terms of these Greeks. Now, as I've shown you here, understanding your Greeks and typically writing them in terms of quantities like ESP Equivalent Stock Position or dollar gamma and so on. Here's a very good idea and market participants do use these approximations all the time, but it is also worth pointing out that for very large moves in s or sigma can, can break down, it will no longer work. And the reason that it will no longer work It's because Taylor's Theorem isn't valid for very large moves in s or sigma. Now I won't go into any further details on this but you have to understand that Taylor's Theorem it gives you a good approximation for relatively small changes in s and relatively small changes in sigma. If you get very large moves or extreme moves, then these approximations break down, and they aren't very accurate. In that case, what people often use is scenario analysis. So, here's one slide giving you an ideal of what is going on with scenario analysis. So what I've shown here, is the following, it's an example of a pivot table, that I've constructed in Excel. If you don't know what a Pivot table is when then you can use the help facilities in Excel to figure out what they are and how to use them, they can be very useful in manage situations. we're not going to say anything more about them here. what we've assumed here is that we've got an options portfolio, the options portfolio is written on the s and p 500s, we've got lots of options and maybe we've also got futures in our portfolio. And what we done is we've considered two stresses. We've stressed the underlying security price. In this case, the underlying security price, as I said, is the s and p 500. And down on this axis we're considering stresses where the s and p 500 falls by 1% or it falls by 2% or 5% up as much as 20%. We're also considering situations where the s and p 500 increase by 1%, 2%, 5%, 10%, and 20%. Across the x axis up here, we're considering stresses and volatility. So this vol here refers to the sigma parameter we've been discussing. So this is the sigma that enters into the black shoals formula. What we're doing is we're considering sigma going to sigma plus 1 percentage point, sigma plus 2 percentage points, up to sigma plus 10 percentage points. And down to minus 10 percentage points as well and then in anyone one cell we can see what the profit or loss is on the portfolio at that particular scenario. So for example down here, this corresponds to the s and p increasing 5%, and implied volatility's increasing 5 percentage points. Well in that case I'm going to see a loss of 4, 3, 2, 2. Now, if this is in units of dollars, then it represents $4,322. But maybe it's in units of 1 thousand, in which case it represents a loss of 4.3 million dollars. So, this is an example of a scenario analysis. People do this all the time in finance with derivatives portfolios. To stress their risk factors, in this case the risk factors are the prices of the underlying security and the volatility of the options. And then they reevaluate their portfolios in these new scenarios and compute the profit or loss in these scenarios. So this is an alternative approach to risk management. It gives you a more global approach than the approach given to us by the Greeks that we saw in the previous slide Where we just use delta, vega, and gamma, and theta and so on, to analyze the risk of small changes in the underlying parameters. Here we're looking at much larger changes in the underlying parameters, either the volatility, or the underlying security. And then we figure out what the P&L is in these scenarios. It is important to choose the risk factors and stress levels carefully. It's pretty straightforward to do this with a vanilla options portfolio. By vanilla I mean where the options are pretty standard or straightforward like European call options. But if you're trying to do scenario analysis with very complex portfolios, portfolios containing complex derivative securities, understanding what these risk factors are can be a challenge in and of itself. Moreover, figuring out what the appropriate stress levels are, and by stress level, I mean a 2% or 10% or 5 volatility points, they're examples of stress levels. So, with very complex derivatives portfolios, figuring out what appropriate stress levels are can also be very challenging. And if you don't believe me, you can just think of what went down during the financial crisis when people were working with CDOs and Asset Backed Securities and ABS-CDOs and so on. In these situations the portfolios were very complex. With many many risk factors and understanding how to do scenario analysis with these portfolios was more or less impressive. And this is one of the many reasons that explain what went wrong during the financial crisis and the difficulties with these exotic structure products during the financial crisis.

### 018. Delta-Hedging

In this module, we're going to discuss Delta-Hedging within the Black-Scholes model. Delta-Hedging allows to exactly replicate the payoff of an option. When we Delta-Hedge, we're following a self-financing trading strategy whose value at maturity is exactly equal to the value of the derivative that we're trying to replicate. So Delta-Hedging is possible, we're going to see how it works within the context of the Black-Scholes model. However, in practice, we cannot Delta-Hedge exactly datas because we cannot trade at every instance in time. And, because we actually don't know the true model and the true perimeters of the model that generate the security prices. So in practice, Delta-Hedging can only be done approximately. We're going to discuss Delta-Hedging in this model. Recall that the delta of a European call and put option, respectively, are given by the following terms here. So, Call-Delta is e to the minus cT N d1, and then using Put-Call Parity, we can easily see that the Put-Delta is given to us by the Call-Delta minus e to the minus c times T. Where T is the maturity of the option and k is the strike of the option. c is the dividend yield, r is the risk free interest rate, and S0 is the initial stock price. In the Black-Scholes model, an option can be replicated exactly by following a self-financing trading strategy. Now, just remind ourselves, first of all, what is the Black-Scholes model? Well, remember in the Black-Scholes model we've seen that the stock price follows the geometric Brownian motion. So, that means that St is equal to S0e to the mu minus sigma squared over 2 times t plus sigma times a Brownian motion Wt. So, this the geometric Brownian motion process that the security price follows. We also assume there's a risk free interest rate r, a dividend dlc. We assume that continuous trading is allowed. So, cts stands for continuous trading. And that short sales are also allowed. And of course, we also assume that we can borrow or lend at the risk-free rate of r. So this is the Black-Scholes model, here, also I should have mentioned, if it's implicit assumptions continues trading that there are no transactions costs. Another is we can trade continuously without having to pay a charge or fee for trading. So, no transactions costs. Alright. So, in the Black-Scholes model, an option can be replicated exactly by following a self-financing trading strategy. Now, we did this in the binomial model. So, if you follow the argument in the binomial model, you'll realize that we can replicate any security in the binomial model. Now, if you also recall, we mentioned that the binomial model can be viewed as an approximation to geometric Brownian motion. And indeed, as the number of periods n goes to infinity. We argued, or at least, we said that the binomial model converges in an appropriate sense to geometric Brownian motion. And therefore, it should not be surprising that it is also the case in the Black-Scholes model that every security can be replicated exactly by following a self-financing trading strategy. When we execute this self-financing trading strategy in practice, we often say that we are delta-hedging the option. And I will explain where this terminology delta-hedging comes from in a moment. But of course, and as I just said in the previous slide, the Black-Scholes model assumes we can trade continuously. However, this is not feasible in practice. In practice, you cannot trade continuously. And indeed, you have to pay transactions cost when you do trade. So what people do instead is they trade periodically, and in particular they hedge periodically. It also means we can no longer exactly replicate the option payoff. In fact, the best that we can do is hope to approximately replicate the option payoff. Anyway, let T be the option in exploration, so if you want to understand delta-hedging a margin that we are trying to replicate pay off of a call option. So remember, the pay off of the call option C capital 'T' is equal to the maximum of 0 and ST minus k.' And of course, we can price this at any time little t via the Black-Scholes formula. So, what we're going to do is, we're actually going to set a fixed number of times. T0 up to t little n. T0 is time 0. T little n is time capital T. We'll assume that Delta t is the length of any of these intervals, so Delta t equals ti plus 1 minus ti for all i. And what we're going to do is we're going to say V0 of S0 Sigma0 is the initial value of the option, so you can think of V0 of S0 Sigma0 as being the Black-Scholes price of the option. So we often write it as S0 or Ck sigma, and we call it sigma 0 now and t. So V0 of S0 sigma 0 is the Black Scholes price of the call option at time 0. And we're emphasizing here that it's going to depend on S0 and sigma 0. The other parameters over here we'll keep implicate, but we wont mention them explicitly. So what were going to do is, were going to define the following trading strategy. Where Vi plus 1 is going to be the value of the trading strategy at time I plus one. So we're going to see Vi plus 1 equals Vi plus delta i. So in the case of our call option, delta i is equal to at the minus c times T minus Ti times nd1. So, it's delta i times Si plus 1 plus Sic delta t minus Sic, plus another term over here. So what are we doing here? Just looking at equation one here, it's not really clear what's going on. So let's try and do this. So, at time Ti, we have, at time Ti, we have Vi dollars. So this is the value of the trading strategy at time i. So what we're going to do is we are going to hold delta i units of the stock at that time. And we are going to put the remainder of our portfolio value, which will be Vi minus delta i times Si into the cash account. So if we do that, then at time Ti plus 1. What will we have? Well, we can see we are going to have Vi. So Vi is what we have at the previous period at time Ti. And remember, we hold delta i units of the stock at time Ti, and we're going to hold them until trading at time Ti plus 1. And therefore, we're going to make or lose delta i times the value of the security at time i plus 1 minus the initial value of the security, which will be Si. So, the value of the security of time I plus 1 will be Si plus 1 Plus any dividends we get. So what we're doing is here is we're assuming that we're going to get a dividend yield of c, so over the period delta t, we're going to get a dividend yield of c delta t times Si. So this represents the dividend payment in the period ti to ti plus 1. So , the total value of the, of the position at time i plus 1, or ti plus 1. Will be si plus 1 plus the dividend that we obtain. Therefore, the gain on the stock position will be this quantity here minus si. Likewise, we would have invested this quantity into the cash account at time i or time ti. And therefore, we will earn interest at the risk free rate between time ti and t plus 1 according to the rate of or. And so, we would obtain all of this quantity from our position in the cash account, time ti plus 1. Therefore, the value of the strategy times i plus 1 will be vi or initial value. Plus the gain or loss from holding delta i into the security, plus our position in the cash account. So if delta iSi is less then vi, we will be investing money in the cash account and earning some interest. If delta iSi is greater than vi, you would actually be borrowing from the cash account. This term would be negative, reflecting the fact that we owe interest to the cash account or to the bank that lent us the money. Now I mentioned here that this is a self-financing trading strategy and it's almost implicit that it is self-financing. And that is because we're seeing that the value of the portfolio time i plus 1 is equal to the value in the previous period, vi plus the gains or losses from trading. These are the gains or losses. This is the gain or loss from the stop position. This is the gain or loss from the cash account. Clearly, if you look at this, we're not injecting any new money into the strategy at time i plus 1, nor are we taking any money out. So in fact, the way we have defined this, value process for the trading strategy, it is actually a self financing trading strategy. So at time, t plus 1, Vi plus 1 equals Vi plus gains or losses from trading. And these gains or losses are given to us in x equation 1 here. So this is a self-financing trading strategy. Now, it is a particular type of soft announcing trading strategy. Because the number of units of the stalk, we hold the time I, is equal to the delta of the option. Remember delta I is short on for the delta we saw on the previous slide so it's this for a call option. It would be this for a put option. So we're going to hold that many units of the underlying security, at time i. So when we adapt this strategy, this self-financing trading strategy, we are delta-hedging the options. And if we let delta t go to 0. Remember, what we have is, we've got a time horizon, a capital T. Maybe capital T is 1 year, or 6 months, or 3 months. And we're breaking this down into a number of subperiods, t1, t2, t3 and so on up to tn minus 1. And the length of each interval here is delta t. So what were saying is, if we let delta t go to 0, in other words, if we let n go to infinity then this self-financing trading strategy will actually replicate the option payoff at time capital T. This is in fact what Black and Scholes showed in there original paper. Otherwise, if we don't let delta t go to 0, but we have to keep it fixed maybe delta t is equal to one day or one week. Then in that case we're only going to replicate the payoff of the option approximately. So Vn is equal to the option payoff at the time t approximately. This by the way assumes that the stigma perimeter that we use to price the option is. Correct. And this is why, returning to the previous slide, I emphasize the dependence of the option price on sigma 0. The value of sigma that we're using within the Black-Scholes formula over here. In practice, we can't expect to know sigma 0. We can only guess what the true volatility is, what the true volatility parameter is. So in fact, we can only expect to replicate the strategy exactly if we know the true sigma 0 and we let delta t go to, to 0. If we assume the wrong sigma 0, then V0 and all the delta i's will be wrong. Remember, V0's the initial value of the option, the call option in this example that's given to us by the Black-Scholes formula. But if we use the wrong sigma 0 inside here, we're going to get the wrong price. Not only will we get the wrong price, but all of these delta i's will also depend on sigma 0. If you look to the previous slide, you'll see that, in the case of a call option or delta i is equal to this expression here. And d1, as we see here, is a function of the sigma parameter. So if we get the wrong sigma, we're going to get the wrong d1. And we're going to get the wrong delta as well. And so, therefore, if we get the wrong sigma 0, we're going to have the wrong value v0, and we'd have the wrong delta I's. And so, we will not be able to replicate the option exactly even if delta t went to 0. In practice, as I said, we can't let delta t go to 0, that's because we don't trade continuously in practice. So delta t would be fine, maybe one day or half a day or one week and we can only hope to guess the right value of sigma. So what that means in total is that, we can't exactly replicate an option. We can't hope to replicate an option in practice, because we don't know sigma. And in fact, the true dynamics of the security prices don't follow geometric Brownian Motions or they are not geometric Brownian motions. So the concept of dynamic replication is really only a theoretical concept. That said, it is useful in practice, because we can hope to use these ideas to replicate option prices approximately, and replicate other, derivative payoffs approximately. Remember, this strategy here is self-financing. So we can actually always follow this strategy, we just have to guess what the correct sigma is to use inside N of d1 to get the correct delta. And we also hope that the initial value price was calculated correctly, i.e., that we used the right sigma 0. If we do that, we can hope to replicate the option approximately and sufficiently accurately for risk management purposes.

## 011.The Volatility Surface

### 019. The Volatility Surface

We're now going to discuss the volatility surface. If the Black-Scholes model was correct, the volatility surface would be flat. In practice, it is anything but flat. And we're going to see, in this module, what the volatility surface is, how it is constructed. And we're also going to see some of the arbitrage constraints that restrict the volatility surface on the shapes it can take on in practice. The Black-Scholes model is a very elegant model. But for several reasons, it does not perform very well in practice. The first reason is that security prices often jump. However, this is not possible with geometric grounding motion. A second reason is that security price returns tend to have fatter tails than those implied by the log-normal distribution. By fatter tails, I mean the fact that extreme returns are more likely in practice than you would expect if the security prices actually had logged normal distributions as implied by geometric Brownian motion. Returns also are clearly not IID in practice. So, if I'm to break any time period, if I was to break any time period up into finite intervals of time, then if the security price follows a geometric Brownian motion, then log returns would be IID. And this is clearly not the case in practice. By the way, if you want to learn more about geometric Brownian motion, there is a module that we have recorded on geometric Brownian motion that can be found on the course platform. Anyway, for all of these reasons, we know that security prices in practice do not follow geometric Brownian motion. And market participants are well aware of the fact that the Black-Scholes model is a very poor approximation to reality. They've certainly known this since the Wall Street crash of 1987. I will return to discussing the crash of 87 in a, in a, in a while. But it was, maybe, after this crash that for many people it became clear that the assumptions of geometric barrier motion did not hold and that, in practice, people would have to adjust the Black-Scholes model in an appropriate way in order to trade options. All of that, having been said, we have to point out that the Black-Scholes model and the language of Black-Scholes is still pervasive in finance. Most derivatives markets use aspects of Black-Scholes to both quote option prices as well as to perform risk management. So, even though the Black-Scholes model is clearly not a good approximation to market dynamics, it is still very necessary to understand the Black-Scholes model if you want to understand derivatives pricing and how derivatives are used in practice. The incorrectness of Black-Scholes is most obviously manifested through the volatility surface. This is a concept that is found also throughout derivatives markets. The volatility surface is constructed using market prices of European call and put options. Now they can also be constructed using American option prices, but it's a little trickier. So, we're going to stick with the case of European call and put option prices. So, these include, for example, options on foreign exchange and options on the most commonly traded market indices, such as, the S&P 500, the Eurostoxx, the Dax , the Nikkei, and so on. So, all of these indices have options traded on them that are European options, and so everything we say here will apply to these indices and, indeed, foreign exchange options as well. The volatility surface, sigma K, T, is a function of the strike K and the expiration, T. It is defined implicitly through this equation here. Where c subscript mkt stands for the market price of the call option. And c subscript bs stands for the Black-Scholes price of a call option. Now, in this definition we're going to use call options but I can tell you that in the case of European options we could just as easily use put options, we're going to get the exact same volatility surface. So we will stick with call options here but again we could just as easily use put options as well. So what have we got here? On the left hand side we have the market price of a call option when the current stock price is s, the strike is k, and the time to maturity is capital T. We can see this in the marketplace. We can go into the marketplace and see how much this call option is worth. That is the left hand side, over here. On the right hand side, we want to use the Black-Scholes formula for the price of a call option. Now, we're going to know that all of these parameters s, we see that's it's the current stock price timed maturities known, risk free interest rate is known. The dividend, dividend yield can be estimated. The strike is known. And all we're left with, is the implied volatility, sigma K, T, or simply Sigma, as we've been calling it, up until now. So, what we do, is as follows, we equate the market price of the option with the Black-Schole's price of the option. And we solve for the one unknown parameter sigma. So, when we solve this equation for sigma, we are getting what is called the implied volatility for the option. Note also that this implied volatility would generally depend on K and T. And that is why we've written it as sigma of K and T. Here's an example of the implied volatility surface, as of the 20th of November, 2007, for the Euro Stocks 50 index. This, is an index of stocks traded in the Euro zone. It is, there are 50 securities in the index. And it is, the analog, if you like, of the S&P 500 in the US. So, there are several points to, to keep in mind. First of all, we don't see this surface in practice. What we actually see, is the following. We see a finite number of options in the market place, which strikes and maturities K1, T1, up as far as, let's say Kn, Tn. So these are the strike maturity pairs for which options are traded in the marketplace. Maybe these values here represent these values of K and T. So, I might see a finite number of strike maturity pairs and I'm plotting them here in the figure. Now, what is done at this point is for each option price, I actually determined, the implied volatility. [SOUND]. And I do that by working with this equation here. I have my Black-Scholes formula coded up. I can have it coded up in any language I like, in Ora, Python, or Excel. And I see the market price as well. And what I do is, I run a simple calibration or root finding algorithm to determine what value of sigma will make this equation correct. And that's how I calculate these values here. So, I can get all of these values here and then I can plot these points here as I have shown. At that point, I now have a finite number of, of these points. What I do is I fit a surface to this point. And that gives me my implied volatility surface. I need to fit my surface carefully, I'll use some sort of regression or interpolation, extrapolation procedure to complete the surface. And that gives me the implied volatility surface. Now, in practice, to get a surface like this, I would also need to have additional points, as well. And, I might make some assumptions, in order to extrapolate out to the extreme edges, edges both in strike, in the strike dimension and in the time to the maturity dimension. So, that is how I construct my implied volatility surface. And as I mentioned in the previous slide, for European options, it doesn't matter whether I use call or put options, I'm going to get the same surface. Now, here's a question. Why will there always be a unique solution, sigma K, T to this equation here? This is equation 2. How do I know that I will always find a unique solution to this equation here? Well, here's why. The first thing to remember is vega, if you recall vega. Vega of a call option was equal to Delta c, Delta sigma. And we mentioned that this is always strictly positive. So, now you can imagine drawing the following graph. On the x-axis we will plot sigma. And on the y-axis, we will plot the option price C of sigma. Now, if this is the zero value then maybe the option starts off here or it starts off with zero. If it's out of the money but it will start off, let's say, at this point here, as a function of sigma. And then it's going to grow someway like this. Okay? How do I know it's going to increase? Well, I know it's going to increase because vega equals delta c, delta sigma, strictly positive. So, c is an increasing function of sigma. Now, if I go into the marketplace, I will see the option price in the market. And maybe this will be the option price in the marketplace. So, therefore, all I need to do to find my unique value of sigma is to come across here, find out what this value is. And this my sigma K, T. And that is how I know there will be a unique solution to that equation too. I am assuming, of course, that there is no arbitrage with the market price of the option. Now, if the Black Scholes model were correct, then we should have a flat volatility surface with sigma K, T equals sigma for all K, T. After all, remember, the Black-Scholes formula is, is based on the Black-Scholes model. And the Black-Scholes model assumes that the stock price follows a geometric Brownian motion, so that the price at time T in the stock is given to us by this quantity that I'm writing here, where wT is a Brownian motion. And here, it is assumed that sigma is a constant. So, if the Black-Scholes model is correct, and indeed the price dynamics of the underlying security follow geometric Brownian motion, then sigma would be a constant. And I would get sigma K, T equals sigma for all K and T. And indeed, it would be constant through time. As I compute the vol surface, the volatility surface on day one, if look at it on the next day, I should still see the same constant sigma. So, that's what I mean when I say constant through time. In practice, however, volatility surfaces are not flat. And they move about randomly. Indeed, options with lower strikes tend to have higher implied volatilities. And we can see this here. Note that the lower strikes are down in this direction. So, we see the lower strikes tend to have higher implied volatilities than higher strikes. For a given maturity T, this feature is typically referred to as the volatility skew or the smile. Notice for any fixed timed maturity T, suppose I take T equals two years, and I look at the slice corresponding to T equals two years, I'll still see this behavior, where the implied volatilities rise as the strike decreases. So, the fact that the volatility surface is not constant is another way to recognize the fact that the Black-Scholes model is incorrect. It is not close to being right. And the market knows it is not correct. For a given strike K, the implied volatility can be either increasing or decreasing with time to maturity. In general, for a fixed K, sigma K, T converges to a constant as T goes to infinity. Of course, I should mention, in practice we will only see options with maturities after 2 or 3 years. So, in general, you actually don't observe sigma K, T for T being very large. It is also worth mentioning that when T is small, you often observe an inverted volatility surface, with short term options having much higher volatilities than longer term options. And indeed, we see that here to some extent as well. We see that for very small times maturity and for strikes that are fairly low or least moderate to low, we see the implied volatilities are higher than for longer times maturity. This actually is often true in times of market stress. In times of market stress there's a lot of worry and concern in the market. People are risk averse. There's a lot of volatility. And, as we know, option prices increase with volatility. And so when there is market stress, we can't see short term options having higher volatility than longer maturity options. Single stock options are generally American. And in this case, call or put options typically give rise to different surfaces. But I mentioned a moment ago, we're not really go into this. The general ideas behind the volatility surface can be found by just discussing the case of European options. And indeed that is what we will stick to. Now, the fact of the volatility surface is not constant, emphasizes just how wrong Black-Scholes is. And in particular, how wrong the geometric Brownian motion model, for security dynamics is. That said, pretty much every equity and foreign exchange derivatives trading desk computes the Black-Scholes implied volatility surface for all of the markets they're trading in. So, these could be foreign exchange rates, like dollar versus euro or dollar v. yen or euro v. pound and so on. And also, for all the main equity in the states, like the S&P 500, the Eurostoxx, the Nikkei, the Dow Jones, the FTSE, and so on. Not only are the volatility surfaces calculated for all, in all of these markets, they also calculate the Greeks. So, remember, the Greeks are the sensitivities of the option prices with respect to parameters. So we have the delta, the gamma, the vega, the theta, and so on. We can still calculate all those Greeks using the Black-Scholes formula. But we just have to make sure now that when we use Black-Scholes formula, we're using the correct volatility, which is a function of the strike and time to maturity. So, it is, it is, it is interesting to note how the Black-Scholes formula is wrong, the Black-Scholes model is wrong. Everybody knows it's wrong. It is wrong for a number of reasons. That said, the Black-Scholes model is still used everywhere. And indeed, use of the Black-Scholes formula is often likened to using the wrong number in the wrong formula to obtain the right price. Where does that come from? Well, if we go back to equation 2, this is what I'm getting at. So, the wrong number is this, sigma K, T. After all, the Black-Scholes model would assume sigma is a constant. So, the wrong number is going into the wrong formula. The wrong formula is the Black-Scholes option price. And it's the wrong formula because, you know, the Black-Scholes model doesn't hold. So, the wrong number goes into the wrong formula to give the right price. The right price is the market price. And of course that is the right price because that's the price of the option in the marketplace. The shape of the implied volatility surface is constrained by the absence of arbitrage. And it is worth making this point here. For example, we know that implied volatilities must be greater than or equal to zero for all strikes K and expirations T. So, therefore, we must have this condition here. It is also true that at any given maturity the skew can not be too steep. Otherwise, arbitrage opportunities, such as a put spread arbitrage, would exist. Now, what do I mean by put spread arbitrage? Well, I'll answer that here. So, lets fix T and lets look at a slice on the volatility surface. So, here I'm going to show you a slice. So, T is fixed. Here is K, the strike. And up here, I therefore have sigma K. I'm going to exclude T from the argument of sigma because we have it fixed in this picture here. Now, I said that the skew can not be too steep. Well, what would be too steep? Well, maybe this would be too steep. Why can we not get a skew that is too steep? Well, the reason is as follows. Imagine we've got two strikes. So, these two strikes, we'll call them K1 and K2. Now, imagine we buy a put. Maybe I'll write it over here. Imagine, we buy a put with strike K2 and we sell a put with strike K1. Well, such a strategy is actually known as a put spread. So, if I buy a put with strike K2 and sell a put with strike K1, then this is going to have a positive cost. The value of this will be greater than or equal to zero, and that's because K2 is greater than K1. And so the payoff of the put strike K2 will always be greater than or equal to the payoff of the put with strike K1. So, it's value today must be greater than or equal to zero as well. So, therefore, my put spread must have a positive price in the marketplace, if there's no arbitrage. However, in my Black-Scholes volatility world, if I have a volatility surface like this, then this is going to be sigma K2 and this will be sigma K1. So, clearly sigma K1 is greater than sigma K2. Remember however, the price of a put option, so the Black-Scholes price of a put option would be increasing in sigma. And if this skew is to steep, then sigma K1 will be much larger than sigma K2. And the put option with strike K1 will be more expensive than the put option with strike K2. And that would introduce an arbitrage because as I said, in the marketplace, the put with strike K2 must be more valuable than the strike with K1. But if this gets too steep, then in fact, that would be violated and there would be an arbitrage in the volatility surface. So, that's what I mean by put-spread arbitrage. Likewise, the term structure of implied volatility cannot be too inverted. What do I mean by that? Well, again, we can draw another picture, but this time we will keep K fixed. So, T is actually our variable on the x-axis here. This is sigma of T and I'm keeping K fixed here. Well, this would be an inverted, what would be called an inverted term structure of implied volatilities. This is just a slice of volatility surface I showed you a while ago. So, for example, if I come back for a picture, I would fix K. So, maybe I would fix K at 4000. And then I would get this slice here. And this would be the term structure of implied volatilities when K equals 4000 so it would be this guy here. If I'm looking at K equals 3800, say, here, I get this kind of term structure implied volatilities and we see that they have, it, at and we see that it is inverted at K equals 3800. So, returning to this here, the best way to explain what I mean by call spread arbitrager is just to make the following point. Suppose [SOUND] r equals c, the dividend yield equals zero. Well, then, in that case, it can be shown mathematically. If there's no arbitrage, then, an option price, let's say, a call option price would strike c2 must be greater than the value of a call option price, sorry, a call option price with expiration T2 must be greater than a call option price with expiration T1, where T2 is greater than T1. So, maybe this point here is T1 and this point here is T2. But if it gets too inverted, the implied volatility for T1 is here. It is sigma T1, and for T2, it is here. And it's the same sort of argument as we used up here for the put spread. If it gets too inverted, then sigma T1 is too large, relative to sigma T1, relative to sigma T2. And the call option price with maturity T1 would be greater than the call option price with maturity T2. And that would be an arbitrage. That only holds mathematically when r equals c equals zero, but the same intuition holds more generally. you might want to think, by the way, if you're interested, why in this situation this must hold. Maybe we'll address that in the forums. So, to summarize, in practice, the implied volatility surface will not violate any of these restrictions. One, two, and three. Otherwise, there would be an arbitrage in the market. These restrictions can be difficult to enforce, however, when we are stressing the volatility surface. What we mean by stressing the volatility surface? Well, stressing a volatility surface is something that is often performed in risk management applications. What we do is we have a portfolio of derivatives, maybe a portfolio of options. We know the current value. And we want to see what will be the new value of this portfolio if the volatility surface changes. So, what we might do is shift the volatility surface from its current surface to a new surface. That will give us a new value of the portfolio, from which we can calculate the profit and loss. So, this is something people often do in practice. So, it's also an example of a scenario analysis which we saw in an earlier module, where we shift the underlying security by various percentages. We also shift the implied volatilites by various percentages and recalculate the value of our portfolio in these scenarios. And then, compute the profit and loss in these scenarios. So, as I said, this is a very important task for risk management. In derivatives portfolios, we need to be able to stress volatilities. We want to be able to stress volatilities in a manner that is consistent with no arbitrage. And so, when we are moving an entire surface, we need to do so in such a way that it doesn't violate these no arbitrage conditions.

## 012.The Volatility Surface in Action and Skew

### 020. The Volatility Surface in Action

In this brief module, we're going to show you some videos of how the volatility surface moves. We will look at examples during the financial crisis and we will see how the volatility surface spiked up during that period. We will also see that the volatility surface is not flat. It has a certain shape, i.e. the skew is very noticeable. We will also see the inverted term structure of the volatility surface. Particularly during times of market stress and market panic, for example, during the financial crisis. So hopefully this will emphasize to you the importance of the volatility surface and how stochastic it is, how far it is from being constant and in particular how that means the Black Scholes model is far from being a good approximation. What we have here is a three dimensional figure. It is a plot of the implied volatility surface of the S&P 500 on August 1st, 2007. Now what we're going to do is actually play a video showing how this implied volatility surface varies through time, right up until January 2009. So before we play let's just make a few observations first of all. Along this axis here we have what is called the moneyness. Now the moneyness is nothing more than the strike divided by the current security price. In this case, the security is the S&P 500 Index. Over on this axis, we have time to maturity measured in days, so in fact you've got times to maturity ranging from just a few days depending on the next option maturity at a given time out until 800 days. Now, on the z axis, the vertical axis here, we are plotting the implied volatility, so we've plotted it from 10% up as far as 70%. Now, one thing to keep in mind is that on this scale, from 10% to 70%, the implied volatility surface on August 1, 2007, looks very flat. It looks like that there's no implied volatility skew here. Well that is not true. That only appears to be the case because we are plotting it against a wide range, 0.1 up to 0.7. If we were to plot this surface in the range 0.1 to 0.3, we actually would see the implied skew. We would see implied volatilities corresponding to these strikes here, 1.1, 1.15, and so on. Being maybe 4 or 5 volatility points below, the implied volatilities for strikes corresponding to .85, and .9 and so on. So you can take my word for it, that there is a skew here, it's just hard to see because we're plotting it against a range of 0.1 up to 0.7. Another thing to keep in mind here is that we have the date up here. We have August 1, 2007. So this is the start date for the video. We're going to run this up until January 2009. Now the volatility data we're using is coming from the option metrics applied volatility database. This database has all the implied volatilities on US options, index options, ETFs, and so on. It gives you the implied volatilities at the close of the day, and so that's another important point. This video is just showing the implied volatility surface at the close of each day. Within each day the implied volatility surface will also be moving around, but we don't have that data. So we just going to plot the close of day implied volatility surface. So the first thing we'll do is we'll just play the video from the start to the end and then we'll go back and look at a few periods in time. So here's the video, you can see it moving, you can see sometimes the implied volatility surface becomes inverted, sometimes it's not inverted. OK, so you saw during the middle there that the implied volatility surface got very, very high indeed. In fact it actually rose well above 0.7 or 70%. let's go back a few moments, and see what was going on here. So one moment to look at is back around March, 2008. so if we, we can play it one day at a time here. So you can see that the volatility surface is around, hanging around 20%. Obviously, as I said, there is a skew there, so it's not flat. But, it's around 20% at this point, at this point in time. If we move on we see it starting to rise some more, now if we go on to March 13th, March 14th we see a big jump up. Actually what happened there was that Bear Sterns stock started to plummet. there were worries that it wasn't viable, that it was going to go bankrupt. Then in fact that's what was going on around here. round this time as well is acquired for $2 a share by J P Morgan. and then the volatility surface came back down. So now let's roll it forward until September 2008 which is where the financial crisis really took off. Lehman Brothers went bankrupt, Merrill Lynch was bought by Bank of America and in response to all of this the United States Congress attempted to pass some emergency legislation to effectively bail out the financial system. This was rejected initially by Congress. Let's see what happened that day, let's play. OK, so now we are into September 8th. Again the volatility surface isn't too high. It's around 20% ish, it looks at that level maybe a little bit higher. It's hard to see the exact levels in this three-dimensional surface. so let's see what happens. September 15th was the date when Lehman filed for bankruptcy. So, this is the 11th, so this is the 12th, and I think this was a Friday. So, the next date we're going to see is September 15th, which was a Monday. That was the day that Lehman Brothers filed for bankruptcy, and we see that the volatility surface moves up entirely. But also we see the short term vols really spike up. So, these are climbing up to levels maybe around 40 or 40% plus, again it's hard to see exactly what levels these are on this surface, but we can certainly see what is happening. let's keep going on. So, it calms down a little bit, it's climbing, so this is sort of, getting into the middle of the financial crisis. 25th, 26th, 29th, so what happened here was that the Emergency Economic Stabilization Act was defeated in the United States House of Representatives, so this was the day when Congress defeated a bill that was proposed. The idea was that this bill would help bail out the financial system. Congress defeated it, and so initially there was a huge panic in the market on this date. The following date we see it falls back down again. Note, however, that these are still pretty high levels of volatility, up to 40% and, and beyond. On some of the days, we are seeing the highest volatility levels that had ever been seen. So now, we're in October 14th, October 15th, October 16th, and so on. It's worth mentioning that on October 6th to the 10th, that was the worst week for the stock market in 75 years. The Dow Jones lost 22.1%. the S&P 500 lost 18.2% that week. So in fact we can go back and take a look at that week. So it started on the 6th. So this was the implied volatility surface on the 6th of October. This was the week, as I said, where the stock market had its worst returns in over 75 years. So all in all a pretty, intense, period of time in the financial markets. letting the video run we see things calming down somewhat, by the end of January 2009, but still these volatility levels are much higher then they were before the financial crisis took hold. it's worth also mentioning the Vix index, the Vix index is sometimes called the Fear index. It's a widely used market indicator that's constructed actually using the options for the S&P 500. So the Vix index is actually constructed using very near terms option. So typically one month after two months. It's also worth pointing out that these, this is what happened to the implied volatility surface of the S&P 500, this is the most important equity index in the world. If we were to plot the implied volatility surface for individual stocks, individual banking or financial stocks, or even industry indices, we would see far more extreme moves in the implied volatility surface. Anyway, so this is just a video showing you what happened to the volatility surface, the implied volatility surface of the S&P 500 during the financial crisis. One of the points to take home is that it is not a constant, as it would be implied by geometric Brownian motion model of Black and Scholes. Moreover, it is very stochastic, it moves about an awful lot. In periods of high market stress, obviously it increases. With the short end or, if you like, the short time to maturity, implied volatility is rising, much more than the implied volatilities of longer time to maturity options.

### 021. Why is There a Skew

In the last module we introduced the concept of the volatility surface. And we saw that volatility surfaces in practice tend to have specific shapes. In particular if you fix a timed maturity and you look at the slice of the volatility surface. Then you will typically see that implied volatilities increase as the strike decreases. This is known as the volatility skew or the smile. In this module we're going to discuss some reasons why we see a skew or smile in practice. So recall, this is our example of an implied volatility surface. This is just the volatility surface for a particular moment in time for a particular underlying security, in this case is the Euro stocks index in November, 2007. Martin mentioned before that the way this volatility surface is constructed is we have a set of options with strikes, and maturities K1, T1, up to say, KN, TN. And what we do is, we figure out the implied volatility. For each of these strike maturity pairs. And we do that, as we said, by equating the market price for the option, CMKT. So the market price of the option. KITI, with the Black-Scholes price of the option. So at the current price srckiti and we get sigma. K I T I. And what we do is, we see this in the marketplace, we know all of these parimeters, S R C, can be estimated, K I and T I. And so we know the Black-Scholes forumla, so the only thing we need to calculate is this. And we explained why we can get a unique solution to this when there's no arbitross. So what we do is we get the implied volatility at all of these strike maturity pairs that are traded in the marketplace. Maybe they are these quantities here that I am plotting. And then I actually fit a surface to all of these points. So that's how I get my implied volatility surface. We mentioned, as well, that one striking feature of implied volatility surfaces, in general, is the so called skew. That is, if I fix a particular time to maturity. Maybe 2.5. I will see, that, the implied volatilities tend to increase. That's it here. They tend to increase as the strike decreases. So this is my slice of the volatilities surface of T equals 2.5. And I can see that these volatilities are increasing, as the strike decreases. So that's called a skew or smile. And after the, the Wall Street crash of 1987, this skew or smile behavior started to appear in the marketplaces for various derivatives markets. And people started wanting to understand why these skews were there. And they also wanted to able to build models that produced these skews. So the skew or smile that you see in options markets is a very important feature of those markets. So we're going to discuss a couple of reasons for why a skew actually exists in practice. there are at least two principal excuses for the skew. First explanation is risk aversion. And this explanation can appear in many guises. For example, security prices often jump, jumps from a downside tend to be larger and more frequent than jumps from the upside. Another guise is that as markets go down fear or panic sets in and volatility goes up. A third reason is simply supply and demand. Investors like to protect their portfolio by purchasing out-of-the-money put options, and so there is more demand for options with lower strikes. So if there's more demand for options with lower strikes, then the prices of these options with lower strikes will actually increase. And therefore they will have higher implied volatilities. Note that in making this argument I am using the fact that our European option price increases as the sigma parameter increases. So, all of these three comments here or three points here reflect risk aversion in some sense. The fact that when markets go down, people get more worried, markets become more volatile, therefore options become more expensive. Supply and demand. People want to protect their portfolios against the downside or against negative returns in the marketplace. One way to protect your portfolio, in that situation is to buy out-of-the-money puts. And so there's a natural demand for out of the money puts in the market base. Again, that pushes those option prices up, which is reflected in higher volatilities for these out of the money options. So these points all reflect risk aversion in some form or another. A second explanation is the so-called leverage effect. The leverage effect is based on the fact that the total value of the company assets, i.e debt plus equity, is a more natural candidate. Is a more natural candidate to follow geometric grounding motion, or at least to have IID returns. So let's spend a little bit of time talking about the leverage effect. Let V, E and D Denote the total value of a company, the companies equity and the companies staff, respectively. Then, the so called fundamental accounting equation states that V is equal to D plus E. So on the left hand side we have V, the value of the firm. This is the value of all of the assets that accompany a firm house. Well, if you think about it for a moment you will see that all of those assets, all the cash flows produced by those assets. Must go to the debt-holders and the equity holders. So therefore, we get V equals D plus E. One way to see this visually as well is to break up the total value of the firm into an equity piece, which we will have down here. And up here we've got a debt piece. So this is the total value of the company. We've got it split up into equity and debt. And indeed, equation three is the basis for many classical structural models. So we won't be discussing structural models in this course, but I can tell you that these models are sometimes used to price risky. Or default able debt, and indeed credit default swaps as well. Merton in the 70s was the first to recognize that equity could be viewed as a call option on V withs trike equal to D. And this is valid because debt holders get paid before equity holders. So what Merton was saying is that we can view equity, the equity piece of a firm, or certainly at maturity if you like, imagine that there's some maturity here. Then the equity value at maturity is equal to the maximum of 0 and V minus D. And so what this is doing is a, it's reflecting the fact that the debt-holders get paid off first. So equity's always the riskiest part of the capital structure of a company. So equity holders actually incur losses before debt-holders. So, if a company is being liquidated at time capital 'T' say, then the debt holders must get their money first. And only after debt holders get their money do the equity holders get paid. What they get paid then is the residual, they get V minus D. They only get that if D is less than V. Otherwise the limited liability of shares And equity holders means that they would get zero. So Martin was the first to actually make this point, he then actually was abel to say, we'll lets maybe model the dynamics of V. Instead of saying let E, the equity piece or the stock price follow a geometric grounding motion. Maybe we could let V follow a geometric grounding motion. And then use risk-neutral pricing to actually get the value of the equity. And in turn, use that to get the value of the debt as well. So this gave rise to what I called structural models for pricing the components of the capital structure in a company. The capital structure being the equity, the debt, and so on. And by the way, this way of looking at things is very important. It's playing out right now in the global fianncial crisis as people are talking about banks failing. And whether equity holders or deposit holders incur the losses. So all of these ideas we're talking about here are actually very relevant to what's going on in the world right now. To see how the leverage effect can actually give rise to the skew, let's do the following. Let delta v, delta e, and delta d be the change in values in v, e, and d respectively. So this might be over some time horizon. T to T plus delta T then the fundamental accounting equation again state that this condition. This equation must be satisfied and we'll assume that delta t is fairly small, relatively small so that delta V is also relatively small. So now if we divide across this equation by V we get the following here. And then all we're doing is rearranging them. We're going to take an E outrside and bring it down here. And take a D outside this term and divide by D over here. So equation four is a way of writing the return on the value of the company. So this here is the return on the value of the company. So if I say, or V for the return in V, so or v, this is return on the equity piece and this is the return on the debt piece. So we see that rv is equal to E over V times rE plus D over V times rD. So, in other words we can actually say that the return on the company. The return on the assets of the company 'rv' Is a weighted combination of the return on the equity part of the company and the return on the debt part of the company. Now by the way just as an aside for those of you that might have studied corporate finance before and capital structure before. We're not going to go into taxes and benefits from taxes on debt and so on. That's another matter entirely. What we're doing here is just trying to understand how the leverage effect can give rise to the skew that we see in implied volatility surfaces in practice. Alright, so let's, let's come back to, to this. So, what we will do is we'll assume the following. Suppose that the equity piece is substantial, so that it absorbs almost all the losses. So remember, this is how we're thinking of, of, of our capital structure. We've got our equity piece down here. We've got our debt piece down here. V is equal to D plus E. Now, if E is substantial enough, so that any of these changes in v losses or gains can be absorbed by e, then that means that delta d will be very small. If delta D is very small then we can do the following. Let's take variances across equation 4. If we do that we'll get the following. We'll get sigma squared v. So this is the variance of the return on the value of the firm. Is equal to E over V to 2b squared times sigma squared E. This is the variance of rE. Plus d over v 2b squared. Times sigma squared D. Your sigma squared d is the variance of r d plus twice e over v times d over v, the covariance of rE and rD. However, if the equity component is very substantial, so that it absorbs almost all of the loses, and so the debt is not very risky, then delta D will be very small. And in particular, sigma square D on the covariants of rE with rD will be very small in comparison with sigma square E. So in particular, in this situation, this will be approximately equal to 0. And so therefore I can get sigma V as approximate equal to E over V times sigma E. I can rearrange to get sigma E equal V over E times sigma V, remember V equals E plus D. So if I substitute E plus d in for V. I will get sigma e equals 1 plus D over E times sigma V. And so if sigma V, is a constant. Imagine the value of the assets of reform following geometric value in motion. So, in that case Sigma V is a constant, we'll see that naturally Sigma E will actually increase as V decreases. In other words, even as Sigma V is a geometric grounding motion, then as V goes up or goes down, Sigma E will actually change. So, sigma V can be constant, but sigma E will therefore be stochastic, and we will see that sigma E will increase as the equity piece decreases. And, so, this also explains why you would see a skew in the marketplace. Why you would see volatilities, implied volatilities, being higher for lower strikes than for higher strikes. This is called the leverage effect.

## 013.The Volatility Surface and Pricing Derivatives

### 022. What the Volatility Surface Tells Us

In the last couple of modules we introduced the volatility surface. We saw how to construct the volatility surface, and we also discussed the skew and why we might see a skew in practice. In this module we're going to discuss what the volatility surface tells us. We will see that the volatitlity surface gives us the marginal risk neutral distributions of the stock price. It does not tell us anything about the joint risk neutral distributions of the stock price at various times. So that is the key part of the volatility surface. It is very important to appreciate it. It only tells us the marginal risk neutral distributions of the stock price at a given fixed time. It tells us nothing about the joint risk mutual distributions. And we will emphasize that in this module and indeed in later modules. So recall again this is an example of implied volatility surface and just remind yourselves again to make sure we don't forget. It is constructed as follows, we see a set of strike expiration pairs in the market place. So we have k1 t1 up to k n t n. We see the option prices in the marketplace for all of these. So, we actually see the caller put price, let's say call price c subscript mkt for market of kiti, and that's true for i equals 1 to n. So, we see these prices in the marketplace, and what we do is, we set these prices equal to the Black-Scholes price with S, r, K, T, C, and sigma of kt. So we set this market price equal to the Black Shoal's price. We know the left hand inside, we know the Black Shoal's formula, we know s r kt. We can estimate C, and so there's just one unknown in this equation, and we can actually back out of this unknown for sigma k i t i. And that will give us the implied volatility at the strike k i and expiration t i. So that will give us a number of points on our surface here. And then we fill in the rest of the surface using some sort of interpolation or extrapolation procedure. I didn't really discuss how we would do this interpretation or extrapolation, but one has to be careful when doing it. So we're going to continue to assume that the volatility surface has been constructed from European option prices. We're going to discuss now what the volatility surface tells us and what we can use it for. Certainly we can use it for risk management purposes. I've mentioned that already. We can do scenario analysis. We can actually stress the volatility surface by moving it up or down, or moving parts of the volatility surface up or down. Recomputing the value of a portfolio, computing the pnl, and so on. So, the volatility surface is certainly used for risk management purposes. What we're going to discuss in the next couple of slides, is what can it tell us in terms of being able to price derivative securities beyond call and put options. So, to answer this question, let's first of all consider, a butterfly strategy. Now a butterfly strategy centered at k, does the following. It buys a call option with strike k minus Delta K. It buys a call option with strike k plus Delta K. And then it sells two call options with strike k. The value of the butterfly, B0, we'll say, at time t equals 0, is therefore given to us by this expression here. Where C is the call option price at the strike K minus Delta K, and maturity T, and so on. And in fact, in practice what we'll be doing is, doing this, using the market prices, so if you like you can assume that these are market prices. MKT, being shorthand for market. let's also see what the payoff of this butterfly strategy is at maturity. So maturity is capital T. Let's get an idea of what this looks like at maturity. So, let's draw a plot. So we will call this the payoff, and we will call it B capital T, for the payoff of the butterfly strategy at maturity. And along the x axis we will have the underlying security price, which is st, at maturity capital T. And, let's, mark off k. k minus Delta K. And k, plus Delta K. Well, it's pretty straight forward, to see, that this strategy earns nothing, if the stock price at time capital T is less than k minus Delta K. It also earns nothing if the stock price at time capital t is greater than k plus k Delta K. Moreover, is easy to see that the maximum payoff of this strategy is equal to k and it occurs if the stock price itself at maturity is equal to k. And it grows linearly for values of stp low k and then it decreases down to zero, at k plus Delta K. So, in fact this is the payoff of the butterfly strategy at maturity as a function of st. Now, a couple of things to keep in mind, the maximum payoff is k. And, if you like, if you're inside this interval where you do get a payoff at time capital t, the average payoff will be k over 2. So the average payoff, if you're paid off, will be k over 2. Alright another thing to keep in mind, we know from risk mutual pricing that the fair value of this payoff. This is a payoff at maturity. So the fair value of this payoff at maturity is the current value of the butterfly today which is B0. We know B0 is equal to the right inside of 6. But from risk mutual pricing this is also equal to the expected value of time 0. Using risk mutual probabilities e to the minus r times t times the payoff. And the payoff we will call B capital T. Now I know I've used b in the past to refer to the cash account. Here it's referring to the butterfly payoff here, and this is our butterfly payoff. So keeping this in mind we're going to get an alternative expression for b0. We have one expression for B0 here in equation 6. On the next line we're going to get an alternative expression for B0 using this representation here. So what we can say is that B0 is equal to e to minus rt or rather is. It is approximately equal to e to the minus rt. Times the risk neutral probability of st being between k minus Delta K, and k plus Delta K times Delta K over 2. Now, where does that came from? Well, if you think about it, it comes from this idea here. So the payoff occurs if st is in k minus Delta K. Up to k plus Delta K. So the risk neutral probability of that is q of k minus Delta K being less than or equal to st, being less than or equal k plus Delta K. So, that's the probability that s t is inside this interval here. Now, were imagining Delta K being small, by the way. In fact, soon we're going to let Delta K go to zero. So we can imagine Delta K is very small. So, this is the probability, the risk neutral probability that st is inside this interval here. We already explained that if s t is in this interval then the pay off you expect to get is k over 2. And indeed that is why we multiply by the k over 2 here. So we have our e to minus r t term, the probability that st is inside this interval, times the average payoff in this interval. And so that's how we get this first line here. It's an approximation, but it is a very good approximation for small Delta K. Now, if you recall something about density functions, then you will understand why we're letting q. The risk neutral probability that st is in this interval is equal to the risk neutral density times the width of the interval. So we're saying the risk neutral probability that st is between k minus Delta K and k plus Delta k. That is approximately equal to the density, risk neutral density evaluated at k times the width of the interval to Delta K. And that just follows from a property of PDFs. We actually explain this in one of the additional modules on, on probability that we also recorded, they're also available on the, on the plat, course platform. So, remember, if you've got a PDF, in general. So if this is our PDF, f of x. And suppose we want to compute the interval that the random variable x is inside x0 to x 0 plus Delta X. Well, the density satisfies that the probability, that the random variable x is in, x0 plus Delta x where Delta x small. That's approximately equal to f of x 0 times the width of the interval which is Delta X. This is a standard property of probability density function and that's all we're using here. So we're saying the portability that st is inside this interval here is equal to the density which is ft, times the width of the interval which is 2 Delta K. So therefore we're going to get B0 is approximately equal e to the minus rt. Times ft of k, times Delta K squared. We have a two here, but that counts as with a two there, and we get a Delta K times Delta K, which is delta k squared. So what we've done now is we've come up with 2 expressions for the value of the butterfly strategy. We have this expression here in equation 6 which is exact. I'm here with this expression here which is an approximation. But as Delta K goes to zero, this approximation also becomes exact. So, what we're going to do is, we're going to equate equation 7 with equation 6 and then solve for ft of k. Or in other words, bring ft of k over to the left hand side. So we will see ft of k, is approximately equal to e to the rt, times this expression on the right hand side of 6 here, divided by Delta K squared. If we now let Delta K go to 0 in 8. Well, if you recall your, your calculus, you'll see that all you're doing when you do this is actually computing the second partial derivative of the call option price with respect to the strike. And so what we're seeing is that by constructing a butterfly strategy where Delta K goes to 0. We're actually able to come up with a risk neutral probability density function for st, f t is equal to e to the r t, Delta 2 c, Delta k squared. And so. The volatility surface gives us the marginal risk-neutral distribution of the stock price, st, for any fixed time, t. So this is a really interesting observation. We see option prices for finite number of strikes and maturities. We compute those implied volatilities. We then actually fit the volatility surface to those finite number of points. I mentioned earlier that we need to fit the volatility surface very carefully. And the reason is if we want to be able to compute something like f t of k, then we're computing partial derivatives and second partial derivatives. So we need to make sure we do things, we fit things very smoothly. This means that, given the implied volatility surface, sigma kt. We can compute the price p0 of any derivative security whose payoff f only depends on the underlying stock price of the single and fixed time capital T. Now, maybe I've chosen f. Unfortunately here because I used f subscript t. F subscript t to denote the risk neutral PDF of st. Here, f, this f here has got nothing to do with this. This is the risk neutral PDF of st. F, here, is just some arbitrary function representing the payoff of some derivative security. So just to be clear, the f that I'm using here has nothing to do with the f subscript t on the previous slide. Which was the risk neutral probability density function of st. Why is it we can compute this quantity here? Well, if I know the risk neutral density of st, I can just perform and integration against that risk neutral density to compute this quantity here. So therefore I can compute the price of any derivative security if the payoff of that derivative security only depends on the stock price at a single and fixed time t. And that's because I will know f subscript t, the risk neutral density for that stock price. And therefore, I can evaluate this expectation on the right hand side. However, knowing the volatility surface tells us nothing about the joint distribution of the stock price at multiple times t1 up to tn. And this is not surprising since the volatility surface is constructed from European option prices. And European option prices only depend on the marginal distributions of st. Just to be clear, the joint distribution of the stock price at multiple times t1, tn, what I'm referring to there is the following. It would be this distribution, t1, up to tn, of s, t1, up to stn. So this is the risk neutral joint distribution of the stock price at times t1 up to tn. And what we're saying here is that we don't know anything about this joint distribution. The only thing that we can learn from the volatility surface is the marginal distribution for each individual time t1 up to tn. Here's an example. Suppose we wish to compute the price of a knockout put option with time t payoff given to us here. So, it's this piece here is like a regular put option. So this is a like a regular European put option, the maximum of k minus s, t, and 0. However we only get that payoff if the minimum stock price over the interval of 0 to capital T is greater than or equal to B. So B here represents a barrier. If the stock price ever falls below B, then this indicator function here becomes 0, and so we get nothing. Remember the indicator function, this indicator function, can take on two possible values. It takes on the value 1, or 0. It takes on the value 1, if the minimum of st is greater than or equal to B. And that's the minimum over 0 less than or equal to little t, less than or equal to capital T and it takes on the value 0 otherwise. So this is an example of a knockout put option. And the point I'm trying to make here is that, we cannot compute the process of this option just using the implied volatility surface. The implied volatility surface will only give us the marginal distribution, marginal risk neutral distribution of the stock price. It doesn't give us the joint distribution. And in order to evaluate this, I would need to compute the following. So if the value of the security is p0. It will be equal to the expected value using risk-neutral probabilities e to the minus or t times the maximum of k minus st and 0 times the indicator function of st being greater than or equal to B. And the point I'm trying to make is, in order to compute this expectation. I would need to know the joint risk neutral distribution for the stock price at all times between 0 and capital T. But I don't know that. I can not compute that risk neutral distribution from the, from the implied volatility surface. And so in practice and we'll come back to this soon. We would need to use some sort of model, some arbitrage free model to estimate the price of this quantity.

### 023. Pricing Derivatives Using the Volatility Surface

We're now going to see how we can use the volatility surface to see how we can price different types of derivative securities. Obviously, we can use the volatility surface to price European call and put options. After all, we actually constructed the volatility surface using European call and put option prices. But we will see that there are other derivative securities that can also be priced. These are derivative securities whose value only depends On the marginal risk-neutral distributions of the stock price. So, we're going to see some examples. In particular we will see how to price a digital option. And we will also see how to price a so-called range accrual using the information in the implied volatility surface. Suppose we wish to price a digital option, which pays $1 if the time t stock price, ST, is greater than K, and 0 otherwise. [INAUDIBLE] . We actually know that we can price the security given the implied volatility surface. Now why is that? Well, the reason for that, as we saw in one of the more recent modules, that if you know the implied volatility surface, then you know the marginal risk-neutral distribution of The security processor on a fixed time 'T', so the pay off of this option is going to be equal to the maximum of '0' and the indicative function '1' which pays off '1' is 'ST' is greater than 'K'. So this is the pay off of the digital option. So the risk neutral distribution of this option only depends on the marginal risk neutral distribution of st. And so we know from the volatility surface that we can calculate this marginal risk neutral distribution. And therefore, we can evaluate. This quantity here. Which is the initial value of this digital option. So lets see how we can actually go ahead and price this. It is easy to see. That the digital price. Were going to call it dkt. K is the strike. T is the maturity. Is given by the following. So dkt is equal to, well we have this limit as delta k goes to 0, of the s, the market price of a call option with strike k maturity t, minus the market price for a call option with strike k plus delta k and maturity t, all divided by delta k. Now why is that? Well, it's easy to see this if we draw a picture and that's what we'll do. So we will draw a picture. This is going to be our payoff of this strategy, so buying 1 over delta K times and option of strike K maturity T and selling 1 over delta K times the call option strike K times delat K and maturity T T. So this is represents S T, the stock price at maturity. We have this value here, whchi is K. And we have the value here K plus delta K. Now it is easy to check. That this option, this strategy here, of going long option and shortest option gives a payoff of 0 up as far as K, and then it grows linearly up to a value of 1. At k plus delta k. And thereafter, gives a constant value one. And you can see this easily. So you see that if the terminal stock price is greater than k plus delta k. Then you're going to make a profit of delta k from these two positions. Divide that by the delta k here, and you get a profit of 1. So, this is the payoff. And so it should be clear that, as we let delta k go to zero. Then this line here is becoming more and more vertical. And we're getting closer and closer to the payoff of a digital option which pays 1 dollar, only if st is greater than k. And so that's why we get this limiting argument here. So dkt is equal to the limit as delta k goes to 0 with this. We're just going to multiply through by minus 1, take the minus outside here and we get it's the limit is delta k goes to 0 of this quantity here. And we just recognize this as being the partial derivative of the market price of a call option with strike k maturity t with respect to the strike k. So it's very straightforward to see that the price of the digital option is given to us by this. Now recall how we defined the implied volatility of an option. What we did is, we equate the market price of the option with the Black Scholes price. And we figure out what is the implied volatility parameter, sigma of k and t. Which makes the Black-Scholes price match the market price. Just to simplify notation, I haven't bothered to include the other parameters that I often include here, R C and S 0. So we know that sigma K, T is the volatility parameter that must go into the Black-Scholes formula so that we get a price on the right-hand side that is equal to the market price of the option. As I said before, sometimes this is likened to Plugging the wrong number into the wrong formula to get the right price. So now, if you recall from the previous slide. What we need to do is, we need to compute this partial derivative here with respect to k. Well, we know that the partial derivative of this with respect to k is the partial derivative of the right hand side with respect to k. And there are actually two terms that come into this. We see, the first argument. K appears here. But also in the sigma argument. K also appears in there. So were actually going to have two terms corresponding to, to, to k here. So were going to get that the partial derivative, with respect of k. Is equal to the partial derivative of the Black Scholes formula with respect to the strike. Plus the Black-Scholes formula with respect to Sigma. Well, that's our vega times delta sigma, delta K. And that's actually what we will call the skew. Of course, we have a minus, because we have in both terms. Because we had a minus outside here as well. So, we're going to get D cave T is equal to minus delta CBS, delta K, minus the vega. Times the skew. And so the skew we're just going to refer to this as being delta sigma delta k. And remember that for a fixed time maturity. Maturity in the Acuity market we'll see a skew like this. So this will be s t or if you like k. Either one. And this is sigma kt. So, we can actually calculate delta cbs, delta k, and the vega from the Black Scholes formula. These are straightforward to compute, because we know the Black Scholes formula. And there, we can compute these derivatives. The skew can be estimated from the implied volatility surface. So we will have calculated our, our volatility surface, and we'll be able to estimate the sku. In other words, we'll be able to compute what delta sigma, delta k is. For example, suppose this is the strike here. Well, this, therefore, has. A value of, let's call it Sigma K. Maybe you go up to K plus Delta K. This has a value, Sigma K plus Delta K, and so we can estimate the partial derivative, the skew, or Delta Sigma Delta K... As being approximately equal to sigma of k plus delta k minus sigma k divided by k plus delta k minus k, which is delta k. And of course as I let delta k go to zero, this approximation becomes better and better. So we can approximate. Delta sigma delta k, or if you like the skew we're calling it, from the implied volatility surface that we will have available to us. So this is an example of how the Black-Scholes terminology, or technology, is used in practice. Even though the Black Scholes model is known to be wrong. We can still compute option prices with, with the, with the Black Scholes terminology. In this case, we're u-, computing option prices from the implied volatility surface. The implied volatility surface, if you recall, has been set up, so that, by construction. Call and put options will match the prices of call and put options in the marketplace. And we're going to be able to use this volatility surface to compute other types of options as well. And in this case, we're going to compute the price of a digital option. As I also mentioned before, we can use the volatility surface to price any security Who's payoff only depends on the stock price at a given fix time tee. That is because we know the marginal retribution distribution once we know[UNKNOWN] and we know the marginal retribution then we can compute the derivative who's payoff only depends on the stock price and a fix time T So here's an example. This example is taken from the book, the Volatility Surface, by Jim Gatheral. It's an advanced text. So I wouldn't necessarily advise anyone to go out and look at it. It's more of a doctoral text on financial mathematics and financial engineering. But there's a nice example in that text that we'll go through here. So what we're going to do, is, we're going to, we're going to be pricing a digital option. The digital option is, has a strike of k equals 100. The current stock price is 100. So the digital is at the money. Remember, just to be clear, the payoff of this digital time t is equal to. The maximum of zero. And the indicator function of st being greater than or equal to k. And the fact if you stop for a second, you can see you don't really need the maximum here because this is simply the indicator function of st being greater than or equal to k. So, if you recall the vega from the Black-Scholes formula, well it is as follows. We know that vega, I'll write it here. We know that vega is equal to e. To the minus c T times S square root capital T times five of D one. Where D one was equal to the, the log of S zero divided by K. Plus R minus C plus sigma squared over two times T divide, all divided by sigma square root T. Now, in this situation, in this example, we're going to assume r equals c equals zero. T equals 1 year. And s zero equals k. So in that case, d is equal to, it turns out to be simply sigma over 2. And it also implies that the vega, in this case. Is equal to. While c is zero. S is 100. T is one. So it's five of sigma over two. So what were actually going to do. Is were going to get this as equal to. S0 times 5 of sigma over 2. So now we can go to the To the task at hand, which is to compute the price of this digital option. We know this price is given to us by this quantity here. So we can actually calculate delta cbs, delta k from the Black Scholes formula. You can check. But it actually turns out to be this quantity here. The vega is given to us by s 0 phi of sigma atm over 2. Sigma atm is the octamum implied volatility. And we're told it's 25 percent. Finally, how about the skew? Well, we are told that the skew is 2.5 percent per 10 percent change in strike. So a 10 percent change in strike is equal to 10 percent of s zero. Because the strike is equal to s zero. And it's 2.5% per 10% change. So it's going to be 0.025 divided by .1 s0. This is the skew. However, we also have a minus sign here. Now the minus sign is, we're not explicitly told there's a minus sign here. But we know that there must be, because we know the equity markets we see askew like this. So clearly as, so this is K. Clearly as K increases, the implied volatility falls. So this number here, which if you recall, is delta sigma delta K, that's going to be negative. And so I implicitly understand that the skew here presents the negative 2.5% per 10% change in strike, and so that's how I get this quantity here. The S zero accounts with the S zero her. I can evaluate this quantity using, I can do it simply in Excel, and I get a digital price of 0.55... What's interesting is if we ignored the skew component. In other words, if I just took the market price, see market price of the call option. To be equal to just the black[UNKNOWN] price, as a function of KT and sigma at the money. And ignore the fact that sigma is also a funcion of K as we see in this skew here. If I ignore that, then I would only get a delta cbs delta k term appearing. Remember when we take partial derivatives here with respect to k, we get a term from the k argument. But we also get a term from the implied volatility argument. Because the implied volatility's a function of k. And that's why I get this second term here. But if I ignored the second term, pretend that signal was a constant, that would be the case of the Black-Scholes model held, then I would only get the 0.45 value here. And, so in fact, by taking the skew into account correctly, I see the price of the digital option as 0.55 and not 0.45, and actually this is significant. This represents ten cents extra. On .54 dollars. So consider now a 3 month range accrual on the S & P 500 index with range of 1,500 to 1,550. After 3 months the product pays X% of notional where x equals the percentage of days over the 3 months that the index is inside the range. So, for example, the notional is $10M and the index is inside the range 70% of the time; then the payoff will be $7M. The question is, is it possible to calculate the price of this range accrual using the volatility surface? The answer is, yes. Consider a portfolio consisting of a pair of digital's For each date between now and the expiration. So, actually lets expand on this answer and see how indeed we can use the volatility surface to price this range accrual. So lets assume that there are N Trading days in the three month period in question. Then the payoff at time t Let's write it here. The payoff at time T, that's called a P subscript T, will be equal to 10,000,000 times the summation from I equals 1 to N of the indicator function. That the underlying security price, we'll call it si, is inside the range in question and this range is 1,500 less than or equal to si, less than or equal to 1,550. We have to divide by n because its the percentage of days that were inside the range. And so we must divide. So this summation is the total number of days that were inside the range that the security price, the underlined security price, in this case the S&P 500, is inside the range. So the percentage of days that were inside the range is the summation divided by M. So this is the payoff at time, capital T. So how might we price this security? Well, we know, let's write it here. From Risk-neutral pricing that the initial value of the security is equal to the expected value under the Risk- neutral probability distribution of E to the minus R capital T. Capital T is assumed to be the maturities of To three months. Of times pt. So let's expand on that. This is equal to 10 divided by n. So I'm going to omit the m, for millionths. So now my units are in millionths. So it's 10 over n. Times the summation from i equals 1 to n of e to the minus r times t minus ti. Times the expected value of e to the minus, or ti, times this quantity here. Now, what can we do with this. We'll notice by the way, that I have a minus minus TI which is a plus TI and that counts as with a minus TI inside here. So let's look at this expression here. So we have the expected value of e to the minus rti, times the indicator function. That 1,500 is less than or equal to si. Is less than or equal to 1,550. Where S I is the underlining security price on day I. Well I can write this as the following, this is equal to, E to the minus R T I TImes the indicator function of si being greater than or equal to 1,500 minus the indicator function of si being greater than or equal to 1,550. So it's quite straightforward to see that this indicator function here. One on the event s size between 1,500 and 1,550 is equal to the difference of these 2 indicator functions here. And if you think about it, what you will see is that this is equal to. Well, using our earlier notation for the price of the digital option. This is equal to D 1500 on Date TI minus D 1550 on Date TI. And so actually what we've managed to do is we've managed to break down the range accrual into a strip of digital pairs... A different pair for each[UNKNOWN] TI, and so therefore the price of the rang accrual is equal to 10 million dollars divided by N, the number of days, times the summation... From i equals 1 to n of e to the minus r times capital T maturity minus t little i. Times the digital option. Would strike 1500 maturity ti minus the digital option would strike 1550 in maturity ti. And indeed, we can compute these digital option prices from the implied volatility surface as we saw a short while ago.

### 024. Beyond the Volatility Surface and Black-Scholes

In the last few modules we introduced the volatility surface, and we saw how to price certain types of derivative securities using the volatility surface. However there are many derivative securities that cannot be priced using the volatility surface. And that is because the prices of these derivative securities depend on the joint risk-neutral distribution of the stock price at multiple times. An example of that is a barrier option. And we're going to see in this module and example of where a barrier option cannot be priced using the volatility surface. So, we will discuss the limitations of the volatility surface, how it can only be used to price certain types of derivative securities. And how we will need to use models to price other types of derivative securities. And so in practice, when we need to price more exotic securities, we need to resort to using models. We cannot use the volatility surface that we see in the marketplace. Suppose there are two time periods, T1 and T2 of interest and then a non-dividend paying security A. Has risk-neutral distributions given by the following expressions here, where in particular Z1A and Z2A are independent N 0,1 random variables. So, you can see here, that this is the stock price at time T1, this is the stock price at time T2. So, you've got some horizon here, today's date 0. We've got T1 and we've got T2. And we see that the stock price at times T1 and T2 are log normally distributed, and that's because Z1A is a normal random variable. And, the sum of two independent, normal random variables, is also normal. So, we see that the stock price, at each time T1 and T2 is log normally distributed. Note, that the value of rho A greater than 0, can capture a momentum effect, and a value of row A less than 0 can capture a mean reversion effect. Well, what do I mean by that? I mean the following. So notice the following. Suppose the stock price at time T1 is known to you, and maybe it's a higher value than you'd previously expected. So, in other words, suppose Z1A is greater than 0. Maybe much greater than 0. Well, in that case, if rho A is positive, then row A times Z1A will also be positive. And so on average, this random variable here will also be positive, in other words the stock price at time T2 will also be larger than you will have previously expected. So thatâs what I mean by the momentum effect. On the other hand if rho A is negative, then this term here will be negative. And so, you will get a mean-reversion type effect. In other words, if the stock price of time T1 tends to be large, then the stock price at time T2 will tend to be small and vise versa. So, that would be a mean-reversion effect. So, you can capture a momentum effect, if rho A is greater than 0. And a mean-reversion effect if rho A is less than 0. Suppose now that there is another non-dividend paying security B, with risk-neutral distributions given by these quantities again, and again we've got Z1B and Z2B being independent N 0,1 random variables. So notice we're implicitly assuming here, that the initial stock price of stock A is equal to the initial stock price of stock B is equal to 1. We're also assuming that they've got the same volatility parameter. So sigma A equals sigma B equals sigma and so I see sigma appearing here. And it's the same sigma up here. Now here is an observation, if Z1 and Z2 are independent N 0,1 random variables, then, then for any rho in minus, in the range minus 1 to 1. Rho times Z1 plus the square root of 1 minus rho squared Z2 is also a standard normal random variable. So this is the standard result. It's certainly easy to see that the expected value of this random variable is 0, and the variance of it is indeed 1. So given this, we can go back to the previous slide and notice the following. We can see that this is N 0,1 and this term here is also N 0,1 and so it is clear that the stock price at time T1 for the two securities A and B have identical risk-neutral distributions. And likewise the stock prices at T2 have identical risk mutual distributions. And that's the point we're making here. Therefore, it follows that European options on A and B, with the same strike and maturity, must have the same price. After all, they've got the same marginal risk neutral distributions, and it is these marginal risk neutral distributions that we would use to compute these European option prices. So therefore A and B would have identical volatility surfaces. We've only got two maturities here, but we could price options with many different strikes and so we can say they've got identical volatility surfaces. But now consider a knock in put option with strike 1. And expiration T2. In order to knock in, the stock price at time T1 must exceed the barrier price of 1.2. So therefore, the payoff function is given to us by the maximum of 1 minus ST2 and 0, which is the payoff of a regular put option, times the indicator function. Which is 1, if the stock price at time T1 is greater than or equal to 1.2, and 0, otherwise. So, you can think of this payoff as follows, or of the security as follows. So, this is time T here, this is the stock price at time T. You can image the stock price starting off at a value of 1. Maybe this is 1.2. This might be time T1, this might be time T2. And, you can see that in order to get a payoff, what must happen is that the stock price must, some way or another, get above 1.2 at time T1. And then, at time T2, it must be below 1 in order to be in the money. So, it can still move about, but its got to come down, and be below, the strike level of 1. So, this is the strike level, this is our K. And, 1.2 is our barrier level. And the stock price must be above this at time T1, and it must be below 1 at time T2, in order to get a payoff. So now the question we can ask is as follows. Would the knock-in put option on A have the same price as the knock-in put option on B? In other words, does the value of the security depend on whether the underlying security is stock A or stock B? And also how does your answer depend on rho A and rho B. Well to answer the first question, we know that they've got the same marginal risk neutral distributions. So, we made this point on the previous slide and we see it again here. So the stock prices at each time T1 or T2 have the same marginal risk neutral probabilities. But what about the joint risk neutral distribution? In other words, what is the risk neutral distribution, let's call it fa for stock A of ST1a and ST2b, so this is the joint risk neutral distribution for security a at times T1 and T2. And similarly we've got the risk neutral distribution, the joint risk neutral distribution for stock b at times T1 and T2. We know these, they have the same marginal risk neutral distributions. That was the point of the previous slide. But what about the joint distributions? Remember, if we evaluate this option or compute the price of this option It's going to depend on fa in the case of security a or fb in the case of security b. So, how does our answer depend on rho A and rho B. Well if you look at this plot here, what you can see is the stock price needs to go up, and then it needs to fall. So, in fact a small value of rho will actually help you achieve that. In particular, you would like your rho parameter to be as small as possible, because if rho A for example, suppose rho A, is very small, less than 0, close to minus 1. Well, if z, if the stock price of time T1 is above the barrier 1.2, that means Z1A would have to have been large. But if Z1A is large then rho a times Z1A will be negative because rho A is now much smaller than 0. So in that case, this will be negative and therefore you have a much better change of this entire quantity being negative. And the stock price of time T2 being below the strike of 1. So in fact a negative value of rho A and the more negative, the closer to minus 1 the better, will help the option xbar with a positive payoff. So in fact, the answer to the question is that if rho A is less than rho B, then the price, let's call it, let's call it P0a will be more expensive than the price of the knock-in on B. Similarly, if rho B is less than rho A, then the price of the knock-in on B will be more expensive than the price of the knock-in on A. So, it certainly does depend on rho A and rho B, and what this tells us is that the volatility surface alone, cannot give us enough information to price these options. After all, these two securities, A and B, will have identical volatility surfaces because they have the same risk neutral distributions, same marginal risk neutral distributions. But they have a very different joint risk neutral distribution and that joint risk neutral distribution will actually determine the value of this not input option. And depending on the value of that rho parameter, we're going to get different prices. So, this is really just another way of saying what we said in the previous module, that we can use volatility surfaces to price derivative securities that only depends on the marginal risk neutral distribution of the stock price at a fixed time T. But any security who's value depends on the joint risk neutral distribution cannot be priced just using the information in the implied volatility surface. Moving on, lets talk about derivatives pricing in practice and in general. So we've seen the dynamic replication theory of Black, Scholes, and indeed Merton. Its' very elegant, we saw it as well in the binomial model. But it is not possible to dynamically replicate and, therefore, price derivative securities in practice. And this is for multiple reasons. First of all security prices don't follow geometric bounding motions. We don't know the particular processes that they do follow, nor do we know the exact parameters that govern those processes. It is also true, that you can not trade at every point in time, continuous trading is not possible in practice, transactions cost would render it impossible and so on. So, dynamic replication really is only something we can hope to do approximately. Instead actually supply and demand is what sets derivative security prices. This is particularly the case with the most liquid securities like European and American options in the fixed income markets. This is also true of caps and floors, swaptions and so on. We have also seen these securities earlier in the course. And indeed volatility is itself an asset class. Well, what do I mean by that? Well, I mean the following, sometimes people want to trade volatility. They have a view that volatility will increase or maybe they have a view that volatility will decrease. In that case they want to buy volatility or they want to sell volatility. And people treat volatility as an asset class. And indeed it is possible to buy volatility by buying a European call option for example or buying a European put option. We know the value of the European call option or put option will increase, as volatility increases. Remember the vega, which is equal to delta c delta sigma is positive, so we know that European call and put prices increase as volatility increases. So by buying a European call put option, your actually buying volatility. And so volatility is viewed as, as an asset class, you can actually buy volatility. It's also true, by the way, of other concepts, like correlation. Correlation can also be viewed as an asset class, and indeed there are mechanisms in securities out there, that will enable you to actually buy correlation or indeed sell correlation. So returning to this point, supply and demand sets the rate of derivative prices in general. And this is true of derivative securities in other markets. Fixed income derivatives, FX derivatives, credit derivatives, commodity derivatives and so on. Most derivative prices in these markets are determined by supply and demand. That having been said, derivatives pricing models are still needed. You need it for two principal reasons. Number one, to price exotic and other less liquid derivative securities. Remember if you have, for example, European call and put option prices, yes you can use that to construct an implied volatility surface. And you can use your implied volatility surface to price some types of derivatives securities. In particularly those securities whose pay off only depends on the underlying stock price at a fixed point in time. But there are other more exotic derivative securities like barrier options for example, who's value depends on the joint risk neutral distribution. You can not see this in the marketplace. You can not determine it from the volatility surface. And so you need models, arbitrage free models to price these more exotic and less liquid derivative securities. We also need derivatives pricing models to risk manage portfolios of derivatives. So, we can do this via the Greeks or via scenario analysis that we saw earlier. So, when I say via the Greeks, I mean the following. I could have a derivatives portfolio and compute the overall delta, delta P, delta S. So, P is the value of my derivatives portfolio. S is the underlying security. I can compute delta P, delta S, and this is the delta from my portfolio. And I can actually hedge this exposure to the underlying security by buying some stock. So, for example, suppose this is equal to $10 million. Well, if I then go out into the marketplace and short $10 million of the underlying security, then my portfolio will have a net delta of 0 and I am delta hedged. You can do similar sorts of hedging with vega risks. Maybe my delta P delta sigma is equal to some quantity. Maybe it's $100,000 say. Well, what I can then do, is, if I want to, I can go out into the marketplace, and buy or sell a security which has a vega of minus $100,000. By adding that to my portfolio, the new net vega in my portfolio would be zero. And so, in fact, that's how people will often use the Greeks in practice. They will use it to hedge away risks that they don't want. So, that's what I mean when I say, we need derivatives models to risk manage portfolios via the Greeks. Because we could, we can compute the Greeks from models, like the Black-Scholes model, for example. We can also risk manage portfolios using scenario analysis. And we saw an example of this in an earlier module. Where if you recall, we had a portfolio of options on the SMP 500 and we considered various scenarios across the top. We were stressing volatility, so we were stressing sigma and down here on the, on this axis we were stressing the underlying security. So, we were able to look at the P and L in the portfolio as the implied volatility or the implied volatile surface is moved to different values. Likewise, as the underlying security is stressed or changed to different values. So, in each of these scenarios here, I need to be able to recompute the value of my portfolio. And that means actually having a model to recompute the prices of the securities in my portfolio and calculating the PNL from this scenario. So, certainly derivatives models are needing in practice to price exotic and other less liquid securities, but also to aid in the risk management process. These models are arbitrage by construction and they are calibrated to liquid security prices. We saw an example of calibration when we were calibrating the Black Derman Toy model to the term structured interest rates. Note however that these models are only an approximation to reality. And generally they are not a great approximation. For example, witness how often they need to be re-calibrated. I mentioned in the past that when you're re calibrating these models, often you have to do so several times a day. Of course, if a model was the correct model you'd only need, you would only need to calibrate it once and you would be done with it. No more calibrations would be required In practice people are always having to re-calibrate their models. And that's just another indicator of how these models are at best only an approximation to the real world. These models also generally completely ignore the endogeneity of markets. What do I mean by the endogeneity of markets? I mean the following, most of these models do not account for the fact that the actual trading of these securities can move the prices of these securities. And if too many people enter into a market and all buy the same security, well, that's going to change the price dynamics of that security. In particular, if a market panic occurs, if people become suddenly very concerned about that security, everybody will try to sell at the same time. And security price will collapse. So, that's what I mean by endogeneity, what the market is actually doing. The trading of that security is going to change the price dynamics of that security, and this can be an extremely important characteristic of the financial markets. Certainly have played a role in the financial crisis of 2008 and beyond, when many people were holding the same types of securities. Many people ran for the exits at the same time, and so the endogeneity of the markets was actually missed by many participants. All of that having been said, the ideas of dynamic replication have not been abandoned and they're still useful. These ideas are still used to partially hedge derivatives portfolios in the same manner as I explained up here. So, just to summarize, the concept of exact dynamic replication is only a theoretical construct. You cannot exactly replicate a security in practice. But the ideas of dynamic replication are indeed still useful and they are still used by participants to perform risk management and so on.

## 014.CDOs and the Gaussian Copula Model

### 025. Structured Credit  CDOs and Beyond

In this first module we're going to briefly review securitization. And we will also discuss how CDOs or collateralized debt obligations are constructed from an underlying pool of bonds. We will of course go into CDOs in much greater detail in later modules we'll see how to price them and we will also discuss the infamous Gaussian Copula Model. Recall the securitization is the name given to the process of constructing new securities from the cash-flows, generated by a pool of underlying securities. An we've already seen examples of securitization in the mortgage market. The economic rationale behind securitization is that it enables the construction of new securities, with a broad range of risk profiles. The broad range of investors may therefore be interested in these new securities, even if they have no interest in the underlying securities. And so this results in an increased amount for the underlying cash flows. This in turn insures that the cost-of-capital is reduced for the issuers of the underlying securities. So for example, in the case of mortgage backed securities by introducing the market for mortgage-backed securities. We increase the demand for cash flows that arise from mortgages, so that we can reduce the mortgage rates for homeowners. Credit default obligations are securities that are constructed from an underlying pool of fixed-income securities. They were first issued by banks in the mid 1990s and their issuance was originally motivated by regulatory arbitrage considerations. And that is why they were supplied to the marketplace in the first place, back, as I said, in the mid 1990s. This slide displays a schematic describing the construction of a CDO. We have an underlying pool of bonds, we see them here, we've got 125 bonds. And they form the collateral for the CDO. The CDO is then divided into tranches defined by their attachment points. So their attachment points are these numbers here. 0% to 3%, 3% to 7%. All the way up to say 40% to 100%. So these numbers on the left, 0, 3 up to 40, they're called the lower attachment points. The numbers on the right, 3, 7, 100 are called the the upper attachment points. These are tranches, so we have the equity tranche, we have the mezzanine tranche. We get maybe other tranches and we have a senior sometimes called a super senior tranche up here. So these are tranches which investors can buy, so for example an investor may buy the equity tranche. Let's say he buys the equity tranche for $50, and what will happen is that the investor will ultimately receive $100. Say over the lifetime of the CDO, if none of the bonds in the underlying pool of assets defaults. But if some bonds default, then the equity tranche would have to incur the losses. And that means that the investor in the equity tranche will no longer receive that $100 I mentioned, but maybe they'll only receive $75. Or maybe $50. In fact, the number they receive, will depend on the number of losses in the underlying pool of bonds. In particular, if the losses in the underlying pool of bonds exceeds 3% of the notional, then maybe they'll get nothing. Right because 3% will exceed this 3% upper attachment point here and so the equity tranche will be wiped out. That doesn't mean that the investor in the equity tranche will receive nothing. Because depending on how the deal is structured, they might receive some payments before the losses in the underlying pool of bonds occurs. But basically, the big picture here is that an investor can buy these individual tranches. They'll pay a certain amount of money for it. and then they receive some cash flows associated with these tranches over the lifetime of the CDO. If any losses arise that impacts these tranches, then they will have to pay some sort of payment because of those losses. We'll get into all of these details in later modules. In fact, just as an aside, later we will consider what's called a synthetic CDO. And in that case, you don't buy a tranche for $50, in fact the payments of a synthetic CDO are structured to work like a swap. So that no cash flows take place at the beginning of the trade. The important takeaway for now, is that if you buy the equity tranche, then you are the hook for the first 3% of losses in the underlying bond pool. If you buy the mezzanine tranche then you are on the hook for losses between 3% and 7% of the notional principal of these 125 bonds. So, maybe each of these bonds has a notional of $1. So, then the total notional principal in the underlying pool is $125. Well, you as an investor in the mezzanine chance will be on the hook for 3% to 7% of 125. So any losses beyod 3% will start impacting the maezzanine chance and any loses above 7% wil start impacting the chance above the mezzanine chance. It should be clear then that the equity chance is the riskiest tranche of the CDO. And that's because the equity tranche is on the hook for the first losses that occur in the underlying good bonds. Likewise the senior tranche, sometimes called the super senior tranche as I mentioned earlier, is the least risky tranche in the CDO. Because this tranche only incurs losses after all of the other tranches below it have been effectively wiped out. In other words, the losses have exceeded all of the attachment points, upper attachment points. 3%, 7%, and so on, and have now entered into the senior tranche. Finally, just one comment here. In practice in order to construct the CDO, the banks that might only underline pool of bonds will often construct what's called an SPV. Which stands for special purpose vehicle. This is a legal entity which is bankruptcy remote from the bank that originally holds these bonds. The bonds, the 125 bonds are placed into this special purpose vehicle... And the special purpose vehicle issues the CDO, and the CDO tranches. But we're not going to get into that. This is part of the legal structuring of these, of these CDOs. So this, by the way, is an example, another example, of an asset backed security. You've seen this already in the mortgage backed security market. This is an asset backed security where the assets, the CDOs, are backed by the underlying pool of bonds. If these bonds were instead placed with loans, we would get what's called a collateralized loan obligation. And in fact, this shouldn't be credit, it should be a collateralized loan obligation. So these are securities that are constructed from the underlying pool of loans. The structured credit market was at the heart of the financial crisis. We saw terms like ABS, MBS, CDO and ABS-CDO's, all these terms became standard in the financial. And indeed the mainstream media during the height of the financial crisis. Our introduction to structured credit and CDO's will do several things. Number one it will provide further examples of the securitization process. Number two, it will allow us to introduce the infamous Gaussian Copula Model. Which came in for an awful lot of criticism in the mainstream media as well as the financial media during the financial crisis. We will discuss the difficulties in risk managing structured credit portfolios. We will also emphasize just how crazy some parts of the financial market have become in the lead-up to the financial crisis. Now it's also worth pointing out that the mechanics of how CEOs work have much in common with the mechanics of how a default swaps. And you already have seen credit default swaps. So it's probably worthwhile reviewing and making sure you understand credit default swaps and their mechanics. Before, continuing on with these modules on structured credit and CDO's. One final point I'll mention, is that if we're ever going to control the excesses in the financial system. Then I think we're going to need a much better understanding of finance outside the finance industry, and certainly the whole, the whole area of structured products. Securitization and so on is considered somewhat mysterious to some people who are not in the financial industry. So I think even understanding the mechanics of securitization, the risks of these new securities is important for people who don't work in finance. But for politicians, journalists, lawyers and so on. So, I think that's another benefit of studying securitization, and studying CDO's as we're going to do in the next several modules.

### 026. The Gaussian Copula Model

In this module we're going to discuss and introduce the Gaussian Copula model. This model came under a lot of criticism during the financial crisis. So it's very much worthwhile introducing it here, and seeing how the Gaussian Copula model actually works. We're going to use it to construct the probability distribution of the number of losses in a reference portfolio of bonds. This reference portfolio will be the portfolio underlying CDOs and CDO chances that we will discuss in later modules. We assume there are N bonds, or credits, in the reference portfolio. Now, I use the word, credit, here because sometimes that is how the underlying bonds in the pool are referred to. So a credit can refer to a bond or it can refer to a company like General Motors, or Ford, or so on. So I'm going to use bonds and credits interchangeably here. Each credit has a notional of Ai. This is in dollars. However, sometimes it can be expressed as a percentage of the overall portfolio notional. If the ith credit defaults, then the portfolio incurs a loss of Ai times 1 minus Ri. Where Ri is the recovery rate that is the percentage of the notional amount that is recovered upon default. Now, we've seen this already in the context of credit-default-swaps. From a modeling perspective Ri is often assumed to be fixed and known. In practice however, it is random and not known until after a default event has taken place. We're also going to assume that the risk-neutral distribution of the default time of the ith credit is known. And in fact this can be estimated from either credit-default-swap spreads or the prices of corporate bonds. Therefore we can compute qi(t), the risk-neutral probability that the ith credit defaults before time t for any t. So we're going to assume that we know these probabilities for all of the names, all of the bonds in the portfolio, and for any time t. Remember, for credit default swap, you can actually compute the term structure of spreads or premier, so this is t. This is the fair spread in the credit-default-swap, and you might see some function like this for different maturities. And so, you can back off from this what these qi of t's are. So, we're going to assume that these qi of t's are known to us. So now, let's discuss the the Gaussian Copula model. We're going to let Xi denote the normalized asset value of the ith credit. So, Xi you can think of if you like as referring to Di plus Ei. So, this the debt plus equity of the ith company. As I've said, the company could be Ford, or General Motors, or Volkswagen, or any company you like. We're going to assume that Xi is equal to ai times M plus the square root of 1 minus ai squared times Zi, where M and the Zi's are standard ith ID normal random variables. Note, note also that each Xi is also a standard normal random variable. Each of the factor loadings, ai, is assumed to lie in the interval 0, 1. It should also be clear that the correlation of Xi, Xj is equal to ai times aj. And this follows because the correlation of Xi with Xj is in this case, equal to just the expect value of Xi times Xj. And that is true because the Xi's are standard normal random variables, which means the have mean 0 and variance 1. So normally I compute the correlation as being the covariance divided by the square root of the product of the variances. Well the variances, in this case, are 1. So now I don't have to divide by anything. The, the covariance is the expected value of Xi Xj minus the expected value of Xi times the expected value of Xj. But the expected value of Xi and Xj is 0. So therefore the correlation is just equal to this term here, and clearly then this is equal to ai, aj, times the expected value M squared. And M is a standard normal random variable, so the expected value of M squared is equal to 1. And so that's how I get this expression here. It should also be clear that the Xi's, our multivariate normally distributed, an we'll use that as well, in a moment. We're going to assume that the ith credit has defaulted by time ti, if Xi falls below some threshold value xi bar. An that's a function of ti, but generally will just refer to xi bar. By our earlier assumption, it must therefore be the case, that Xi bar equals phi inverse of qi of ti, where phi is the standard normal cdf. Why is this? Well if you recall, we said that qi, we said qi of t is the risk-neutral probability of default by time t. We also said that the ith credit defaults by time ti if Xi is less than or equal to xi bar of ti. What the probability of this occurring, we know is equal to phi of xi bar of ti. Because the Xi's have a standard normal distribution. So this is equal to phi of xi bar of ti, but we also know it's equal to qi of ti. And so therefore we see that xi bar just apply phi inverse to both sides of this equation, we see that xi bar of ti is equal to phi inverse of qi of ti. We're going to let capital F of t1 up to t capital N denote the joint distribution of the default times of the n credits in the portfolio. Then we know that F of t1 up to tn must be equal to the following. It's equal to the probability that X1 is less than or equal to x1 bar of t1, all the way up to Xn being less than or equal to xn bar of tn. Because this is the event that X1 up to Xn defaults before times t1 up to tn, respectively. However, X1 up to Xn is a multivariant normal distribution. So this is equal to phi P, the phi is in bold so that represents a multivariate normal distribution. P refers to the covariance or in this case the correlation matrix. And it's got a mean 0 as well, and it's evaluated, the arguments of this multivariate normal CDF are x1 bar of t1 up to xn bar of tn. So that gives us this line. And now we just substitute n for these x1 bars using this expression here, and that's how we get this equation down here. So, believe it or not, even though this is very simple, there's lots of notations, so on, but it's actually very simple to, to derive this expression, given our assumptions. What we have is the infamous one factor Gaussian Copula model. So this here give us the one factor aspect Gaussian Copula model. It's one factor because we just have one random variable m driving the dependent between the Xi's. If we go back to the previous slide, we'll see m appearing here. M is a random variable that is uncommon to all of the XI's. So all of the correlation between the XI's comes from this random variable M. If we introduced a second random variable, say n that was also common to all of the XI's then we would end up with a two factor Gaussian Copula Model. The next task is to actually compute the so-called portfolio loss distribution. In order to price credit derivatives and CDOs in particular, we need to be able to compute this portfolio loss distribution. So that's our first goal here. The first thing we'll do is we'll note the following. That if we condition on the random variable M, then the n default events are independent. And in particular the default probabilities conditional on the random variable M are given to us by these expressions here. Now where does this come from? Well, this comes from the following, we know that qi t of M or t given M is equal to the probability that Xi is less than or equal to xi bar of t given M. Well, we know what Xi is equal to. So we can substitute n for Xi. This is equal to the probability Xi is equal to ai times M, plus the square root of 1 minus ai squared times Zi, is less than or equal to xi bar of t, given n. So this is then equal to the probability that Zi is less than or equal to xi bar, t minus ai, times M divided by the square root of 1 minus ai squared. And that's all conditional on M. Now if you think about it for a second conditional on M, if we condition on M as we have here then everything on the right hand side here is a constant. Zi is a standard normal running variable. So this just becomes the probability that a standard normal running variable is less than or equal to. This expression here, and so that's equal to phi of what we have inside here, so that's what the conditional risk neutral default probabilities are. There are qi of t given n's. Now let P superscript n, l of t denote the risk neuter probability that there are a total of l portfolio or defaults before time t. We may then write pl of t as being the integral for minus infinity to infinity of p superscript n l of t given M times phi of MdM where phi is the standard normal PDF. Now if you're wondering where this expression comes from, well, this is just a standard basic undergraduate expression for probability. In discrete form, you can imagine the following. Suppose we want to compute the probability that X is equal to little x. Well, a standard way of doing this is to consider another random variable y, and to sum over all possible values of y. So it's equal to the probability of X equals little x, and Y equals little y. And this is also equal to the sum over little Y of the probability that X equals little X. Given Y equals little Y by the probability that Y equals little Y. So this is a standard expression you probably all seen before in your undergraduate probability class. We're just using this here and. In density form rather than discrete probability mass function form. So M here takes the place of y. So we have our m here, taking the place of y over here, and so instead of a summation, we have an integral. And we're integrating with respect to m instead of summing over the y values here. So this is standard, so we can now write the probability of l default, and just to be consistent, I should have put a superscript n there. So the probability of l default out of the n names by time t, is given to us by this integral here. So the next task is going to be how do we compute this quantity? We know phi of M, it's just the standard normal density. So, we need to compute this quantity here. We can compute this quantity, then we can evaluate this integral numerically, and therefore compute this risk-neutral probability function here. So let's focus on how to compute this expression here. So, in fact, we can easily do it using an iterative procedure, and the iterative procedure will work as follows. So the first thing we're going to do let's initialize. We're going to have to run a couple of for loops here. So let's initialize our quantities first of all, we're going to set p 0. Given M to be equal to 1 minus q1 of M. We're going to set p1, given M to be equal to q1 of M. And we're going to set p2 given M to be equal to P3 given M all the way up to Pn given M. We're going to set all of that equal to 0. Now, what I'm doing here is, I'm dropping the dependence on n and t here. So, I don't want the slide to get too cluttered. If I did I'd have an n in all of these values here. And I'd have a t in here, and so on. But that's just going to get really cluttered. So, I won't do that. So, I'm dropping the dependence of these quantities on n, and t. So, now we're going to do the following. We're going to run the following for loop, we're going to say. For i equals 2 up as far as n. And, for j equals 1 to i. I am going to update these quantities here that i have already initialized. In particular I am going to say. P, j given M so this is the probability of j defaults, conditional on M. So this is going to represent the probably of j defaults in the first i names. So there, there are two ways we can get j defaults in the first i names. We could have j minus 1 defaults in those first i names, and having the ith name defaulting. Which is represented here or we could have had j defaults in those first i names. And then having the ith name not defaulting. So that's the end of this for loop. We must also handle the, the case of 0 defaults. So we must also update that. We get the probability of 0. Given M is equal to whatever the previous value was or the value in the previous iteration. Times 1 minus qi of M. In other words, what I'm really doing here. So this is the end of the, of the algorithm. What I'm really doing here is I'm lining up the names. I'm ordering them from say, 1 all the way up to to nth names. I know the risk neutral probability given n for all names. And I'm going through these names these credits in order starting with 1, all the way up to value capital N. I'm doing that via these two for loops here, and I'm updating the probabilities at each step. So, as I said here, so if I'm at this point, for some value of i and some value of j, what I'm doing is the following. I'm now going to update the probabillity of the j defaults. In the portfolio based on the first i names. So, the way j defaults can occur among the first i names is that j minus 1 defaults occur in the first i minus 1 names. Remember this value here is the value left over from the previous iteration. Which considers the names from 1 up to i minus 1, so I get this equals the probability of j minus 1 defaults in the first i minus 1 names. Times the probability that the ith name defaults, plus the probability of j defaults in the first i minus 1 names, by the probability that the ith name does not default. And so I can just run through these two four loops to compute pN l of t, given M. So in other words, at the very end once I get up to , N, i equals capital N and j equals i at the end of this procedure I have the probabilities that I want. And now at this point, we can perform a numerical integration on the right hand side of 2 to compute Pl of t. So this is Pl of t here. I now have computed all of this using that iterative procedure, and I can do numeric integration to calculate this quantity here. And there should be a super script in there as well. If we assume that the notional ai. And the recovery rate ri are constant across all credits, then the loss on any given credit will be either 0 or a times 1 minus r. Therefore knowing the distribution of the number of defaults is equivalent to knowing the distribution of the total loss and the reference portfolio. And that's because l losses on that case is equivalent to a loss of l times a 1 minus r and the portfolio of bonds and so knowing one implies the other. So this, the assumption of constat Ai's and Ri's actually simplifies the calculations, and we're going to be assuming that through out here. But I will mention that this assumption is easily relaxed. We could actually get by without it.

## 015.A Simple Example

### 027. A Simple Example  Part I

In this module, we're going to look at a simple CDO example, where there's just one period in the model. We're going to assume that all the bonds in the reference portfolio have the same risk neutral probability of default. We'll also assume that all the pair-wise default events have the same correlation parameter rho. So these simplifying assumptions will enable us to easily calculate the loss distribution in the bond portfolio, and we will use it to compute the expected tranche loss in some tranches of a CDU. So in this simple example we're going to consider it is going to be a one period CDO. CDOs in practice are over multiple periods, but here we're just going to consider a one period CDO. The maturity is one year, or if you'd like one period. We'll assume that we've got 125 bonds in the reference portfolio. in case you're wondering why are choosing a number like 125, and not a, a, a st, more standard number like 100. Well, that's maybe a legacy of what goes on in the synthetic CDO market which we will discuss later. In those portfolios you often get 125 bonds in the so called reference portfolio, and that's why we're using 125 here. We're going to assume each bond pays a coupon of one unit. After one year, and that is if it has not defaulted. The recovery rate on each bond is 0, so in fact, if a bond defaults at any time over the next year, then the bond will pay 0. If it doesn't default then the bond will pay one unit. In one year's time, at the end of the CDO. We will assume that there are three tranches of interest. The equity, mezzanine and senior tranches. So the equity tranche is always the tranche which has a lower attachment point of zero. The senior tranche often has an upper attachment point of 100. But here we're actually going to assume that the senior tranche is exposed to default numbers seven up as far as nine. In fact, maybe a super senior tranche would be represented by these dots here, which would contain the defaults, or be exposed to the defaults. Num-, from numbers 10 up to 125. I will mention at this point, that this example we're considering is taken from this paper, the Devil is in Tails, Actuarial Mathematics and the Subprime Mortgage Crisis, by Donnelly and Embrechts. This is a very nice paper. It discusses CDOs, subprime CDOs, the crisis. It's a little bit technical in part, but much of it is readable for an undergraduate audience, and I'd certainly recommend those of you who are interested in learning more to go ahead and take a look at this paper. It can be easily found online. We're going to make the simple assumption that the probability q of defaulting within one year is identical across all bonds. We're also going to assume that the correlation between each pair of default events is identical. So these assumptions plus the fact that the maturity is one year and that this is just a one-period CDO is what makes this example particularly easy to analyze. As before, we assume X i is the normalized asset value of the ith credit. Or the ith bond, and now we're going to write that X i is equal to the square root of rho times M plus the square root of 1 minus rho times Z i. Where M, Z 1 up to Z n, are IID normal random variables. And recall that this assumption also implies that X i is also standard normal mean zero variance one. Recall that the ith credit defaults if X i is less than or equal to little x i bar. Therefore, the probability that the ith main defaults, is equal to the probability, we write it up here that X i is less than or equal to little x i bar. This must be equal to phi of little x i bar, because x i is the standard normal random variable, and phi's the standard normal CDF, so this is true. But we're all assuming that this is also equal to q. This is the probability of defaulting within one year, so this is equal to q, and from that, we see that if I take phi inverse across both sides of this expression here, I see x i bar equals phi inverse q. And that's what we down here. So the probability that x i defaults conditional on M is going to equal to the probability that X i is less than or equal to little x i bar. I can substitute equation three in down here. Replace x i bar with phi inverse q. Take the M term over to the right hand side, divided by the square root of 1 minus rho, and I get this expression here. This is what we're going to call q subscript M, this is going to be the risk neutral probability that X i defaults, conditional on knowing the value of the random variable M. What is also clear, is that this is equal to the standard normal CDF evaluated at this value here. Because Z i is a standard normal random variable. Therefore, conditional on knowing the value M, the total number of defaults is actually binomially distributed with parameters n, the number of names in the portfolio, the number of credits, the number of bonds and probability q M. Why is that? Well if you think about it, conditional on knowing M, we've already seen what's the probability of default is, it's q M. But also conditional on knowing M, all of these default events become independent. Because X i depends on M and Z i, and Z i, the Z i's are IID normal random variables. So, if I condition on the value of M, then the X i's become independent, which in particular means that the default events of all of the names in the portfolio are also independent. The probability of default conditional on M is q M. So therefore, the total number of defaults in the portfolio condition on M has a binomial distribution with parameters of M and q M. So therefore the probability of l defaults, and note I've dropped the dependence on t here which is fine. Because we're just considering one period with t equals one year. So therefore the probability of l defaults, out of the n names in the portfolio. Or n credits in the portfolio, conditional on the value of M is binomially distributed. And this is equal to N choose l times q M to the power of l, times 1 minus q M to the power of N minus l. Where phi we said in the previous slide is the standard normal CDF, and we know this expression for q M as well. Recall the q the risk neutral probability of a single name default within one year. So just be clear. You shouldn't get confused between q and q M. Q is the risk-neutral probability of a single name defaulting within one year. And qM is the same probability that is the risk neutral probability of a single name defaulting within one year, conditional on the value of M. So here are two questions. The first question is the following, when correlations on default probabilities are not identical, why is four no longer valid? Well, that's because, if the correlations an default probabilities are not identical, then these qM's are not the same for all of the names in the portfolio. You end up having a different qM, for each of the N names. So this quantity here is no longer a binomial. Random variable or a binomial probability. Next question, how do we calculate P superscript N l M in that case. Well, we'll just do it as we did in the last module, we saw that we had an iterative algorithm, remember we had the two nested for loops. That was the way, how we calculate P N of l in general. In this example, we don't need to run through those two for loops, because here we can just use the fact that the qMs are identical for all names I equals 1 to capital N. And therefore this is a binomial probability and we know this expression. [SOUND] So at this point, in this example, we actually know this quantity here. This quantity is a binomial probability. Assuming we can calculate q M, and we can because q M can be calculated as this expression here. We know these binomial probabilities, and so in particular we know the risk neutral probability of l defaults occurring conditional on the random variable M. How can we use this knowledge? Well, we can use it to compute the expected tranche losses. And that's what we're going to do in this slide. First of all, maybe I should go down to equation five first. So remember, what we're going to say is the following. The probability of l losses. Is equal to the probability of l losses given M times phi M and integrate that with respect to M. That's just using this trick we mentioned before from our undergraduate probability course. If I want to know the probability that X is equal to little x, well I can do that by summing over y the probability that X equals little x, Y equals little y. Which in turn is equal to the sum over little y of the probability that X equals little x given Y equals little y, by the probability that Y equals little y. So here we're identifying M with the random variable Y, and instead of a summation, we have an integral. But that's all we're doing here. So we know how to compute these quantities, we saw that on the previous slide, that these are binomial probabilities. So these are binomial probabilities and therefore we can do a numerical integration to calculate p of l. For any value of l equals 0 up to capital N. So we know that p of l's, we can do it very easily by integrating this expression numerically. So now let's turn to the issue of computing the expected tranche losses. In the equity tranche, we can actually lose either zero, one, two, or three. So the expecwe, expected equity tranche loss will be, k equals 1 times the probability of one default by year end. Plus k equals 2 by the probability of two defaults by year end. Plus k equals 3 by the probability of three or more defaults by year end. Remember the equity tranche is on the hook, if you like, for the first three losses in the portfolio. So, the most that the equity tranche can lose is actually three. But it will lose three if we have three or more defaults by year end. And so that's how we get the expected equity tranche loss. Let's turn, for example, to the expected senior tranche loss. Well, the senior tranche can only lose one, two, or three. You see back here that the senior tranche is on the hook for defaults seven to nine, so the most it can lose is nine minus, actually six, which is seven minus one, is three. So it's on the hook for these three defaults, seven, eight, and nine. So some that hope for three units, the most it can lose is three units. It will lose nothing if there are less than or equal to six losses in the portfolio. It will lose one, if there are exactly seven losses in the portfolio. It will lose two if there are exactly eight losses in the portfolio, and it will lose three. If there are nine or more losses in the portfolio. And that's represented over here in this expression for the expected senior tranche loss. So you should make sure that you're very comfortable and understand where these expressions come from. The equity, the equity tranche is on the hook for the first three losses. The Mezzanine tranche is on the hook for the next three losses. So, those losses will be lost as four, five and six. The Senior tranche is then on the hook for the next three losses, which would be losses seven, eight, and nine. And so these are the expected tranche losses for each of those three tranches.

### 028. A Simple Example  Part II

In this module, we're going to continue on with the example we introduced in the last example. That was the simple model, it was a one period model with identical risk mutual default probabilities for each bond in the reference portfolio, and so on. So what we're going to do here is we're going to look at some of the tranche losses or the expected tranche losses. And we're going to look at the characteristics of these expected tranche losses as a function of the correlation parameter rho and so on. We're also going to see how the total expected losses in a portfolio does not depend on the correlation parameter rho. So recall the details for our simple example. We want to find the expected losses in a CDO, or in CDO tranches, with the following characteristics. The maturity is 1 year, and it's just a 1-Period CDO, there are 125 bonds in the reference portfolio. Each bond pays a coupon of one unit after one year, if it has not defaulted. And the recovery rate on each bond is zero. So in particular, if a bond has defaulted before the one year is up, then that bond will pay a coupon of zero. There are three tranches of interest, the equity, mezzanine, and senior tranches. The equity tranche is exposed to defaults 0 to 3, the mezzanine tranche is exposed to defaults 4 to 6, and the senior tranche is exposed to defaults 7 to 9. We saw in the last module that we could actually compute the expected tranche losses. We saw our expressions for the expected loss in the equity tranche, the expected loss in the mezzanine tranche, and the expected loss in the senior tranche. So, on this slide, we're actually going to see what these expected losses are as a function of rho, which is the common pairwise correlation between the various name in the portfolio, and the individual risk mutual default probability. So this is the q = 1%. So this corresponds to the case where the probability of each individual name defaulting is 1%. So there's 125 bonds in the portfolio, we assume each of them defaults would probability equal to 1% here. Over here, each of them default to probability q=2%, down here, 4%, and over here, 3%. And on the y-axis we have the expected losses. Note, we have 125 names in the portfolio. Each name will pay one unit, if it hasn't defaulted after one year. So therefore, the total portfolio notional is 125. The equity tranche is on the hook for the first three losses, so the equity tranche can lose a maximum of three. The mezzanine tranche is on the hook for losses 4, 5, and 6. So the maximum the mezzanine tranche can lose is also three. Likewise, the maximum the senior tranche can lose is also a three. It's on the hook for losses 7, 8, and 9. So the maximum loss in any of these tranches is three, and that's why you don't see in any of these cases anything greater than three on the y axis. Across the x -xis, we're actually plotting these expected losses as a function of the correlation parameter rho. So this is that value rho we saw in the last module, which defines the normalized asset value, xi. So there are some important observations we should make here. The first observation is the following. Regardless of the individual default probability, q, and correlation parameter, rho, we see that the expected equity tranche loss is greater than or equal to the expected mezzanine tranche loss, is greater than or equal to the expected senior tranche loss. Now this only holds when each tranche has the same notion exposure, in this case three units. So we see it here. We see the blue line, which is the expected tranche losses in the equity tranche, is always greater or equal to the red line, which corresponds to the mezzanine tranche, which in turn is always greater or equal to the senior tranche, expected losses. And that makes sense. After all, we can see that the equity tranche is the riskiest. You can only lose, the mezzanine tranche can only lose, if the equity tranche has already lost everything. In other words, if you have four defaults, the mezzanine tranche loses one unit, then that means we've had more than three losses, and the equity tranche has lost everything. Similarly, if the senior tranche is to lose anything, than that can only be the case if we have seven or more losses, which means the equity and mezzanine tranche have already lost everything as well. And so we should be absolutely certain and understand why the expected losses in the equity tranche must be greater than or equal to the expected losses in the mezzanine tranche, must be greater than or equal to the expected losses in the senior tranche. Another important observation is that the expected losses in the equity tranche are always decreasing in this correlation parameter, rho. So we see it here. So let's pick q=2% for example. If we look a q=2%, we can see that the equity tranche losses is a decreasing function of rho. And in fact it's true in all four graphs, it's always a decreasing function of rho. Why might this be the case? Well, one easy way to see this, perhaps, is the following. Imagine two possibly different values of rhos, so imagine rho being equal to 0, or rho being equal to 1. Well, if rho is equal to 1, well, then what happens, either all of the names, all of the credits default together, or none of them default together. So in that case, the equity tranche will actually be as risky as the senior tranche, because either all of the names default or none of them default. The probability of all of them defaulting will therefore just be q = 1% in the 1% case, or 2 in the 2% case, and so on. So in other words, let's considered this example here. So the q=1% case, for numerical reasons we didn't take the value of rho all the way equal to 1, but we can look at the value rho = 0.99 to see what's going on. In these case, either all the names default together or none of them default. In that case, the three tranches are all equally risky, and so the probability of any one defaulting is 1%. So the expected losses in the tranche is going to be 1% times 3, which is 0.03. So this value here is roughly 0.03. On the other hand, if rho equals zero, well because there's no correlation among default events, we'll always expect there to be maybe just one default or one or two defaults or zero defaults. But what it means is that most of the time we're actually going to see a default, maybe one, maybe zero, but sometimes two or three. And so with such a low correlation, we'll always expect to see some credit event happening. And because it's the equity tranche that is on the hook for that first credit event, we expect the equity tranche to incur losses most of the time. And that's why we see this number being much higher for a low value of rho. And in fact we'll see this behavior for all values of q. Down here for example, we see q = 4%. And we see the expected tranche loss is now almost 3, and that's because we expect with q = 4%, we expect there to be 4% of 125, which is 5. So we expect to see on average five losses in the portfolio. Because correlation is very low down here, we're always going to expect to see almost five losses in the portfolio, which means that most of the time the equity tranche will be wiped out. We're going to see more than three losses. Most of them we're going to see four or five losses maybe. So, that's why it will be wiped out. Down here, for example, when rho equals 0.99, sure, we do on average expect to see 4% losses, which corresponds to 5 port-names defaulting. But they're all going to default together or not at all. Which means 96% of the time, in fact, the equity tranche won't be hit at all, and only 4% of the time will it see a loss of 3. 4% of 3 is 0.12, so this number here is roughly at the 0.12 level. So that's the first two observations. Another observation to note is the following, mezzanine tranches are often relatively insensitive to rho. We can see that, for example, perhaps most easily in this plot, when q = 1%. Which in many cases in practice might be the most relevant example, because in practice, depending of course on the nature of the names in the portfolio, you will often see a q of approximately 1%. So you see here that actually certainly maybe in this range here that I am circling, You see that the expected tranche losses don't very much with rho at all. And actually this is a commonly observed phenomenon. Also, it actually has implications when it comes to model calibration. Now we're not going to get into model calibration for this Gaussian Copula model, I might say a few words about it in a later module, but generally we won't have time to go into it in any detail. So that's the third observation here. So I have two more observations I want to make, but I'm going to make those observations when we change the problem slightly. In the remainder of this module, we're going to assume that the senior tranche is now on the hook for all losses between 7 and 125. So, it's not between 7 and 9, it's all losses between 7 and 125. What we will see then, and we'll see it on the next slide, is that the expected loss in this senior tranche, sometimes called a super senior tranche, will see that it's increasing in rho. And sure enough we can see that. So this is the green here. We see it is always increasing in rho, regardless of the value of q. And actually the reason for this is the same reason why the equity tranche expected losses are always decreasing in rho. So the same intuition I gave will actually also apply in the opposite direction to the expected losses in the senior tranche. The final thing to note, and this might not be so obvious from the figure, because I'm not giving you the individual numbers. But the total expected losses on the three tranches, that is, the expected losses on the index. Remember, all of the index, now the index consists of all 125 names. And the three tranches are equity, 0 to 3, the mezzanine tranche, 3 to 6, and now the senior or super senior tranche is 7 to 125. So now these three tranches now all add up to entire index, all 125 names. And the point I'm making, and you can see it on the next slide, is that the total expected losses on the three tranches is independent of rho. This is not an accident. So what am I getting at here? Here's what I'm getting at. Let's pick this figure here q=3. If I fix a value of rho, say rho equals 0.1, and sum of the losses for the three tranches at rho equals 0.1, I'll be summing up maybe this number plus this number, plus this number. And that will equal to the losses at any other value of rho. So if I take rho equals 0.7, then this, this and this number here, the sum of these three, will be equal to the sum of these three numbers over here. Why is this occurring? Well, we can analyze it. We can show that this is no accident as follows. The expected losses, the expected losses using the risk mutual probabilities, so the expected total loss, Is equal to the expected value of the sum of the losses from i equals 1 to 125 of the indicator function that the ith bonder name defaults. I'll just use the capital letter D and E F to denote default. Now, I would normally multiply this by Ai(1-Ri), but, by assumption, we have said that the Ais are equal to 1. And the Ris are 0, so in fact this term here is just 1. So in fact, I can ignore this piece here, and I get that. Well this is just equal to the sum, From i = 1 to 125 of the expected value, Of the indicator function of the ith name defaulting. This is equal to, The sum from i = 1 to 125 of the probability of the ith bond defaulting. And, the important thing to notice here, is that this, the probability of the ith bond defaulting, well, this is equal to our q, but this certainly does not depend, On rho. And so we see that the expected total loss in the portfolio, which is equal to the total loss and the sum of the three tranches in this case, is equal to this quantity over here, and that does not depend on rho. And that's why we see this behavior I was describing a moment ago. However, it is worth pointing out that the allocation of these losses to the three tranches, the three separate tranches, does indeed depend on rho. We can see, as before, that the expected tranche losses in the equity piece are decreasing in rho, this will always be the case for an equity tranche with lower attachment point equal to zero. Similarly, we can see that the expected tranche losses in the senior tranche are always increasing in rho. And this is true for any senior tranche with an upward attachment point of 100%, or in this case 125 units.

## 016.Understanding a CDO Tranche

### 029. The Mechanics of a    Synthetic    CDO Tranche

[BLANK_AUDIO] . In this short module, we're going to discuss the mechanics of a synthetic CDO tranche. While we haven't actually described for you what a synthetic CDO tranche is yet, we will actually do that in a later module. In particular, we will distinguish between a cash CDO and a synthetic CDO. But for now, we're just going to go into the details of the mechanics, of how a synthetic CDO tranche actually works. So now let's discuss the mechanics of the synthetic CDO tranche. I'm going to describe or explain for you, the distinction between a synthetic and a cash CDO in a later module. For now we're just going to discuss the details of a synthetic tranche. As I said, I will distinguished between the synthetic and a cache CDO, in the later model. So recall there are N credits in the reference portfolio. Each credit has the same notional amount, A. If the ith credit defaults, then the portolio incurs a loss of A times 1 minus r. Where R is the recovery rate which is assumed fixed, known, and constant across all credits. A tranche is defined by the lower and upper attachment points, L and U respectively. So, we've already seen examples of L and U, L and U, 0 to 3 and so on. 3 to 6, 6 to 9. Usually L and U are given as percentages of the total portfolio notional amount. In our simple example on the previous two modules, L and U were given as the number of losses. 0, 1, 2, or 3, 4, 5, or 6, 7, 8 or 9, or so on. But, typically in practice, they're given as percentages. The tranche loss function, TL for tranche loss, superscript l and u, to denote the lower and upper attachment points are parameters of this function. So its a function of the number of losses in the portfolio L, is a function given as follows. First of all we take the minimum of LA1 minus R and U. So this, here, is actually the total portfolio loss. So if the total portfolio loss exceeds U, then the tranche loss is given by U. After all, the tranche cannot lose more than U. U is the upper attachment point, it cannot lose more than U. So if the total portfolio loss exceeds U, then this minimum is given to us by U. Otherwise the minimum is given by the total portfolio loss. Now the lower attachment point is L, so we then have to subtract L from this minimum here. And finally we take the maximum of that last quantity and 0, and that gives us our tranche loss. It tells us for a given number of defaults, what loss is suffered by the tranche. So for example, suppose L is 3% and U is 7%, so we've got some sort of CDO as follows, maybe there's an equity piece here, which is the 0 to 3%, we've got a mezzanine tranche, which is maybe 3 to 7, and so on. Well, suppose the losses in the portfolio add up to 5%. Well, in that case, this piece represents the losses in the portfolio. The first 3% of losses are incurred by the equity tranche. But the next 2% of losses fall in here, and they are incurred by this tranche here, with lower attachment point l equals 3%, and upper attachment point U equals 7%. So, therefore, the tranche loss is 2%, and actually, that's 50% of the tranche notional. The tranche notional is 7% minus 3%, which is 4%. So, we've incurred 2% losses out of a total maximum loss of 4%. So, therefore, in this example we have lost 50% of the tranche notional. When an investor sells protection on the tranche, she's guaranteeing to reimburse any realized losses on the tranche to the protection buyer. In return, the protection seller receives a premium, at regular intervals from the protection buyer. These payments ticky, typically take place every three months. So, when you see the word protection here, what you might want to do is think of it as being insurance. So protection, think of this as insurance. And what's going on here, is that one person is selling insurance, and the other person is buying insurance. So the person who's buying insurance, is insuring against losses, in the underlying portfolio that impact their given tranche. In return for providing insurance, the insurance seller receives an insurance premium. And they receive that premium at regular intervals, from the protection or insurance buyer. In some cases, the protection bar may also make what is called an upfront payment, we're not going to be concerned about this. But sometimes they might make enough front payment, in addition to, or instead of the regular payment which might take place every three months. This is often the case, for example, in the case of equity tranches which, as I said earlier have a lower attachment point of zero. The fair value of the CDO tranche, is that value of the premium plus upfront payment, if applicable, for which the expected value of the premium leg equals the expected value of the default leg. So, just like a swap, the initial value of a CDO tranche position is 0. Now, if this doesn't seem very clear to you yet, that's fine, we're going to see a diagram of the next page, which will make it clearer still. And then in the next module, we're going to go through the premium leg and the default leg in more detail, so that hopefully the two legs of a CDO tranche position, should become clear to you, and you understand exactly what is going on, with a CDO. Another point I want to make is the following. We have already seen the tranche loss function, we're going to need to compute the expected tranche loss function, nor did it compute the value of the CDO. We actually already computed this, in our earlier example, our one period example. We computed the expected tranche loss in an equity tranche, a mezzanine tranche, and the senior tranche. Well, the expression we used for that was just this ex, this expression here. So, it's equal to the sum from L equals zero to capital N, T L T of L times the probability of L losses in the portfolio. And remember, we can compute this probability by conditioning on the random variable M, which makes the default events of each name independent. So, we're, we were then able to compute this quantity, either using the iterative. In that case for a simple example, we saw that this was just a binomial probability. But either way, we can compute this. This is the standard normal PDF, so we can compute this quantity using a numerical integration. So this gives us our expected tranche loss function. So now let's see what happens visually with a CDO. We've got a number of periods, so we've got a period here, here, here and so on. This is the premium leg. So these are the payments made by the person, or investor, who buys insurance, or buys protection. S is the annual premium, or spread per unit of notional. These here, are default events. We will see in the next module, that the tranche notional decreases after each default. So, we, these vertical arrows represent the size of the payment. Because S is an annual spread, we have to multiply be delta T, which is the length of an interval. Typically approximately one quarter, representing payments every three months. So the, the, the premium per quarter will be delta TS. It's paid on the notional of the tranche, and in fact it's paid on the outstanding notional on the beginning of each period. So at this point, there haven't been any defaults yet, any default's that have impacted to tranche yet. At this point we have a loss, and this loss impacts the tranche, so this actually decreases the notional of the tranche, by an amount of 1 minus RA. and so we get decreased payments, after each default event. So a second default event occurs here, this default event also impacts the tranche, and that lowers the outstanding notional in the tranche. And so the insurance payments, or the premiums, are payed only on the outstanding notional in the tranche. As I've said in the previous slide, this is just a schematic, describing basically what goes on in the CDO. We have two legs. We have the premium leg, and we have the default leg. If you like, you can think of this like being a swap, where we've go the fixed payments and we have the floating payments. The fixed payments correspond to the premium leg, they're not always fixed. The rate is fixed, the delta TS, but they're paid on the outstanding notional. The default lagger like the floating payments, you're never sure what you're going to get in each period. Most of the time you'll get nothing, if there hasn't been any default event in the tranche. But if there has been a default event that impacts the tranche, you will receive a payment. You will receive an insurance payment, for that event of 1 minus R times A. And we will see in the next module, that the way the CDO is priced, or in other words, the way the S value is calculated. It is calculated by equating the value of the premium leg with the default leg. And so the initial value of an investment in a CDO tranche would be zero, and we're going to find what value of S makes that value equal to zero.

### 030. Computing the Fair Value of a CDO Tranche

In the last module we saw the mechanics of a synthetic CDO tranche. We saw there was a premium leg and a default leg. Well, in this module, we're going to price the premium leg and we're going to price the default leg. We're then going to set these two prices equal to each other. And as a result, we will be able to calculate the fair premium of a CDO tranche. So let's start with calculating the fair value of the premium leg. The premium leg represents the premium payments that are paid periodically by the protection buyer to the protection seller. These payments are made at the end of each time interval and they're based upon the remaining notional in the tranche. In this sense it is different to a CDS since the latter contract ends as soon as a default occurs. Here in the CDO. A CDO can survive well beyond an initial default. Multiple names can default and the CDO, the CDO tranche, may need to pay out upon each default event. Formerly the time T equals 0 value of the premium leg, which we're going to call P subscript 0, 0 denoting T equal 0 on superscript, L U which refers to the lower and upper attachment points respectively. So this quantity is equal to what's on the right inside here of expression six. So we have s which is the annualized spread or premium pay to the protection seller. So this would be a percentage, it might be 2%, it might be 3%, or it might be 10% for a chance where you expect to see many losses. But maybe it'll just be a quarter percent or some very small number as well for a chance which is relatively safe. DT is the risk free discount factor for payment day T. Delta t is the accrual factor for date t. So typically, delta t would be approximately one quarter corresponding to quarterly payments and is the total number of periods in the contract. So for example, if the CDO lasts or has a maturity of ten years and payments are made quarterly. Then this implies n will be equal to 40. So what's going on here is that the fair value of the premium leg. This is the fair value of the premium payments made over the n payments. It's equal to S times delta t. The sum from t equals 1 to n of S times delta t. Remember, S is an annual spread or premium, so we've gotta multiply it by delta t to get the payment made per period. So it's S times delta t. Times the expected notional remaining between periods T(-1) and T. So, remember the total notional of the is U minus L. So if U is 7% and L is 3%, then the total notional of the is 7 minus 3 equals 4%. The total losses in the tranche can't exceed U minus L. So this expression here is equal to the expected. Notional remaining at time period t- 1. And so the insurance, the s times delta t is made on this expected notion. Those payments, which occur at time T, they must be discounted back to time zero, and that's why we have this risk free discount factor here. Now I should mention I'm not going to worry about accrued payments and so on. And practice default events don't take place at the beginning or end of a three month period. They might take place in the middle. And maybe you might have some accrued payments as well but we're not going to get into that. The other leg of the CDO tranche is the default leg. The default leg represents the cash flows paid to the protection buyer upon loses occurring in the tranche. Formerly, the time t equals zero value of the default leg, which we're going to call DL subscript zero for t equals zero, superscript LU, satisfies this equation here. Again, DT is the discount factor. Be the sum from t equals 1 to n, representing the end periods in the CDO, and so payments occur when there is a default in the tranche. And the expected payments at time t, is given to us by this. Because if you think about it, this is the expected tranche loss at time T minus 1. This is the expected tranche loss at time T. So the difference is the expected tranche losses in the period from t minus 1 out to t. So these are the expected payments that must be paid by the seller of protection or the seller of insurance by time t minus 1 and t so these are the risk mutual expectant losses and the charge between these two periods. And we have to discount them back to time zero, using the discount factor in Dt. So while some programming is required, we can actually calculate these quantities very quickly. If I go back to the previous slide, I can see that I also have an expectation of a chance loss appearing here as well. So the key to computing the premium leg value and the default leg value, is being able to compute these expectations here. Now if you recall, just a reminder since we know, that the Tranche Larousse function is given to us as follows. We know that TL subscript t superscript L, U, it's a function of the number of defaults in the underlying pool of bonds or pool of credits. We know that that is equal to the maximum of the minimum lA(1-R) comma u minus L and 0. Now the only random variable in here is L, the number of losses in the portfolio. We also note that the expected value. Of the tranche loss, at time t, is equal to the sum, from l = 0, up to capital N TL Lu, T(l) times pl(t), pl(t) we saw in the one-factor Gaussian model. This is equal to the integral from minus infinite to infinite of p superscript n, l, t, given M times the probability density function from standard normal random variable, phi M, dM. And finally we saw that in general we could compute this. Using our iterative algorithm. That was the algorithm with the nested for loops, if you recall. We had a for, I think it was for i = 1, up as far as n. And then we had for j = 1 to i, and so on. So if you think about it, the big picture here is as follows. We want to be able to compute the fair value of a CDO tranche. In order to compute the fair value of a CDO tranche, we need to be able to compute the fair value of the premium leg, the fair value of the default leg. And what we're going to do is we're going to set those two fair values equal to each other to get the fair value of the spread s. But before we do that, we need to be able to compute the expected tranche loss function, and we can see, as we've written here, that this expected tranche loss function ultimately comes down to computing this integral here. And we can do this numerically. So, while we do need some programming, we do need to write some code to actual compute this quantity, we can actually get it to run very quickly. And, in fact, this is the principle reason for the Gaussian Copula model's popularity. It has many flaws, we may discuss a couple of them in later module if we have time. But the reason it's so popular is because it enables us to price very quickly a security that is in fact very complex. Remember, in a CDO tranche, we might have a 100 names or a 125 names in the underlying portfolio. Each of these names have different risk neutral probabilities of default at various times. They all have different pair wise correlations and so on. It's a very complicated product, a very complicated security with many moving parts and this Gaussian copula model enables us to price the premium leg and the default leg tranche very efficiently in practice. Okay let's move on to the final slide here. How do we compute the fair value of a tranche? Well, just like a regular swap, what we do is we determine the fair premium S star say, so that the premium leg is equal in value to the default leg. And so all we do is we equate six, which is this, this is the fair value of the premium leg, we're going to equate this leg, With the fair value of the default leg which is given to us by 7, and we're going to solve for S. And we're going to call that solution S*. And so we get S* equals to this expression here. Now one thing to keep in mind with this expression here. This expression here is modeled independent. We did not need a model, we did not need a model to compute S*. S* follows just by grading the premium leg with the default leg, and the quantities we need to actually compute S*, are these expectations here. I mentioned in the previous slide that we can compute these expectations numerically very easily using the Kopler model. So this is where a model comes in. So we need our model for this piece. Okay, and it's the Kopler model which became the standard in industry for computing these quantities. So as is the case with swaps and forwards, the fair value of the tranche to the protection buyer and seller at initiation, at the beginning of the contract, is therefore zero. It is easy to incorporate any possible up-front payments that the protection buyer must pay at time t equals zero. In addition to the regular premium payments. So that's also easy to handle but we won't get into it. Actually, it's also possible to incorporate recovery values and notional values that vary with each credit in the portfolio. Here we've assumed that R i is equal to a constant R for all i. And we've also assumed that notional value A i is equal to A for all i. But again I just want to emphasize that we could still use the Kopler model even if these assumptions didn't hold. In practice, the way it works is similar to what we saw when we were looking at the implied volatility surface for equity options. In practice, we actually don't compute S star. We actually see S star in the marketplace. There would be a market for these tranches in the marketplace. We would see the fair spread as star in the marketplace. And what we would try and do is back out a correlation parameter, let's call it rose say, which meant that this right inside, or that the model fair price S* or row was equal to the S* that we saw in the marketplace. And then row would be called an implied correlation parameter. So very analogous with what we saw with equity options and computing implied volatilities for a given strike and maturity. One point that's worth emphasizing is that if this Gaussian [INAUDIBLE] model was somehow correct, then you should see the same correlation value for different tranches. In other words, suppose I compute the fair correlation for a chance with attachment points, say 3% and 7% and then I can back out a correlation parameter row. Well I should see the same row if I change 3 to be 7 and I make 7 equal to 10 say. In other words, if the model was correct I should see the same value of rho regardless of what values of L and U I use. But in practice this is not the case. We see a different applied correlation for different attachment points L and U. And in fact it's possible in some circumstances to not be able to back out and apply the correlation parameter at all.

### 031. Cash and Synthetic CDOs

Up until now we focused mainly on synthetic CDOs, well we haven't actually described yet what a synthetic CDO is, and we haven't compared it to what a cash CDO is. In this short module we're going to discuss first cash CDOs, and then we will discuss synthetic CDOs, and describe the differences between these two types of CDO. The first CDOs to be traded were all cash CDOs, where the reference portfolio actually existed, and consisted of corporate bonds that the CDO issuer, usually kept on it's balance sheet. Capital requirements then meant that these bonds required a substantial amount of capital to be set aside to cover any potential losses. Now sometimes the banks however often wanted to reduce these capital requirements. They didn't want to tie up capital with these bond portfolios. So, what they did instead was they converted the portfolio into a series of CDO tranches, and they sold most of these tranches to investors. They usually kept the equity tranche for themselves. And therefore they actually kept most of the economic risks and rewards of the portfolio. If you recall, the equity tranche is the riskiest tranche. It has a lower[UNKNOWN] .0 and it could have been 0 to 2% or 0 to 5% or some such number. And so, most of the time many of these tranches or CDOs, all of the losses would have occurred just in this equity tranche. So, effectively the equity tranche, incurred all of the economic risk and reward of the portfolio. However, by selling off these other tranches, the banks were able to reduce substantially the amount of capital they needed to set aside. And so, they're able to keep on the economic risk and reward, which is what they want to do, but they did not need to set aside an enormous amount of capital. And so, these first CDO deals were therefore motivated by what is called regulatory arbitrage considerations. The idea is that they are arbitraging the regulations. Which said they would need to hold a substantial amount of capital for this economic risk. But in fact what they did was, they just tranche the portfolio up, kept the riskiest tranche here, which meant they kept pretty much all of the economic risk in the portfolio. And they were able to substantially decrease the capital requirements with just holding this piece of the portfolio. So, that's what regulatory arbitrage refers to. The cash CDOs however, must be managed, and the legal documentation can be lengthy. You've got what are called waterfall structures to manage and design. You've got what's called credit enhancement and so on, an other important features. So, what for example is a waterfall structure? Well a waterfall structure, describes what happens to coupons prepayments for example, in the event of a loan pool or a mortgage loan pool underlying the CDO. you might have some derivatives securities inside the CDO in order to change some of the characteristics of the, the underlying cash flows. Maybe you've got some floating rate bonds in the underlying pool of bonds, and you want to convert them into fixed-rate bonds. Well you could use an interest rate swap to do that. So, you will often have extra factors inside a cash CDO that need to be managed. Credit enhancement, on the the hand, refers to many CDOs. The issuer of the CDOs may want the traunches to receive better credit ratings. a credit enhancement refers to methods for doing this. One common way of doing credit enhancement is to over-collateralized the CDO. What that means is, if the nominal notional of the CDO, say, let's say it's $100 million is the nominal notional of the CDO. Well the bank might actually put $101 million into it, so there's an extra million dollars. And that extra million dollars would be referred to as an overcollateralization amount. So, there is different ways to make the, the tranches seem a bit safer and therefore, to get higher ratings from the rating agencies. We don't have time here to go into how these ratings agencies actually rated these CDOs, but I think it's fair to say that they didn't do a very good job of this. these structures are very, very complicated, the waterfall structures make them even more complicated. And the idea that you could actually create models To actually understand the riskiness of the securities is, is, is somewhat, somewhat optimistic to say the least. But as I said we wont go into this issue any further. Once these cash CDOs came into the market place, it became clear. That there was an appetite in the market place for these products. Hedge funds, for example, were often very keen to buy the riskier tranches, the equity tranches. And that's because the equity tranches having the most risk, also have the greatest expected reward, or expected payoff in the future. So, hedge funds were often keen to buy the riskier tranches. Insurance companies and so on, often sought to purchase the triple-A rated senior and super-senior tranches. Remember, these senior and super-senior tranches are the safest tranches. So you rarely expect to see any losses entering into these tranches. And so they're considered very safe. They were typically triple-A rated products. But maybe by selling insurance, on these senior tranches. The insurance setters might get 10 or 15 basis points more than they would get from buying triple-A rated products out in the marketplace. Maybe by buying triple-A corporate bonds. Maybe the coupons on those triple-A corporate bonds, were just a little bit less than the premium they could earn by selling protection on triple-A rated senior and super-senior tranches. This appetite and explosion in the CDS market gave rise to so called synthetic tranches, where the underlying reference portfolio is no longer a physical portfolio of corporate bonds or loans. Instead, it was a fictitious portfolio consisting of a number of credits with an associated notional amount for each credit. If you were confused by the distinction between cash and synthetic CDOs, Imagine a series of football games for example. So, lets suppose Barcelona are playing, I don't know lets say Bayern Munich, Aresenal are playing AC Milan, Real Madrid are playing Manchester United. And let's say Juventus are playing Paris Saint-Germain. So, we've got four games here. Now, what we can do is, we can actually bet, or speculate or, if you like, invest or hedge on the outcomes of these four games. And we can do that without anyone actually owning these games. In fact, I'm not even sure what it means to own a game. But it certainly doesn't stop us from constructing a bet, or a payoff, or a security, whose cash flows depends on the outcomes of these four games. So, now you can imagine doing the exact same, but instead of having these four football games. We replace them with four credits, maybe General Motors, maybe Ford, maybe IBM, maybe Siemens. And now we can construct securities whose payoff depends on what happens to these securities. So, that's how a synthetic CDO works. We don't own the underlying bonds. We don't own, there isn't a reference portfolio of bonds on GM, Ford, IBM and Siemens and so on that the bank owns. We just refer to these credits, just like we don't own these football games, we can still bet on the outcome of these games. Likewise we can invest in traunches whose payoffs depends on what happens to General Motors, Ford, IBM and Siemens. And in particular whether these companies default or not over a specified period of time. And, so, that's what I mean by a fictitious portfolio. We, there doesn't have to be an underlining physical portfolio of bonds, of the GM bonds, Ford bonds, IBM bonds and Siemas bonds. We can just see these names out in the marketplace, we can see at any point whether they've defaulted or not. And we can construct securities who's payoffs depend on the default events of these underlying names, or this underlying fictitious portfolio. The mechanics of a synthetic tranche are precisely as we described earlier. When we introduced the Gasling-Coppler model, and we looked at that one period example, we were actually pricing synthetic tranches. We were computing the expected tranche loss, on such a synthetic CDO. there are at least two features that distinguish synthetic CDOs from cash CDOs. Number one, with a synthetic CDO, it is no longer necessary to tranche the entire portfolio and sell the entire deal. For example, a bank could sell protection or sell insurance, on a 3% to 7% tranche, and never have to worry about selling the other pieces of the reference portfolio. This is not the case with a cash CDO. In the case of a cash CDO, the bank would own all of the underlying bonds. If it's sold to the 3 to 7% tranche, let's say this one, it would still then be on the hook for the equity tranche and these tranches up above the 3 to 7% tranche. This is not the case with the synthetic CDO, because the underlying portfolio doesn't exist in the first place. The bank is just selling protection on a not, on a 3 to 7% tranche. And as I said it doesn't have to worry about selling the other pieces of the reference portfolio. But because of this we come to issue two. Because the bank no longer owns the underlying bond portfolio, it is no longer hedged against adverse price movements. It therefore needs to dynamically hedge its synthetic tranche position. Typically we might do this or would have done this in the past using the CDS markets. But hedging and risk managing CDO portfolios is very difficult in practice. And this is true regardless of whether or not you have a good pricing model. There are simply too many moving parts, there are too many names in the portfolio. There are too many individual default probabilities, you've got different industries and different correlations between securities and different industries and so on. These are very complicated securities and very difficult to hedge dynamically and risk manage.

## 017.CDO Portfolios

### 032. Pricing and Risk Management of CDO Portfolios

In this module, we're going to discuss the pricing and risk management of CDO portfolios. We will focus mainly on the risk management of CDO portfolios. Unfortunately, the risk management of CDO portfolios is an enormous topic in and of itself, and we won't have time to do it justice in this module. But however, we will discuss some of the issues that arise. We will discuss some of the weaknesses with the Gaussian copula model. We will also mention as an aside, that linear correlation, the correlation coefficient in and of itself is not enough to describe the dependent structure for multivariate distribution. So, this fact is lost on many people and we will emphasize it at the end of this module. Here's an example of a sample synthetic CDO portfolio. Across the top, we've got various columns. So, the first column index, this contains a name, so CDX IG A, this actually refers to a reference portfolio. So, this is an index with a certain number of names in the index and these names are known. Typically, there would be a 100 names or a 125 names in the index. So, CDX IG A IG stands for investment grade, A is typically actually numbered, it could be eight, nine, ten, eleven and so on and different numbers can contain different reference portfolios. The second column is just a tranche description, it could be an equity tranche, a mezzanine tranche, senior trance, or it could be an index. This can be viewed as a tranche with a lower attachment point of 0 and an upper attachment point of 100 as we have here. And the next two columns indeed contain the attachment points, L for lower, U for upper attachment point. We have the maturity that is 10 years, 7 years, 5 years, 3 years, 4 years and so on. So, the materials can vary and we have the notional amount so this is the notional amount of protection that we are buying or selling. And these are the current prices and basis points. Now, these are given, these are the spreads. The spreads, current market spreads of these tranches. the equity tranche prices are often quoted in a different format to reflect upfront payments and so on. But we're not going to concern ourselves with that. IG as I said, will refer to investment grade, HY, for example, refers to a high yield. So, these would be riskier credits or riskier bonds that are more likely to, to default. very often, there's substantial overlap in these portfolios. So, for example, IG A and IG B, each portfolio or reference portfolio will contain 125 names or 120 names or so on. And in the case of A and B here, typically, there would be a very large overlap between the two portfolios. So, most of the names in A will also be in portfolio B, and so on. In practice, structured credit portfolios could contain many, many positions with different reference portfolios, different maturities, and counter-parties. They also can have different trading formats, so as I said earlier, sometimes these tranches trade in the, in the form of a spread, a spared that is paid quarterly, or a premium that is paid quarterly. This is the insurance rate if you'd like for buying protection or buying insurance on the, the tranche, but sometimes, they can also trade in an upfront format and R, the running spread format. The ultimate payoff of such, of such a portfolio is very path-dependent with substantial idiosyncratic risks. They are very difficult to risk manage. they can also be very expensive to unwind and that is due to why bid-offer spreads. Over here, what I'm giving here is a current price but this should really be interpreted as the midpoint of the bid-offer spread. So, the bid on the offer will be on either side of, say, 223. Maybe the, we'd have 210 and 240. And so, if you want to sell protection or if you will hid one side of the bid-offer spread, if you want to buy protection, you would hit the other side. So, if I'm, if I'm buying protection, I'm going to have to pay 240 basis point for that protection. If I'm selling protection, I'm going to receive 210, so that's the bid-offer, okay? And sometimes these bid-offer spreads can be very wide so actually unwinding such a portfolio can be very expensive, especially in times of market stress or when these portfolios, these synthetic CDO tranches aren't trading very often as would be the case today. Computing the mark-to-market values of these portfolios can also be very difficult because market prices maybe non-transparent. I don't think I've used the phrase mark-to-market yet in this course. But just to be clear, mark-to-market is referring to the current value of portfolio using current prices in the marketplace. So you're not using the historical price at which you purchased a portfolio of securities, instead, you're using the current market price for these securities. So, that refers to mark-to-market. And on this note, you might be interested in the Belly of the Whale series on the Alphaville blog of the Financial Times. You can actually get to that blog via this link here. And while the Financial Times does have a paywall, so most of the articles aren't available for viewing freely, their blogs are. And so, the articles in this series can be found here. This series refers to the so called London Whale. And in fact, the London Whale first came to attention because price levels in the CDX IG9 index. So, this an example of where we're using a number. So it's the IG9 index. It diverts too much from other related price levels. In particular, it diverts too much given the CDX prices of the credits in the IG9 portfolio. So, you'll see a lot of interesting material in the articles that have been published on this series, on this Alphaville blog. You won't be able to understand everything in this series and that's in part because there's a lot of jargon and there's a lot of references to positions that we can see. And indeed, there's references to communications that we can't see. Maybe there weren't e-mail communication but verbal communication between some of the players and so you won't always understand what's going on. But you will see a lot of discussion of value at risk, and Gaussian copula and the synthetic CDOs in risk management. By [UNKNOWN] you've said this at the beginning. But this London Whale came to attention because of ultimately massive losses that occurred, in the, synthetic credit portfolio of the Chief Investment Office of JP Morgan. So, this is a very recent situation, where they lost 7 billion dollars out of the Chief Investment Office on synthetic credit portfolios. And reading this series is certainly of interest and certainly relevant to what we've been discussing in these modules. Risk management for structured credit portfolios is also very challenging. we've seen two types of risk management to date, we haven't gone into either one in any real detail for time reasons but they're certainly both very important. The first the scenario analysis where what we did was we stressed the important risk factors for portfolio. We moved these risk factors to different level. We reevaluated the portfolio in these stress scenarios. Computed the profit and loss that would therefore arise, and figure out or evaluate overall risk of a portfolio based on the PNLs in the scenarios. So if we wanted to do a scenario analysis with the synthetic CDO portfolio, we'd have to figure out first of all what are the main risk factors. Well that's a very difficult question to answer. There are so many moving parts here. it'll be hard to figure out what are the risk factors. Of course, overall credit spreads are important because credit spreads drive the individual default probabilities. And certainly, the riskiness of these CDO tranches increases as individual default probabilities increase. So certainly, the overall level of credit spreads is important. But, what about the individual credit spreads? Some CDS spreads may increase, some CDS spreads may decrease, and depending on what happens, you will get very different outcomes for given CDO tranches. That, correlation, of course, is a hugely important factor. In fact, the trading of synthetic CDO tranches is often called correlation trading because correlation as we saw, it drives the value in particular of equity tranches, also super senior tranches. and so it's very important here to stress correlation appropriately. But in fact measuring correlation, even understanding correlation, what correlation is, what this correlation of default times actually means, that's, they are difficult questions to answer. And it's very difficult to determine what correlation risk factors are there and how you should stress them. Moreover, you need to determine, what are reasonable stress levels? How far should you stress a given factor? What's reasonable? What's not reasonable? What's like to happen, what's very unlikely to happen, what's almost impossible to happen? You have to be able to answer all these questions in order to do a scenario analysis. Finally, suppose you could figure out what appropriate risk factors are and you could figure out what reasonable stress levels for these factors are. Well then, how you going to reevaluate the portfolio, your synthetic CDO portfolio in a given scenario where you've stressed these factors. Well to do that, you need some sort of model. And as I mentioned before, it is very difficult to find a good model. In fact, I think it's fair to say that there isn't a satisfactory model for pricing CDOs out there in the marketplace. The Gaussian copula model has been the standard model but it is certainly a flawed model and has many, many weaknesses. So, scenario analysis is certainly very difficult. What about the Greeks? Well, we saw the Greeks when we discussed equity derivatives. We saw delta, gamma, vega, theta, and so on. Well, you can also come up with Greeks for synthetic CDO portfolios. You can figure out how much the value of the CDO tranche will increase if an individual credit spread or default probability increases or decreases, and so on. So, you can certainly come up with Greeks but there are many, many Greeks, you could argue you've got a separate Greek for every individual default probability. You've got Greeks to correlation and so o. but you've basically got too many of them. You've got too many moving parts here. The Greeks are model-dependent and it would be very difficult really to risk manage a portfolio based on the concept of the Greeks. In fact, there's an interesting article you can read here. It's from the Wall Street Journal back in 2005, which discusses some of the fallout of the downgrading of Ford and General Motors in May 2005. Certain investors, in some of these synthetic CDOs, found out that their hedging, using the Greeks didn't work nearly as well as they anticipated when Ford and General Motors were downgrade, downgraded. Just as in the side, Ford and General Motors were part of, were members in the reference portfolio for very commonly traded [UNKNOWN] at that time, and so there are inside, the reference portfolio for CDO tranches. and so, certainly some market people lost a lot of money when they thought they were actually hedged when Ford and General Motors were downgraded. I should mention that, in fact, the Wall, the Wall Street Journal is behind the payroll and so you may not be able to read this article but it depends. On one or two occasions I've been able to read it and I just Google it, other times I can't, so maybe you'll be able to see it. And that said, don't believe everything you read in this article. in my experience, some of these articles which talk about fairly arcane and complicated details in, in finance, don't always get all the facts right. But the overall picture is pretty accurate and it's certainly an interesting read. Liquidity risk and market endogeneity are also key risks that must be considered, and that should have been considered in the trading of CDOs and the risk management of CDOs. I've mentioned market endogeneity before. It basically refers to the idea, for example, that if everybody is holding the same position, then that's a much riskier situation to be in, than if only a few people hold a position. And that's because if everybody needs to exit that position at the same time, or in other words, if everyone wants to run for the exits at the same time, then everybody wants to sell the security at the same time. There's no demand for it and the price will collapse. That's an example of this concept of market endogeneity. we've got a trade that's too crowded, too many people holding a position. Too many people wanting to get out of it at the same time, prices collapse. This certainly happened during the financial crisis. Other problems that arose in the whole structured credit area during the financial crisis were the massive overreliance on ratings agencies to rate some of these tranches. And overreliance on models that really weren't worthy or that were, at best, a poor approximation to reality. you had issues related to just the behavior of organizations, the incentives of individuals making big decisions in these organizations. All of these obviously played a very important role in the financial crisis. Very briefly I want to spend a little bit of time talking about copulas. We introduced copula in an earlier model when we discussed the Gaussian copula model. But we haven't had time really to spend on copulas more generally. I'm just going to say a little bit about copulas here and the Gaussian copula model. So certainly, the Gaussian copula model is the most famous model for pricing structured credit securities. There has been enormous criticism aimed at this model and most, if not all of it, is justified. With that said, some people like to say that they didn't understand the weaknesses of the Gaussian copula model until after the financial crisis broke. Well, I simply don't think that's true. There's nothing we've learned about the Gaussian copula model that we didn't know before the financial crisis. So, to say or to plead ignorance that you didn't understand the model, that the market didn't understand the weaknesses of the model after the crisis blew up or the crisis took place, simply is not a well-founded statement. Many people fully understand the weaknesses of the, of the Gaussian copula model. Just to mention a couple of them, it's a static model. By static, I mean, there are no dynamics in the model. We just compute the expected tranche loss at a fixed period of time. There's no stochastic process here, we assume credit spreads are constant. we assume correlation is constant, we assume correlation is constant across the various names. There are problems with this model in terms of time consistency and so on. So I know this is a very brief aside, we don't have time to go into, into this in any more detail, but certainly, the weaknesses of the Gaussian copula have been well-understood. There has been a lot of academic work on building better and more sophisticated models, but none of them are really satisfactory. It's an aside but I want to also make this point. A common fallacy is that the marginal distributions and correlation matrix are sufficient for describing the joint distribution of a multivariate distribution. In others, what I'm saying here is, many people think that if you've got a multivariate distribution, the only thing that you need to know about distribution are the marginals and the correlation between the random variables. Well, that's not true. Correlation only measures linear dependence. On the next slide, we'll provide a counter example to this. So, in this slide, we've got two distributions, two bivariate distributions. The first one is a bivariate normal distribution and the second one is what's called a Meta-Gumbel distribution. What I want to emphasize here is that in each case the marginals are standard normal. So, the marginals in each of these are standard normal. Now, the plots aren't really drawn to an appropriate scale, maybe we should stretch the x-axis out here, because really the, the width, the length of the horizontal piece here should be the same length as the vertical piece here. So, they're both, the marginals in all cases are were in 0,1. The correlation in each case is 0.7. So, what we have here are two bivariate distributions which have the same marginals and the same correlations, but they're very different. And one way to see they're different is the following. The Meta-Gumbel distribution is much more likely to see large joint moves. And the way to see that is to look for moves where the x and y variable are both greater than or equal to 3. These are up here, and up here. So, over in the multivariate normal, we see there's only one move where both the x and y variable are both greater than or equal to 3. Whereas, over here, we see there are five such situations. What we've done here, by the way, is we've simulated 5,000 points from each of these distributions. So, five of those 5,000 points, or 0.1% of those 5,000 points resulted in extreme joint move. Whereas only 1 5th of that resulted in an extreme joint move in the case of the Bivariate Normal. Now, 0.1% might seem like a very small number. And indeed it is. But when it comes to figuring out losses, that 0.1% can be substantial.

### 033. CDO-Squared's and Beyond

In this module, we're going to go beyond CDOs and discuss more complicated products such as CDO squared's and CDO cubed, and maybe even a little bit about ABSCDOs as well. That point we're going to try and make here is that the risk management of these products is incredibly difficult. And it is difficult indeed to see any economic justification for introducing these products. Nonetheless, they were traded in the marketplace in the lead up to the financial crisis. And it is worthwhile seeing what they were and how they actually work. It should already be clear that structured credit portfolios consisting of CDO tranches can be difficult to risk manage. But at least there is a solid risk sharing motivation for the creation of CDO's, and this is true for securitization in general. We mentioned earlier that the idea behind securitization is to package a series of underlying bonds or loans or whatever, into a set of new securities each of which may have a different risk profile and which may appeal to a different audience or investor class if you like. And so, by spreading risk that way we can actually make the, the financial markets more efficient and so this is the theory that justifies securitization in general. But the structured credit market quickly ran amok with the creation and treating of ever more complex securities. For example, products such as CDO squareds were soon developed. They were difficult to justify economically. they provided great examples of product risk whereby people didn't really understand the product that they were buying and model risk, and that really models were completely inadequate for pricing these securities. Legal risk and so on. Why legal risk? Well, the actual contracts underlying these CDOs ran to maybe many thousands of pages and so it's hard to believe that anybody fully understood what exactly they were purchasing when they invested in CDO squared's and so on. Before discussing these classes of securities, these CDO-squared's, recall first how a CDO is constructed. So, we've got an underlying pool of bonds, say 125 bonds. we might have what's called as we mentioned earlier, a special purpose vehicle. Which is a legal entity into which we would place these bonds. And then from these bonds, we can construct the CDO. So the bonds form the underlying collateral for the CDO. And then the CDO is tranched up into an equity mezzanine and so on. Tranches and people can invest in these different tranches and get very different risk profiles as a result. So, that's how a CDO is constructed. How about a CDO squared? Well here's an example of a CDO squared. We're going to assume that a hundred CDOs, CDO number one up to CDO number 100. We're going to take the mezzanine piece of each of these CDOs. So we're going to assume the mezzanine piece corresponds to attachment point of 3% up to 7%. And then we are actually going to construct a CDO square using these mezzanine pieces. So the CDO squared is constructed from mezzanine tranches of underlying CDOs. So basically, you can think of these mezzanine pieces as now corresponding to the bonds underlying the CDOs. So basically a loss will only occur in say the equity tranche here. When there is at least some loss in the mezzanine tranche of one of these underlying CDOs. If none of these underlying CDOs ever experience a loss in their mezzanine tranches then there will never be a loss anywhere in the CDO squared and in particular in the equity tranche here. On the other hand if all of these mezzanine tranches experience losses. In fact, if all of them are blown out, in other words maybe losses go right through the mezzanine tranches in all of these tranches, well then this CDO squared will face complete wipe out as well. All the way up through the[UNKNOWN] mezzanine and senior tranches. Remember the mezzanine tranches are the underlying bonds, if you will, for this CDO squared. It's also worth pointing out that many bonds act as collateral for multiple CDOs. So behind this, remember there are bonds behind each of these CDOs. And in many cases what you'll have is, you'll have a bond being in the reference portfolio for this CDO, but it might also be in the reference portfolio down here for this CDO. So there would be a lot of overlaps of names, of bonds going into these different CDOs. So this is just repeating in words what we showed visually on the previous slide. There's not much else to say here, so let's move on. Here's a question. How would you price and risk manage a CDO squared? Here are some considerations. And by the way a discussion of CDO squared can also be found on the paper by[UNKNOWN] that I referred to in an earlier module. They discuss some of these issues there as well. So here's some considerations. The legal contract governing each of the mezzanine tranches in the underlying portfolio of CDO's could be on the order of 150 pages long. So, therefore, if you really want to do your due diligence, really understand the legal details underlying a CDO squared, you would need to read approximately 100 time 150, which is 15,000 pages of legal documents. To just say good luck. You should also of course read the contract governing CDO squared. How do you keep track of the CDO squared's performance? Just to keep track of the performance of the CDO squared, remember you're going to have to keep track of the performance of all of these underlying bonds. You're going to have to feed the performance of these underlying bonds into each of these 100 CDOs and figure out what's going on in each of these CDOs. And then based on that, you're going to have to figure out what's going on in the CDO-squared. In order to do that, you're probably going to have to write several thousand lines of computer code, and that is just to keep track of the actual performance. It is not to actually price the CDO-squared. Or to, risk manage the CDO squared. You might need a model to price it. In fact, it's hard to say that any model really could ever possibly price that CDO squared correctly or give you a good sense of how much a fair value is for a CDO squared. So these are very difficult securities to manage. How would you perform scenario analysis? how would you estimate the value at risk? Or the conditional value at risk of a portfolio of CDO-squared's? It's it seems very difficult to even imagine doing such analysis. But why stop there? There are also ABS CDO's. An ABS CDO is an a, is a CDO where the underlying securities, the underlying bonds are themselves acid backed securities. So going back to our CDO squared instead of having a CDO number 1 up to CDO number 100 this could be ABS number 1 up to ABS number 100. And these ABSs could in fact be mortgage back securities. So there would be underlying pools of loans feeding into these ABSs. Which then feed into the CDO itself. Uhhh you can have CDO-cubes uhhhm. And why stop there? So here's how a CDO-cube would work. You got your n CDOs and a couple of slides ago we had n is equal to a 100. Now we've got n CDO's. From that we construct say 100 CDO-squared. So imagining here that the n, number n is greater than 100, so we can construct CDO-squared out of these n CDO'S maybe using the mezzanine tranches from these CDOS. Now we have our CDO squares. Let's take the mezzanine tranches of these CDO-squared and construct another CDO that would give us a CDO-cubed. So, if your head is spinning at this point, it's not surprising. And yet, there were trades apparently on CDO-cubed in the marketplace leading up to the financial crisis. So, one other point I'll make about the financial crisis and the subprime crisis before, before ending this module is the following. So there were securities, I mentioned in the previous slide, called ABS CDOs. And very often, actually, it was sub-prime mortgage ABS's that were feeding into these CDOs. And so you can imagine this being the CDO, maybe there's equity mezzanine and so on. So, maybe this is the zero to 3% tranche. Maybe this is, I don't know, a 6 and 9% tranche. And maybe the underlying pool of securities that feeds into this CDO. Are some mortgage backed securities. So we've got a bunch of mortgage backed securities feeding in here. Well, an interesting antidote about the financial crisis is that the sub prime crisis actually didn't come suddenly to many people. There were several money marketers, including banks and so on who had a good sense that the subprime crisis was coming down the line. And one way to profit from that belief was to actually buy protection on the 0 to 3% tranche of an ABS CDO. So if you buy protection here, what will happen is that you're going to get paid off. You're going to make money. If you see lots of defaults in the 0 to 3% piece, or lots of losses in the 0 to 3% piece of this CDO. And if you expect the subprime crisis to come down the line, then you're going to assume that the underlying mortgage backed securities are indeed going to see a lot of losses. Because people are defaulting on their loans and so on. And if they're defaulting on their loans and you're seeing losses in the underlying mortgage pool, then you expect to see losses inside this tranche as well. And so you could profit from that by buying insurance on this tranche. And so thats what some players did. They bought insurance on this tranche. But, when you buy insurance you've got to pay an insurance premium. And the insurance premium which you have to pay quarterly could be quite substantial. So rather than having to pay out this amount of money every quarter, some of these players or banks got clever and said, you know what, instead of paying out money every quarter on this tranche, why don't we sell protection or sell insurance up here? On this tranche, say. and if you sell insurance on this tranche, well then you are going to be taking in a premium. And you could use the premium you take in here to fund the insurance premium you have to pay out for your protection here. The only problem with that is because this tranche is much riskier than this tranche, you have to sell a lot more insurance up here to cover your payments down here and that's what some players did. They thought that the sub prime crisis might blow through these tranches up to here say, but that the higher tranches would be safe and that they would never incur losses and so on. And so they thought it would be a good idea to sell protection on these more senior tranches and use the premium to fund protection on the equity tranche. And so that was a good idea. It, it meant you didn't have to spend any money net on your position. The premium here was funded by the premium you're taking in up here. The problem was, that the subprime, crisis came along, and was much more severe than anybody anticipated. And in fact, the losses didn't stop at this point, or at least the mark-, market losses didn't stop at this point. The mark to market losses went like this, and blew out these tranches as well. And so the players who actually put on the straight, ended up losing an awful lot of money. Because they were selling protection on a much larger notional up here than the notional they were buying protection on down here. So this is just an aside. And the reason I wanted to mention it is, number one, many players actually did see the sub prime crisis coming along and they used these ABS CDOs in order to make plays on what was happening, or what might happen with the sub prime, with the sub prime crisis. But also it emphasizes how even if your opinion is correct, and their opinion was correct. The sub prime crisis was coming and it did occur. It can still be very difficult to execute a trade properly. So they executed the trade by buying protection down here, selling protection up here but their execution didn't work. In fact, the sub prime crisis was worse than what they anticipated. And some of these players ended up losing an awful lot of money as a result.

## 018.Liquidity, Trading Costs, and Portfolio Execution

### 034. Liquidity, Trading Costs, and Portfolio Execution

In this set of modules, set of three modules, we're going to talk about liquidity, how liquidity of assets affect trading costs, and how these trading costs have implications for portfolio selection. In the first module we're going to be mainly focusing on measures of liquidity, how do you set up a portfolio selection problem that takes liquidity into account. What is liquidity and what is a liquid security, is very hard to define in practice. What we do know is a liquid security is one that can be traded very quickly, has very little price impact, meaning when I try to put in an order to buy or sell, it moves prices very little. And it can be bought and sold in large quantities. That means it has a very deep order book. There are different measures of liquidity. Some of the measures based on volume and these include the trading volume and the turn over which is defined as the trading volume divided by the shares outstanding. Both of these measures, try get, try to get at the idea. That liquidity refers to the fact that one can execute your trades quickly. So if something has a very high trading volume or high turnover, then my order will get executed very quickly. There are cost base measures which look at the impact of liquidity on the cost of trading a particular set of securities, particular amount of securities. One of the measures that gets at this is the percentage bid and ask price. An ask price is the price at which people are willing to sell a particular security, and B, the bid price, is the price at which people are willing to buy a security. As always, the ask price is going to be greater than the bid price and the percentage bid as spread is defined as A minus B, the difference. Divided by A plus B, divided by two. So the mid price times 100. A volume weighted average prices, is another quantitiy that gets us this notion of liquidity. So what happens is that you want to sell a total amount of shares, v. This total amount gets split up into smaller trades. We want to vm. And each of these treats get's executed at a different price. P 1 through P m. So the volume weighted price that you got for the particular order would be simply Pi, Vi, some from I going from 1 through M, divided by the total volume V. So this quantity is known as the volume weighted average price. It tells you the price that you ended up getting. If you're trying to sell a particular commodity, what happens is that the price start to slip downwards so you instead of, P1 could be the opening price, Pm could be the price at which your last bit got sold. Typically P1 is greater that P2 is greater than P3 and so on. So the average price turns out to be less than the price that was existing in the market just before you put in your trade. Other authors have tried to get at the price impact function directly. There was a, the first of these functions was introduced by Lobe in 1983, called the Lobe price impact function. More recently, Kissel and Glance have introduced a price impact function, which measures how expensive or what is the cost of putting in a particular trait. In the next slide, I'm going to talk about the Kissel-Glantz price impact function and in that context I'll tell you what the Lobe function is as well. In the rest of this module, I am going to assume that we are going to be looking at basically, a cost based measures of liquidity and we are going to incorporate those cost based measures into my portfolio execution of portfolio selection procedure to get at what is the optimal. Choice for my portfolios. The trading cost function. The cost of creating a particular block of shares is typically assumed to be separable across assets. Which means that it ignores the cross asset price impact. This is an assumption which is not valid anymore. There is cross price impact and in the last module of the series, we going to. Start discussing some ideas of why this cross-price impact occurs. And what can be done to sort of of take it into account in your asset allocation decisions. So the Kissel-Glantz function says that if I want to trade Q shares of a particular asset and the cost of. Trading these shares, meaning the slippage, the extra price that I have to pay if I'm buying or the loss in price that I'm going to see if I'm selling is given by this function c of q. It has three components, the first component is just a constant, a three. So the cost is dependent on the total dollar amount that I'm going to sell. Its depended on the volatility. So if, if a particular, there is no index I there, if a particular stock is very volatile you expect to pay more, prices move around. And so when you've put in your order to the time it actually got executed. You will end up getting a higher volatility. And then a third component that depends on basically the percentage of your trade Q to the daily volume V. So Q over V is the percentage of the daily volume that you are trying to take times 100 that gives you the percentage raised to the power beta. And these are some const-, constants A1. How does one estimate a function like that? What one does is postulates, that there are three factors in the regression function. This is factor number one, volatility is factor number two, and this is basically the intercept. And then one runs a regression. One records, over a history, of trades, how much extra cost did you end up paying for that particular trade. So Qt is a particular trade that was executed at time t, or trade t. PtQt should have been the price that you should have gotten. cQt is the extra price that you had to pay or the extra revenue that you lost. You divide that. That gives you one observation of this regression function. And then you regress it to compute out what a1 is going to be, what a2 is going to be, what a3 is going to be. And this is what was proposed by Kissell and Glantz in mid 2000's, and this has sort of become the standard pro- standard function that people use for trading costs. There was another function the was introduced by Lobe before, and which was slightly different. And what he, what, in his model, the cost versus volume initially grew linearly, and then it grew with a power. So the cost was some alpha 1 times q up to sum q max. And then it was some alpha 2 to the power, times q1 plus beta after Q max. And beta was estimated to be approximately 0.65. So this is the cost under q, that's q, and this was the Lobe function. So the low function is was suggested in 1983, and it was relatively simple. It did not take into consideration the volatility. It did not take into consideration the average daily volume. But it was the inspiration that led to other liquidity functions later on, in particular the Kessell Glance function. And we will focus with Kessel Glance function in this module. Alright so once we have a price impact function, we can include that into our portfolio selection problem. So there are two approaches to introducing liquidity and portfolio selection. One approach is to do the usual portfolio selection, and then account for liquidity and executed traits. In the second module of the series we're going to talk about, how to include. Liquidity in executing trades. And the other approach is to incorporate liquidity concerns directly into the portfolio selection problem. And that way you're choosing position, so you're choosing portfolios that will have low cost, of execution. The best practice is to do both, account for it with the portfolio selection and then when you do trades. You account for it by trade execution as well. So the generic problem that one solves for the second approach which is to incorporate liquidity concerns directly into the portfolio selection, is as follows. You take your usual mean variance optimization problem, so I have a current position Y. One transpose y tells me the total wealth that I have, x is a new set of positions. So in this particular problem, the x's do not add up to one. They are just dollar amounts, or any other units, which add up to the initial amount of money that I have. Mew transpose x minus lambda x transpose x, this quantity, is our usual mean variance. Objective. Mew, mew is the mean return and v is the covariance matrix, lambda is the risk tolerance or the risk aversion parameter. Now instead of just stopping there, what we are going to do is subtract from it, at the trading cost. This is extra cost that I have to pay, and that actually reduces my mean return. And I'm going to add an eta to try to incorporate the effect that I can control the amount of liquidity cost that I'm going to incorporate into my portfolio selection problem. So some part of it I might include here. Some part I might handle while execution. Or I might just want to use eta as a way to trade off between mean-variance returns and the trading cost. And what is Cxy, Cxy is the cost of moving from the current position y to the new position x and we can write it as using the Kissel-Glantz function as this expression down here. XI minus YI is dollar amounts and that's why I've now divided by PI. And so to adjust vi to include the fact that it's now the percentage dollar transacted to the power beta. This sigma value remains the same. A3 remains the same. And xi minus yi is actually the dollar amount transacted. Now if you expand it, you end up getting. You can take the constant over here, it just becomes xi minus yi absolute value. You can take this one and take out the extra part, so, it's a100 over pivi to the power beta, and xi minus yi to the power 1 minus, 1 plus beta. Now, I have a function, I can incorporate the function into my portfolio selection problem, and then, I can solve that portfolio selection problem to compute what my new positions x are going to be. In the next module, which is going to be an excel module, I'm going to show you how to solve setup, and solve this optimization problem and we're going to play around a little bit with what happens when eta changes values and so on. In the rest of this module I'm going to talk about a very simple model that has become popular, that was introduced by Andy Lowe in one of his papers, and it's a easy model that incorporates some aspects of liquidating. So this approach was taken, is taken by a paper by Lo Petrov and Wierzbicki. And the title of the paper is very interesting, it's 11 PM, do you know where your liquidity is? The mean variance-liquidity frontier. What they do, is it that they ascribe to each security a certain normalized liquidity measure. So let L [UNKNOWN] note the measure of liquidity where high values, implies more liquidity. So, if you're talking about turnover, high turnover is a good measure. if you're talking about volume, and high volumes is a good measure. When you're talking about trading costs, or bid ask spreads, you take the reciprocal of those numbers. So the high percentage bid ask spread is bad, low percentage bid ask spread is good and therefore when you define this measure of liquidity in the model introduced by Andy Lo. You take one over the beta percentage, beta spread to define your LIT. And then your normalize this over a certain period. So what you do is you look at LIT for a particular amount of time. You take the minimum value that this particular measure could take over all assets. So it's i-prime ranging over all assets and all times. And divided by the maximum value that can be achieved over all assets and all times minus the minimum. So this number, whatever it is now, becomes a number between zero and one. So this lies between zero and one. They assumed in their model that all the wealth is in cash, and formulated three different optimization problems that get at this notion of how do you incorporate liquidity into portfolio selection. The first method they call Liquidity Filtered Portfolio Selection, so you do the usual main variance portfolio selection, so one transpose X equals one,mew transpose X minus lambda would do X transpose VX. But now you insist that XI is equal to zero for all I's that do not meet a particular liquidity threshold. So L bar is your liquiddity threshold. And if doesn't meet that liquidity threshold, you cannot hold that particular asset. Another one is to use a mean variance liquidity objective. again this time I'm just adding to it l i x i and then saying this is different from the formulation on the previous page, because for, this is no longer a cost, but this is a quality measure. So l i high is good, so I want to add that liquidity measure instead of subtracting as if it was a cost. A third version that is suggested was liquidity constrained portfolios, so you do not put a cost but you say that, LIXI over the average value of XI is greater than, equal to L bar. So difference between the first model and the last one, is that the only thing this is measuring liquidity on a portfolio level, so this is a portfolio level measure. Instead of asset. In the first formulation over here, this is asset by asset. If a particular asset does meet the liquidity threshold, you throw it away. In this particular case, you just want to make sure that on overall portfolio level this happens. in that way. The expression for overall liquidity in the portfolio is slightly different here, this is to prevent short positions in illiquid stocks, cancelling long position in other liquid stocks. And we'd, because of that, instead of taking just XI, we take the absolute value of XI. All of these portfolio selection problems can also be solved in Excel in much the same way. That the fourth formulation is going to be solved. [BLANK_AUDIO]

## 019.Optimal Execution and Portfolio Execution

### 035. Optimal Execution

In this module, we will focus on a single asset and we will double up a model which takes into account the temporary price impact of a trade and the permanent price impact of a trade. And construct an optimization problem that allows you to select a treating strategy that minimizes the cost of the execution, and as well as the risk associated with this execution. In this module we are going to take the approach that we have decided a portfolio, that we want to trade to words. So this is a new position, we had an original position and now we want to trade to a new position. And we have computed this new position perhaps by taking liquidity into consideration or perhaps not. And in one of the pieces of this over, over all trade, we have to sell a total of capital x shares over at most t traits. I choose a certain number of trades that I can put and over those trades I want to sell these shares in order to have the least amount of trading cost associated with it. And in order to compute the trading cost, I need to have a model for trading cost and that's what we're going to develop over this module. So, in order to model how going to trade, I'm going to introduce this notion of a trading strategy. So, N sub j would denote the number of shares that will be sold on the jth trade. Capital N or bold face N, which is N1 through N capital T will be called the execution sequence. It's just a complete sequence of execution that I will be interested in. Over the entire period, j going from 1 through capital T, the sum of all the trades that I made must be equal to X, capital X, the amount that I wanted to trade. I'm going to introduce a new notion of little x, which is going to be the inventory. That is, the holdings at the end of a particular trade. So x sub zero will be capital X. x sub k will be the holdings at the end of not the jth trade, but kth trade. After the kth trade, I would have n1, n2, n3, up to nk. I subtract that from capital x, that tells me what is the holdings left over, and that's the inventory that I have. In order to understand how to choose these sequences, I have to bring in this notion of what happens to the prices. So let S hat k denote the price per share received for the nk shares sold in the k-th trade. x hat, this S hat nk is going to be a function of all the trades, n1 through nk. Note that it also depends on the trade that you actually put in. And now in the next slide I'm going to set up a particular model for how these prices behave. And using those models, I'm going to try to understand how I can trade off various important quantities that play a role in the execution of a particular stock. So this slide is perhaps the most important one in this module. I'm going to assume that the price impact, the impact on the price of my trade is going to have two components. There's going to be a temporary price impact component, which is the impact of trade nk on its own price per share, S hat k. And a permanent price impact is the impact of trade nk on all the future prices. And here's the model that's going to happen. Remember, I'm selling shares, so whatever I do tries to drag the price down. If I were buying orders, if I were putting in my orders then the, the whole story will be a mirror image and I will start increasing prices because of my trade and not decreasing prices. So let Sk denote the price that I observe in the market, when I am contemplating the k-th trade. When I put in the K-th trade, the average price that I get for this trade is not going to be Sk but a smaller amount S hat k. This is the amount of money that I would get per share when I put in the trade hnk. Now, I'm going to assume that S hat k is going to be Sk minus hnk, it's something hn is a temporary price impact function. It defines what'll happen to my price by what amount the price is going to dip if I decide to sell nk amounts of shares. Now what happens to the price in the future periods? This particular trade, nk, is going to have an impact of what happens to price Sk plus one. And therefore, it's going to start having an impact on Sk plus 1, Sk plus 2, Sk plus 3, all the way up through S capital T. And the model that we are going to say is the following. The price at the next time period is going to be some random walk to its current price, plus a random walk component. So sigma is the variability or the standard deviation, zk is just IID standard Normal random variables. So without any price impact, this particular asset is just doing a random walk. If there was drift in the market, we can simply add another drift term. Typically, when ignores the drift term and claims that this trades are happening over a certain period said that the price is not significantly drifting, but it is varying. So Sk plus sigma zk tells you what happens in the random walk. The expected cost term takes into consideration the fact that if I sell a large chunk it's going to have a price impact, and I won't get the revenue that I want. Rho, the term over here, is the trade off that trades off my concern for variance with my concerns for trying to keep the cost minimized the cost that I end up getting from it. The total revenue from execution, is simply the price per share for every trade times the number of shares sold in that trade. So it's the sum of k going from 1 through capital T of S hat k, which is the price per share times nk, which is the number of shares that we're trading. If you write out the expression for S hat k, it becomes Sk minus the term that corresponds to the temporary price impact times nk. So this term, we have taken it together and kept it over there. Then Sk has an expression. Sk is equal to S1, the initial price when we started trading sum from j going from 1 to k minus 1 of all the random walk terms, minus nj, which is all the permanent price impact terms, times nk. So if you unravel the sum and do it two different ways, you end up getting the first term, which is S1 times the total number that I sold. So this is the revenue that I expect to get if there was no price impact. I could just sh, sell everything all at one go, I get the current price. That's it, I'm done. Plus I get a term which corresponds to random walk. The random walk term starts to show what is going to happen, what the trade off between selling and inventory. So the random walk term has a term z delta k that refers to the random term at time k, the random walk at time k and it affects all the left over inventory at time k. So, this is not nk but xk, it's the inventory at the end of the k-th trade. Similarly the term that corresponds to the permanent price impact also af, affects, is affected by the inventory and not the current trade. So gnk, the trade at time k, is going to affect all the stocks that I have not yet sold, all the shares that are not yet sold, and sitting in inven, inventory. This is the revenue that was expected, that is the revenue that was realized, so the difference between the two of them is the slip edge or the expected cost of the trading strategy. So, the trading strategy Cn gives me a cost, which is gnk times xk, which is the inventory plus hnk times nk. This is the expected cost, and therefore the term that corresponds with the random walk goes away. The risk or the variance of the trading strategy is that all the deterministic terms go away. Since the random walk terms were assumed to be IID standard normal, you get sigma squared times the sum of the inventory from time 1 to time Capital T. Now we can define waht is called the optimal execution frontier, which is a trade off between expected cost and risk. So I want to minimize over all trading strategies, the expected cost, plus rho times the risk term. The time horizon capital T is also a variable, but in this particular case we are going to assume that Capital T is given and just optimizer of the execution strategy. What this objective is basically trying to do is the following. If I completely ignore variability, then the best thing for me to do is to sell equally, across the entire time horizon. That minimizes the amount that I sell on any given day and therefore that minimizes my price impact. And we will see that on the Excel spreadsheet that is exactly what is going to happen. But if I spread it uniformly, what's happening is that I expose my inventory to very high availability. And therefore the, the realized revenue could be very far away from the expected revenue. If I want to control the variability, then I want to sell quickly, but then I pay a cost in the expected slippage, or the, or equal until if my revenue comes down. So I need to balance these two, and rho is sort of exploring the different points on the surface, that is a trade off between the expected cost and variability. What are some typical choices for the price impact function, for the permanent price impact function typically one takes it to be linear. For the temporary price impact function, you can use the Kissell-Glantz function that we introduced in the last module, and we're going to be doing that in the excel module that we, we'll be talking about very soon.

### 036. Portfolio Execution

In this last module on liquidity and execution we're going to talk about the main ideas that are important for portfolio execution. And focus on some of these ideas and how they're impacting, how portfolio execution is done in practice. But we're not going to be looking too much into the details of any these problems. In this last module on portfolio execution and liquidity, I just want to introduce some ideas that are relevant to portfolio execution. In this module we will not give you any strategies, or will not formulate any problems. But we'll just talk about really is issues that are of interest and importance in portfolio execution. So, the big problem that one is interested in is that, one has a portfolio x or a position x, they may not add up to 1. You want to move to another position, y over a certain number of trades capital T. One of the various decisions that one has to make in order to make this trade happen. First of all we have to decide what is a trade horizon? Is it one day, is it a week, is it a month, is it milliseconds? So that's a variable, depending upon what we decide. The strategies that one uses and the models that one constructs are going to be different. Does one consider cross asset price impact? If I trade one particular asset, it's going to impact the price of that asset, but does it impact the price of another related or maybe unrelated asset? How does one model this? Because if it is the case that my trades in one asset are going to map, affect another asset, then I may want to construct my trades in such a way that I have offsetting pricing facts as I go along and perhaps reduce the amount of slippage that I'm going to have. I'm going to have to think about what is the difference between market orders. So these are orders that I put into the market and I tell the broker to immediately execute. Or limit orders, where I tell the broker to put my order in a book called the Limit Book. And I will wait for my turn for my order to be executed. The difference between these two is, one of them I'm going to get the current price, it will get executed, but I'm going to possibly lose in the best possible price. In the other, I'm going to sit in the limit book. I don't know when I'm going to get executed. But if I'm going to get executed, I'm going to get a better price. And I still might be the case that my entire order may not get executed at a particular time, but might be spread over lots of dates. So I have execution uncertainty, but I typically get a better price. How does one trade that off? What is the importance of dark pools in these decisions? I'm going to defer the definition of a dark pool for a few slides, but it's basically venues where the volume that is available for trade. And the prices at which this volume is available is not transparent. You cannot see it. And the reason one goes to the dark pool is because one wants to limit price impact. And another thing that is becoming more important recently is this notion of portfolio being in balance. So the idea is that here's my portfolio. X that's where I started from. Here's the portfolio y, that I want to go to. There are many ways, many paths that I could take in this space to go from x to y. One extreme path could be that I first sell asset 1, and then I buy asset 2. And I end up getting that path. Or first I buy asset 2 or sell, then sell the asset 3, that's another path. The difference between these two paths, is that the proportions of the assets, along the path, changes dramatically. If I do something like this, then it's sort of, I'm keeping them in balance with each other. But if I do something proportional, I may have to constrain my trades which mean I may not end up getting the best possible price. So, sometimes people think about having a, a sort of window around this, and you say that your portfolio trades have to me in the window. Which means at any given time your portfolio must fall in this ellipse some where. There are many different groups that are trying to develop strategies that will allow you to do this, and yet control the price that you pay for execution. All of these aspects are not fully understood. There are, these are active research topics that are going on right now, to understand cross-price impact. Understand the trade off between market and limit. how do you keep a portfolio balance and so on. Similar issues come up in high frequency trading, which is a topic that we have not covered in these sets of modules. And the issues are where, where to place orders in the limit book, how do you manage the risk of the inventory? This is sort of along the lines of how do you trade off between the risk. in the transaction where it says the expected cost of the transaction very similarly, in high frequency trading you are setting the limit book and taking whatever orders hits you. And you want to make sure that at any given time, the inventory of offer that you're holding, is not very risky. So let's take all of these aspects one by one and try to sort of get out flavorful what's going on there. Cross-asset price impact. There is now increasing evidence that cross-asset price impact is important. And that typical economic models that one is thinking about behind this is that market-makers, who are typically assumed to be less informed about the prices or the fundamental values of these assets as compared to speculators in these assets, attempt to learn the fundamental value of one asset from the order flow of related assets. So if there's an order flow that's happening in a related asset, because the market makers are trying to infer something about the fundamental value of a particular asset, by looking at related assets, that will have an impact on the price. This peculiar is, I strategically trade another assets in order to reduce trading costs, manage their risk, they want to keep their portfolio balanced. So when they are trading one asset, they might want to trade another asset to keep the risk balance. And they may want to try to reduce their direct price impact by looking at other related assets. And because of that, the, the order flows in these assets become correlated. And when the order flows becomes correlated, the market-makers then look at these correlated order flows. Order flows and try to set prices which start reacting to order flows of [UNKNOWN], nearby or related assets. This is sort of an intuitive idea for why there might be cross asset price impact. There is some initial theory by Kyle. But this area is not very well understood and there is very little empirical work to justify many of the models. Some of the features that have been noticed is that cross-price impact is often negative. Both direct and cross-price impact are smaller when speculators are more numerous. If the volume is high, you expect this to go down, so, that's not very surprising it's greater when the market-wide dispersion of beliefs is higher. So the beliefs are more uniform. Then these overflows have less information, and therefore the cross-price, cross-asset pricing pact that is driven by overflow information will be less. if the dispersion of beliefs is larger, then people are looking to these overfloes to get information about the values of different assets. And therefore the cross asset price impact could be higher. It's typically greater among stocks dealt by the same specialist, specialist deals in a particular set of stocks. And sometimes order flows from one particular asset in that group, starts impacting the price. And the other one because the specialist also wants to do this management and which correlates the assets and therefore there's a cross asset price impact. The next thing that I want to talk a little bit about is Market orders versus Limit orders. We have referred to this limit book a number of times in these modules. Here's a sort of a schematic picture of it. A limit book is a database that keeps orders, that is buy orders or bids, or sell orders or offers, on a price time priority basis. So the red, which are shown above the line are all ask side, or the sell orders. And what it's, what it's depicting is the order that are available. So here's a particular chunk of an order. This is the number of shares, this is the quantity. And it's available at this price. And at this particular price, there are three different quanitties that are available. This arrived earlier than that one and then that one so this one has time priority, over all the other chunks that are sitting at the same price. So for example, we just called the lowest price at which somebody is willing to sell we just call the ask price. And at that particular price there was initially just one chunk of orders available. Here's another chunk that came in and this person said, I don't want to buy. So this is a sell order, this person could have sold to somebody whose willing to buy but he doesn't want to sell it right now and she just goes and sits at the ask price and waits for what is going to happen. Symmetric story over here on the buy side. This is the bid price. This is the price at which people are willing to buy. These are the orders that they, the amount that they are willing to buy. And here's a limit order, meaning that this person is willing to buy these many shares at that price. And there is a priority again in terms of time. So what happens in a market order? In a market order you can come in and start buying off of this limit book. So let's say that you want to sell something. When, and you want to sell a particular set of shares. Let's say you want to sell these many shares. When you arrive, there is somebody waiting on this side that is willing to buy those shares at that price. So this much share gets deducted from that account and you end up getting, that this is the remaining volume. And the problem with the market order is that you end up getting the bid price for it. Where as if you had decided to put a limit order inside of this particular point, you would have gotten a higher price. But, you would have to wait till somebody comes along and is willing to buy you at the higher price. so there is this trade off between getting a better price versus having uncertainty about when your order will get executed. So the market order picks up orders from the Limit book starting from the bid or offer price, that is the best buy or sell order in the limit book. You get immediate execution, you get low revenue from selling and high cost from buying. A limit order on the other hand, places the order on the limit book at a specified price. The execution time is uncertain, the revenue of the cost is higher or respectively lower. So you get a better deal, but when basic execution happens to become uncertain, whether and where to place a limit order is a function of patience. Whether you're, this is an opportunistic trade or an immediate trade. Depends on the volatility of the price because the entire order book moves back and forth depending upon what happens to the mid-price which is approximately the price of the asset. If it's very volatile the order book is going to move quite a bit and your orders will get deep orders and the limit will get traded. On the other hand if the volatility is low this is not going to happen. Sometime discount is giving the liquidity providers, so if you place orders on limit book because you're providing liquidity, you get a discount. And that affects whether or not you're going to put a market order or a limit order. Another little concept that's coming up and becoming very important is this controversy of dark pools. Dark pools are. Dark pools of liquidity are venues where blocks of shares can be bought or sold without revealing either the size of the trade or the identity of the trade until the trade is filled. By contrast, regular exchanges are called lit pools. They're transparent. You can see the order book. You can see how many shares are available at what price. Consequently, dark pools trading a wide market Impact. You don't know how many people are willing to sale. What is the order that is available? And as a result, because this information is not available those orders do not impact the price. But with dark pools, because you don't know what the limit book looks like, if you put them in order the volume of the trade, the amount of your trade that's going to get excluded and at what price it's going to be executed remains uncertain. They have recently attracted a lot of controversy because by some estimates dark pools are attracting about 11 to 12% of the volume of certain securities. And because that much volume is going away from the lit venues, it's impacting price discovery, and publicly traded price will no longer be fair. Dark pools have a winner's curse problem. A buyer who buys a big block in the dark pool knows for sure that there was much higher volume available. And so in some sense maybe what they should have done is let this volume go into a lit venue. Drive the price down, and then buy whatever they wanted to get from it. And as a result they could have bought at a better price on a lit venue but there is a problem that the seller would not have come to a lit revenue, a lit venue if they have a very large trade to make. In 2009, SEC introduced new measures to increase the transparency of dark pools, so investors get a clear view of stock prices and liquidity. So this is a concept that's, that's controversial, it's being pushed by a number of banks, particularly because it aligns very nicely with the [UNKNOWN] desk, but it is something to keep in mind.

## 020.Optimal Execution in Excel and Real Options

### 037. Optimal Execution in Excel 1

In this module, I'm going to walk you through how to set up this optimization problem that involves a mean term, a variance term, and a liquidity cost term, and compute portfolios or positions that optimize mean variance and a cost term. So here's a fictitious example that has been created. I have 10 different assets. Here are the mean returns for these assets. Here's the variance, covariance matrix for these assets. And then I also computed the volatilities by simply taking the square root of these quantities and multiplying them by 100. Then I define something called volume. I'm not particular about what the units are. So in, in whatever are the base units, the volume is 10, 0.1, .01, and so on. So, the first asset is very liquid, and the third asset is very illiquid according to these units. The other assets are somewhere in the middle and asset number nine is the most liquid, it's about 100 units of volume per day. And the tension I'm trying to build up here in this example, is that the illiquid stocks, so this one for example, has high returns, so 7.17% return. And it's liquidity is 0.1, 6.75 return it's liquidity is 0.01. So, if we include, exclude concerns about liquidity, you should expect that you would want to hold asset three and four. Asset six which has medium It has 6.289, so about 6.3% return and its liquidity is around three. So, this one asset six is a good trade off between both return and liquidity. And we would want to see how things change. Five point, asset nine, which is very liquid, doesn't have very high returns from someone. So, here's the risk aversion parameter that I'm going to be using for my portfolio selection, which is ten, it's arbitrarily chosen. Here are the trading cost parameters. So, in my notes, I'm calling them a1, a2, a3. Here, I'm calling them alpha one, alpha two, alpha three, just because then, I can name them appropriately. Alpha one is the factor that hits the normalized paid volume, divided by the average beta volume, alpha two is a volatility term, and alpha three is just a interceptor. Beta is the power to which the percentage, of order to volume is raised, and it's typically around 0.65. So here's my initial portfolio. It's all ten units on all of these assets. And these are in the same units in which the volume has been quoted, so it's across the board uniform, and just to make things interesting I'm going to clear this. And keep it as the initial run. What about the trading costs? I'm going to use a formula. It's alpha one times 100 divided by b15, which is the average daily volume, and the volume here I'm quoting not in per share, but in the total dollar amounts traded because I want to keep the units of the portfolio and the units of the volume the same. So it's 100, divided by the daily volume in dollar terms, raised to the power beta, plus the absolute value of the difference between the initial position and the final position, raised to the power 1 plus beta. Alpha 2 times the volatility divided by 100 plus alpha 3 times the absolute value of the difference in the two assets. The difference is, just to be very clear here, I'm looking at positions and not at portfolio, so I'm just going to change these names back to. All right. So, now I'm setting up the optimization problem. The mean return is the just a product of the final positions and the mean return vector up there. The variance, take the final position, multiply it by the covariance matrix, and multiply the, the final positions once again and that will give you the variance. The trading cost is just the sum of the trading cost across various assets because I've assumed that the trading costs are going to be separable across assets. What about the objective? The objective is b31 which is the mean, minus lambda times b32, which is the variance, minus eta times b33 which is the trading cost. So the first thing I'm going to do is I'm going to set trading cost parameter to zero. This eta to be zero. And what does that mean? It means that I'm going to ignore liquidity constraints and I want to see where does the portfolio selection move the asset. So we should typically see if I just look at returns, we should start seeing more of an investment in asset three and asset four. Because they have high returns, but maybe not completely because of the covariance matrices and so on. So let's run the solver to try to get what it is, and what is solver going to do, it's going to maximize my objective subject to the constraint that the sum of the final position must equal the sum of the initial positions and I'm only allowing long positions here so, I'm going to make the variables non-negative. So I solve it. And you end up getting that basically the portfolio gets concentrated in asset three about 22% there, 32% in asset four. 14% in asset six which is so this medium one, 16% in asset seven, which has low liquidity and so on. So, this is the final position when I don't take liquidity into consideration. Now, let's put eta to be 0.1. So I have medium amount of liquidity constraints in place, and I want to see what happens to the final portfolio. So, let's again ask for our solver to solve it. Once again, the, the problem remains the same except now my objective function has changed because eta has been increased. So now, asset number four, which is not so liquid, but it still has a very high return, you end up still putting about 30% there but it is much smaller. Whereas asset number three which has lower return and much lower liquidity, now you start reducing the amount that you're going to put in there. Asset number one, which didn't have much of an investment before, but it has a pretty high liquidity, numbers about 10, ends up getting a good proportion. And the last one, asset number nine, which still, which has a liquidity of about 100 ends up getting a little bit more position. Let's increase this to 0.5 and run it again. And again, what it should intuitively happen is happening. Six and seven, which have high returns, their money is being pulled out, and it's being spread across other assets which have high liquidity. And that's pretty much what I wanted to show you in this module. You can take the approach that was by Andy Low and others and also set up an optimization problem which is very similar to this one.

### 038. Optimal Execution in Excel 2

In this module we'll walk through formulating and solving the optimum execution problem that we introduced in the previous video module. In order to set up the problem, I arbitrarily took that the asset we are trying to sell is the first asset. So the volatility of this one was read off from the previous worksheet. And it was the worksheet of volatility was given in percentage so I divided by a 100 to get what the volatility numbers are. The volume is the typical daily volume that I'm going to be using, and I need these two numbers in order to compute the [INAUDIBLE] glance's temporary price impact function. For the Permanent price function I took it to be gamma times n and the gamma number was taken to be .001. The alphas and the deltas, these correspond to the alpha here, corresponds to alpha two times B1 which is the volatility plus alpha 3. This one corresponds to basically the constant term in the temporary price impact function delta. I took I took it to be alpha1 plus the power divided plus beta. This is the other term that is involved in the temporary price impact function. And these 2 are used to compute what a temporary price impact function is going to be. Okay, I have a total of a thousand shares that I want to sell. These are the various trades so, in trade 1, in this particular setup, whatever I have, I sell 849 shares and in trade 2, I sell 104 shares and so on. And, should add up, and so this 1,000, this is a constraint that I'm going to put. In my portfolio selection, or execution problem. X is the inventory, so before anything gets sold the inventory is a 1,000. After I sell whatever is necessary, this is going to be simply initial inventory minus the trade. Similarly over here it's going to be now. This inventory minus the trade and so on. So by the end, I must have inventory equal to 0. In the beginning I have inventory equal to a 1000. All of these trades must add up to a 1000. So, given the trade amount, I can compute what the temporary cost is going to be, and what the permanent cost is going to be. The temporary cost is simply alpha, which is a linear term, times the absolute value of the trade, plus delta times the trade to the power 1 plus beta. And the beta turned out to be 1.5, in this particular case. And that has been read from the worksheet mean variance liquidity. What about the permanent cost? Permanent cost is going to be the linear term, so it's gamma times the trade, times the inventory, because any trade that I do, it's permanent price impact, effects all the inventory that is there at the end of the day. So that's what that term is going to be. The variance is simply going to be. Inventory squared times volatility squared, and that's what I'm going to sum. So the total trading cost is going to be the sum of the temporary cost plus the sum of the permanent cost. The variance is going to be just a sum of these x variance terms. The objective I've said it to be basically, the sum of the trading cost plus rho times the variance, and this is what I want to minimize. So let's start with row equals 0. So there is, I'm completely ignoring variability in my calculations, and I want to see what is going to happen to my execution strategy. When we talked about it in the module, we said that because I don't care about variability and the temporary price impact and the permanent price impact get minimized when you do equal, you should end up doing uniformly. And let's see whether that helps up happening. Here are my constraints that I want to minimize the objective subject to the constraint that the total sale, total amount of stocks that I share, sell, must equal 1,000. I had to put this extra constraint that any trade that is going to be less than the initial inventory just to keep the optimization problem bounded. I also made it on, all the unconstrained variables to be non negative which means that I cannot put an opposite trait. I can when I'm trying to sell along the way I'm not allowed to buy. But this is something that's worth exploring and may at least lead to some lower cost but I'm ignoring it. And now let's solve it. So when you started solver, it didn't give you exactly what we expected and that's because this is a non linear problem and the solver doesn't get you exactly the solution that you're looking for, but it is going towards a solution of uniform trades. It's over 100 shares over all ten days, totaling to a 1000 shares. Now if I put rho equal to 1, which means that I'm starting to value variability and I want to minimize variability, but the weight is around 1. I solve it now. So you end up getting front loading the optimal solution for this should be completely monotone but it's not exactly towards the very end you see .50.53.66. It should be monotone but because it's looking for a local minimum, it didn't exactly find it. Now, if I increase rho to be two, then it should try to reduce variability even further which means that it starts front loading and pay. The cost that is necessary for it. So now, buy 912 shares and you end up paying, which goes to give you a very high temporary price impact as well as a permanent price impact, and that's the cost you pay because you want to reduce variability. And pretty much that's what I wanted to show you in this particular worksheet.

### 039. Real Options

In this module, we are going to discuss real options. These are options that are written on nonfinancial, more operational units. And they have optionality built into it. Meaning that we have the option of doing one particular set of operations, or another set of operations. And we want to use option theory to value an operation with built-in options. In this set of modules we're going to talk about how Option Theory can be used to evaluate non-financial investment and decision problems. Some examples of this include the valuation the lease in a gold mine. We're going to go through this in detail, valuation of an equipment upgrade option. Also in the context of gold mine, we'll go through a detailed example of how one could use Option Theory for calculating the value of such an option, valuation of a drug development process, this could include options such that you could sell your IP to another company, or options such that you it can increase the investment into a particular drug process and so on. Evaluation of a manufacturing firm that has the option of contracting its facilities to other manufacturers. The option here is to decide when to contract out your facilities and how much of it to contract out. Depending up on the market conditions you could do that. And in order to figure out what the value of such a manufacture, manufacturing firm is, one has to, accurately describe the value of such an option. And we know that in order to calculate the value of an option, we have to define an discounted expected value according to the risk neutral measure. So one can apply that technique to value. A manufacturing firm. We'll go through simple examples of an evaluation of a tolling contract at a power plant, evaluation of a gas storage facilities, and so on. The real options paradigm wants to view a project as having many sources of uncertainty. These could include market uncertainties such as price for the product, demand for the product, industry uncertainties such as mergers, mergers and acquisitions happening, innovations happening in the industry, technical uncertainties such as research and development, when a particular research breakthrough will happen, how will the development progress happen and so on? Organizational uncertainties, key personnel might leave the company and what should the company do to react to it? Political uncertainties meaning there are regulatory changes, there could be wars, there could be government changes and so on. The real options paradigm wants to manage these uncertainties by adding flexibility to a project or to a company via options. And project management in this paradigm, is all about managing flexibility. So we will explore some simple examples of real options in these modules and get back to this idea of how to introduce flexibility, how to value the flexibility, how to optimally execute this flexibility, and so on. The example we'll be using is called a Simplico Gold Mine Case. This is example 12.7 from Investment Science in Luenberger. The set of the problem is as follows. We want to evaluate the value of a ten year lease on a gold mine. The details are as follows. The price of gold, the current price of gold, is $400 per ounce, much lower than what the current prices are right now. Each year, the price increases by a factor U, which is equal to 1.2 with probability P equal to .75, or decreases by a factor D equals .9. With probably one minus B equal to 0.25. The cost of extracting gold is $200 per ounce. The maximum rate of gold extraction is 10,000 ounces per year. The interest rate R is 10%, so given the interest rate and given U and D above, we can compute the risk neutral probability Q and that turns out to be two thirds. When we're doing this risk neutral probability, we're implicitly assuming that we can buy and short sell gold. We're going to use a convention, that the cash flow, occurs at the end of the year. The revenue is the determined by the price at the beginning of the year but this revenue appears at the end of the year for bookkeeping purposes. So here are some details of the modelling. The current time, t, is equal to 0. The lease ends at t equals to 10. At the beginning of the 10th year we have to return the mine back to the owners. And therefore, the lease ends. The states in each year is given by the gold prices at the beginning of the year. Let vts denote the value in state s at the beginning of the year t. It's the value of the lease in state s at the beginning of the year t. Since the lease ends in ten years, we know that v ten s is equal to zero. Now we want to compute, vts as as a recursion. So here's my time t, I'm sitting in a particular state s, and this state s is determined by the price of gold in that particular year. From this state I can go to two possible states. U times S, or D times S. The probability of going to U times S is Q, the risk-neutral probability, and the risk-neutral probability of going to D time S is one minus Q. I already know the value here. So I know VT plus 1 US, because I am doing a recursion backwards and similarly I know VT plus 1 DS and I want to compute what is going to happen. I want to compute VTS. And the recursion is very simple. You take the revenue in year T. Plus the expected value that you would get, starting from time T plus 1 and onwards and discounted back by a factor 1 plus R. The reason the revenue is also being discounted by a factor 1 plus R is because we assume that the revenue occurs at the end of the year and therefore it has to be discounted back by the annual interest rate R. The revenue in ERT can be written very simply to be the maximum of s minus c and 0 times the maximum rate at which you can produce gold, which is g. What does this mean? If the current price of gold is greater than the cost of extracting gold, so s minus c is strictly positive, then you will extract gold at the maximum possible rate. If s minus c is equal to 0, or less than 0, then you will not operate the mine. So implicitly we are assuming that there is no cost for shutting down operations in any given year. We can shut it down in one year, and reopen the mine the next year, and we don't pay any cost for that. Since we're interested in pricing this lease, all the expectations with, must be with respect to the risk-neutral measure. Or the risk-neutral probability. And that's why we are highlighting the fact that here the expectation is with respect to the risk-neutral probability. Written out in detail this is Q times the value at the up state. That's 1 minus Q times the value of the down state. We know the value at time ten. We can compute it backwards using lattice to compute V zero of S, which is the value of the lease at time zero. In the next module, I'm going to work through this in an Excel spreadsheet and show you exactly how this works out. Now we want to take this example a little bit further. If you think about this example for a moment, it is actually a sequence of option. We don't do it in that way, we don't compute it explicitly in that manner. But it is a sequence of options. At the beginning of every year, I can look at the price of gold and decide I have the option to either run the gold mine, or not run the gold mine. So, in every year, I have the option of running the gold mine or not running the gold mine. And that option, has been implicitly calculated here. It's a maximum of S minus C and zero. I can choose which one I want to opt for at the beginning of every year. In the next example we will explicitly include another option and then try to value it. So, this is an example with an equipment enhancement option. The details of the equipment upgrade are as follows. The cost of the upgrade is $4 million. It's a one time fixed cost. If you upgrade the equipment, the new rate of production goes up to 12,500 ounces per year instead of 10,000 ounces per year. But at the same time. The cost of production goes up to $240 per ounce instead of $200 per ounce that had existed before. This upgrade is an option, in that it can be exercised at any time over the lease period, but once the upgrade is in place, it applies for all future years. When the lease ends they upgrade the equipment in the worst part for the miners, and the question is, what is the value of this upgrade option? So we're going to solve this in stages. First thing we're going to define, is a, value function with the in place. So V up will denote a value function. The value of the mine in state S at time T with the equipment upgrade already in place. We can compute this using the same computations as we did for VS except that now we have to uses these new parameters, G up and C up. In order to calculate what V happens. Now, this is the value that you would get if the upgrade was already in place. But now you have to pay for the upgrade, and how does one model it? The upgrade is an American option that pays V up S minus $4 million if exercised in state S on AT. We haven't upgraded equipment yet. We are sitting on a situation where the mine is operating, but the equipment upgrade has not happened. If I decide to upgrade, I'll move to a different mine operating conditions at that particular time. So, here's my states s if I decide to upgrade. My value that I will get will be v up ts now, in this particular state. But in order to upgrade I will have to pay 4 million dollars so you end up getting 4 million dollars as The cost that you pay for this upgrade. Once exercised, the equipment is upgraded and the mine is operating according to policy corresponding to v up t, meaning that if we decide to operate a mine in v up t, we operate the mine once the equipment is placed. If we decide in a particular [INAUDIBLE] the cost. Of extracting gold is too high, we don't operate the mine,and so on. so let UTS define the value instead as in [UNKNOWN] with an upgrade option. This time, the equipment upgrade has not happened, we only have the option of upgrading the equipment. So what do you do? In every state. And every time you have two actions available to you. Either you exercise the option or you don't exercise the option and you continue. If you exercise the option, the process stops. You move to the lattice that corresponds to the upgraded mine. You pay 4 million dollars for it and you manage the mine as if the equipment upgrade was already in place. So that's the exercising option. If you continue, then you have not upgraded your cost of producing gold still remains at 200. Your maximum rate at which you can produce gold still remains as 10,000. And this recursion is just as if you were continuing with old equipment. And the decision now is which of these two actions to choose, whether to upgrade or to continue. And we will show you in an Excel spreadsheet how these calculations are done.

## 021.Energy and Commodities Modeling

### 040. Valuation of Natural Gas and Electricity Related Options

In this module, we're going to show you examples of natural gas and electricity related options, and show how option theory can be used to value operations with built in optionality. In this module, we're going to talk about two real options. The valuation of the natural gas storage facility, and the valuation of a toning contract on a electrical power plant. And we're going to show you how some of the concepts of option pricing, can be used to evaluate situations where operations play a big important role. Caverns can be used to store gas and profit from temporal variation of price. So the idea is, you buy natural gas when the price is low, store it in a cavern and then pump it out, and sell it into the market, when the price is high. Typically, natural gas in the United States is used for heating purposes. And the demand and therefore the price of natural gas goes up in winter, whereas, in summer it's cheaper, so you buy in summer, and you sell in winter. The goal is to evaluate the value of a lease on a cavern with capacity C. So we have a cavern, here's my cavern I can pump gas into it, or I can release gas out of it. And what I want to know is, what is the value of such a cavern? So let It denote the gas stored in the cavern on day, t. I would also refer sometimes to It, to be the inventory. How much gas do you have? Let zt greater than equal to 0, denote the gas pumped out of the cavern. So whenever I am pumping gas out of the cavern, meaning I'm selling it to the market, I'm going to assume that zt is greater than or equal to 0. When I'm pumping gas into the cavern, I'm going to assume that zt is less than equal to 0. So, fzi denote the loss of gas, if z units are pumped out when the gas volume, or the inventory in the cavern is I. Most of this loss. is because the gas is actually used to drive the pumps that are necessary for pumping in and pumping out the gas. Some part of it is leakage. Let P of D denote the price of gas at time T. Then the optimization problem that I am interested in solving is the following. B of D is the price, Z of t is the amount I pumped out, fzt it, is the loss that happened at time T, when I pumped out CT in the inventory, or the amount that I stored was It. So this entire thing, that gives me the revenue from selling gas. This is the discount, and this is the expectation with respect to the risk-neutral method. Again, since I'm interested in pricing, I need to ensure that the expectation is with respect to risk-neutral measure. Not the real world probability, but then risk-neutral probability. What are my constraints? I need to make sure that the inventory level, always lies between 0 and C. These are operating constraints, these are, this is where real, the real option part of the problem comes in. This is not a financial instrument alone. This is a financial instrument coupled with something physical. And this says that the inventory has to be positive, and cannot be more than the capacity C. Down here tells you the dynamics of inventory. Since I assume that zt is positive when I pull out, so the inventory and time t plus 1, is going to be simply it minus zt. The complicating factor in this particular problem is that zt, the decisions of pumping out, ha, can be a function of past prices, and the inventory level It, could be a arbitrary function of past prices inventory levels. And, therefore, it's not something that I can compute at times 0, as the prices evolve, I need to compute it dynamically, as we go along. This is not a new concept. Even with American option pricing, and the gold mine equipment upgrade option that we saw in the last module, this story was there. We had to decide, as we went along whether we want to upgrade, whether we want to exercise our option, and so on. Except that here, we have to also keep into consideration what happens to the inventory, what happens to the cost of actually pumping in or pumping out the gas that I need. So we can set it up, as a dynamic program. So what does this dynamic program consist of? It consists of value functions. As in the case of option pricing, we have a value function that tells me what is the value of being in a particular state. Except, in this particular problem, there are two states. This is the gas price, and this is the inventory. The decisions that you make depend on both the price and the inventory. And Vtip simply says, what is the value of this lease starting at time t, when your inventory is i, and the gas price, the current gas price is p. It's a maximum of p of z minus f z i. So this is the current revenue. And this is the value from the future. This is the value of the future. And that is discounted back By E to the minus R, to bring it back into present dollars. Remember there was this constraint, that we needed to make sure that the inventory lies between 0 and C. We will put that in here, by making this equal to minus infinity, if I minus Z is not in 0 to capital C. And that way, we can ensure that we never take decisions, where we are violating the constraints. How can one solve this dynamic program? We can use a binomial lattice for the price speed. So if that was the only state, we can do the backward recursion, that we've been using in the past. However, one has to innumerate all possible inventory levels. Inventories are continuous variables, which not clear how to do that. You can use approximate dynamic programming, where the value function is approximated by factors. You can sometimes use stimulation-based optimization, where you simulate the prices from time 0 to time capital T. And then use some kind of predictive control, to figure out how the inventory is going to behave, and how you're going to get the value function out of it. I'm not telling you the details of how these operations work. The point of this module, is simply to expose you to problems where one is using option pricing, in situation's that have to do with operations. Here's another example of a real option. Tolling agreements on a gas-fired power plant, allow a company renting a gas power plant, to operate it, and then use, typically natural gas, to generate electricity and to earn money, which is the difference between the cost of natural gas and the cost of electricity. What we want to evaluate in this particular problem, is the optimal operating policy for a company that is renting a two regime gas power plant, over a time period 0 to T. So what does this two regime power plant mean? It means, that the plant can be operated in a low capacity mode. In which case, the output is Q lower bar, the gas consumption is H lower bar. In the high capacity mode, the output is going to be Q upper bar, and the gas consumption is going to be H upper bar. The company does not own the power plant and, therefore, it has to pay rent to the owner's. If the power plant is shut down, it is not providing any electricity, then the rent they have to pay is k. If the plant is being operated in the low capacity mode, then they have to pay rent k lower bar. And if they are operating it in the high capacity mode, then they pay rent k upper bar. The reason because, the rent is different for different states, is because implicitly in the rent, you are also capturing the maintenance cost. If it shut down, then the owner of the plant is simply taking rent from you, for allowing you the usage of the plant. If you run it on a low capacity mode, then the rent include both the cost of actually giving you the operations, as well as the future cost of maintenance that they will have to pay, because the plant was run. Presumably, if you run the plant at a high capacity mode, they have to do, maintenance more often, and therefore, they're interested in actions. And therefore, they try to get a higher rent from you. So what is the state of the plant? The state of the plant is either 0 or 1. Either it's on or it's off. If the plant is on, and you want to turn it off, you have to pay a ramp down cost of Cd. If the plant is off, and you want to turn it on, you have to pay a ramp up cost Cu. That actions that are available in given state, is to turn the plant on or turn the plant off. So as before, in order to compute out what the value of a particular option, in this case, renting the plant, as well as trying to decide when to use the low capacity mode, and when to use the high capacity mode, when to shut down the plant, when to bring it back. These are all options that are, can be used by the company while it's operating the gas power plant. So, in order to compute the value, we'll postulate a value function. Let's say v t s d t t g t, so three states now, is the optimal profit over the time, little t to capital T, with the current state being s t, current state of the plant being s t, either on or off. Current price of electricity being Pt, and the current price of gas being Gt. So what I want to do now, is to set up an recursion for this problem. In order to set up this recursion, I have to tell you what happens when you take actions. So let c(s,a) denote the cost of taking action a when the plant is in state s. S takes two values, 0 or 1, a takes two values, 0 or 1. So plant is up or down, and action a basically says, either we bring the plant up or we bring the plant down. Let U S A denote the state of the plant, when action a is taken in state s. So here are the expression. If the state is 0, meaning that the plant is down, and we take the action as dow,n we do not bring it up, then the cost of this action is simply to pay the rent K. If the state was 0, and we decide to bring it up, then you pay the ramp up cost plus the rent K. If the state was up and you put it down, then you pay the ramp down cost plus the rent K. Now, suppose the state of the plant was up. And you continued operating it, you took the action of being up. Then, you have the option of deciding to run the plant either at the low capacity mode, or the high capacity mode. So this maximum, is actually is also evaluating an option. If you run it at the low capacity mode, you have Q lower bar as the production, H lower bar as the consumption of gas, and K lower bar as the rent that you want to pay. So this is, this is the profit in low capacity, and this is the profit, in high capacity. You take the maximum of these two, and decide that, that's the option that you are going to exercise. What about the next state? If the current state S is equal to 0, and the action A is equal to 0, the next state is 0. If the action is equal to 1, the next state is 1. If the action here is 0, the next state is 0, action is 1, the next state is 1. So the next state is basically whatever action that you do. The dynamic program that is going to be underlying this, is that in a particular state SPD and GD, you take a maximum overall possible action, so action takes value 0 or 1. The current cost of operating, so this is the current profit of operating, sometimes it's negative ,meaning that you just have to pay, and this is a future profit. This counted and again, risk-neutral, because we're interested in pricing. Now the stake here, consists of the price of electricity, the price of gas and the state of the plant 0 1. One can solve this dynamic program by constructing a binomial lattice, for a gas price and electricity price separately. If you want to get a correlations, then we'll have to correlate these two binomial lattices. Each point in this lattice now will actually represent two different points. S equals to 0 and s equal to 1, meaning plant is down or plant is up. This is similar to the story that we built in for the defordable bonds. We had a term structure for interest rates, which was a binomial lattice, and in every state we split it up into two states. Born alive, or born defaulted. Similarly, over here, we'll have a binary lattice, and every node will get split up into two states. Plan up, plan down, we can do the recursion, and compute out what the values of option is going to be. Again, I'm not going to be showing you how to compute this in practice. It's a module, where we are trying to introduce this idea, that option theory and financial engineering is starting to make an impact in other applications, where people have to also include the cost of operations.

### 041. Real Options in Excel

In this module, we'll go through the Simplico Gold Mine example that we introduced in the video modules. The first half of this module is about the operating option, meaning that the only thing that I'm trying to value is a lease over ten periods and every year I have the option of either shutting down the mine or operating it at the maximum possible rate. In the next half of this module we are going to value an equipment upgrade option that is also valid over the ten years that we are trying to figure out when we will exercise it. And what is the net revenue gain that I would get from that option? So here are the details of the model. The current price of gold is $400 per ounce. It can go up by a factor of 1.2 or go down with a factor of 0.9. The interest rate is 10%. And therefore, from there I can calculate out what the risk-neutral probability of the up state is, and the risk-neutral probability of the down state is. So that's going to be Q and one minus Q, respectively. The extraction rate, and cost are as follows. The cost is $200 per ounce. The extraction rate is 10,000 ounces per year. So in order to decide when to operate this plant and when to shut it down, I need to have a lattice of gold. Whenever the gold price is greater than $200, I'm going to operate the plant. And I'm going to operate it at 10,000 ounces per year. Whenever the price of gold is below $200 I'm going to shut it down and not incur any costs. Here is the gold lattice, it starts with $400, it goes up to 480 or goes down to 360 and so on. These are in thousands of dollars for ups. Down here you'll see States where the price of gold is lower than the $200 required to extract gold. And therefore in these States we are going to exercise the option of shutting down the mine and incurring no cost. In all the other States where the price of gold is greater than $200, we are going to exercise the option of operating the plant, and getting the profits that we get from it. So here are, here is a value of the gold mine lease, in millions of dollars. At the beginning of the tenth year we return the gold mine back to the owners and therefore the value at the beginning of the tenth year from the future is going to be zero. Now we start looking at what is going to happen to a state before. So if we look at a particular state over here, all we are trying to do, is we are using the formula that we had developed in the video modules. If I decide to operate the gold mine, I'm going to get K19 minus cost, which is the price at the current point, minus cost, times the maximum possible rate. But if this term, K19 minus cost, the current price minus the cost of operating the mine happens to be less than zero, I will elect not to run the mine. I will exercise the option of shutting it down, and get a zero from this term. So this max of K19 minus cost and zero times the rate tells you what is the one year revenue from operating the mine in the optimal fashion. And that might include shutting it down. This next term, Q time offset K33 minus 11 and 1 minus Q times offset K3301 basically computes what is the expected value from the future. It's Q times the value in the upstate plus 1 minus Q times the value in the downstate, at time T plus 1, and all of it is divided by 1 plus the interest rate to bring it down to current dollar terms. So same thing is being done overe here at previous times. Exactly the same thing and at the end of the day you end up getting that the value of this option turns out to be 24.07 million dollars. That is total value that you could generate from leasing this market. That's the fair price for the mine under the circumstances that we are considering. Now let's go on to consider the case with an equipment option in place. So the story is the same. The gold price dynamics remain the same. You've got $400 per ounce today. They go up by a factor of 1.2, go down by a factor .9, and the risk neutral probability is 0.6. The interest rate is 10%. This lattice is exactly the same as it was in the previous page. So now what we want to do, is figure out what is the value of an option that allows us to upgrade the equipment any time between time zero, which is now, and time ten, when I return the mine back to its owner. As we detailed in the video module, in order to compute this, I want to think of it as an American option on two different mines. So I've got the mine which is operating as it does currently, with $200 per ounce as the operating cost, 10,000 as the maximum extraction rate. At any given time I can exercise my upgrade option and move to another mine, which has $240 per ounce as the operating cost, but 12,500 as the maximum possible rate. In order to do this, we showed in the video modules, I have to first calculate out the value of a gold mine with the equipment option already in place. And that's what I'm dong over here. This is the value of a gold mine lease with the cost equal to 240 and the rate equal to 12,500. This is the value where the equipment upgrade has already happened. Again, the calculation is the same as before. You start with all zeroes and then you back calculate. You back calculate as K16, which is the cost of gold, or price of gold, minus the cost of operation, which in this case is 240, times the maximum rate, which is 12,500. And Q time the upstate plus 1 minus Q the times table divided by the interest rate, which is 1 plus the interest rate. Calculate it backwards and you end up getting various values of the various states in this particular latice. Now we want to value what happens to the gold mine with an equiment option in place. You start off with 0s here. In the beginning of the 10th year you have to give the gold mine back, whether you upgraded the equipment or not, and therefore the value you end up getting is 0. Now lets see what happens to this particular state. It's a complicated formula, so lets go through it one by one. There are two different MAXs, there's one term over here. So this term is the same expression that we had for figuring out what to do with a gold mine where the operating cost was 200 and the operating rate or the maximum rate at which you could extract gold was 10,000. So this particular maximum, all it's saying is that if I continue to use the current mine, meaning not upgrade, then I still have to decide whether I would operate the mine or not, and that corresponds to the max of K16 minus 200 and 0, and if I decide to operate, I'm going to run it at the maximum possible rate. And then I need to figure out what'll happen in the future. The second term over here, this maximum, refers to the fact that now I have the option of moving from this lattice point to the lattice that corresponds to an upgraded mine. So instead of staying on this lattice, I'll move to the upper lattice. But in order to move the upper lattice, I have to pay a cost of $4 million. So, K35 is the value that I would get, in this upgraded lattice, which is 20.73, but I have to pay $4 million for it, and therefore, I have to decide whether it's worth it. If you look at what happened over here, the value here is 20.73, the value here is 16.94. If I had decided to upgrade, I would have got 20.73 minus $4 million which is 16.73. In this particular state I can get $16.94 million simply by continuing. So its worth it for me to continue, and not pay the extra $4 million. Same thing we go backwards. Calculate out exactly the same calculations here we here. What is the maximum profit that I could get by continuing with my current mine operations? Or I can upgrade by paying $1 million. The value here is 29.88. Which is 33.88 minus 4, so it appears that at least in this particular state, we will jump up, and in a little bit I'm going to show you how exactly the exercise boundary's going to be calculated. We calculate this backwards, starting from ten all the way down to time one, and at time one we get a time zero which is the initial state we end up getting that the value of the gold mine with the equipment option in place is $24.63 million. And if you compare this to the lease without the equipment option, it's $24.07 million. So it turns out that it is having that option, that equipment option is valuable. And the value of that is approximately $0.6 million. The thing to think about is that we can consider two different situations. One situation where we have the option in place, and another situation where we are forced to upgrade at time zero. If we are forced to upgrade at time zero, we will get $27.02 million, which is the value that I get with the upgraded mike, minus $4 million, so we would, I would only get $23.02 million. Whereas, with an option in hand, I can get $24.63 million. And the difference between these two comes from the fact with an option I have the flexibility of when I excersize the option. So it will turn out that the various states, when the price of gold is high, and therefore I expect to make a lot of profit, it makes sense for me to pay the extra operating cost of $40 per ounce in order to get the extra rate of extraction, which is 2500 more. So in order to decide where we are going to extract, we just compute the two value functions. So, if you look at the genetic one over here, what we are doing is we are looking at the value function of exercising my option versus the value function of continuing. If the difference between them is positive, I'm going to exercise. If the difference is negative I'm going to not exercise. Negative or zero I won't exercise. So if you calculate this out, you end up getting a exercise frontier, which is the states at which you are going to exercise.

## 022.I

### 042. Review of Basic Probability

>> We're now going to review some of the basic concepts from probability. We'll discuss expectations and variances, we'll discuss Bayes' theorem, and we'll also review some of the commonly used distributions from probability theory. These include the binomial and Poisson distributions as well as the normal and log normal distributions. First of all, I just want to remind all of us what's a cumulative distribution function is. A CDF, a cumulative distribution function is f of x, we're going to use f of x to denote the CDF and we define f of x to be equal to a probability that a random variable x is less than or equal to little x. Okay. We also, for discrete random variables, have what's called a probability mass function. Okay. And a probability mass function, which we'll denote with little p, it satisfies the following properties. P is greater than or equal to 0, and for all events, A, we have that the probability that x is in A, okay, is equal to the sum of p of x over all those outcomes x that are in the event A. Okay. The expected value of a discrete random variable, x, is then given to us by this over here. So, it's the sum of the possible values of the random variable x. These are the xi's, weighted by their probabilities, p of xi. So, that's the expected value of x. If I was to give you an example. Suppose, for example I tosses a dice. So, it takes on 6 possible values. Okay, 1, 2, 3, 4, 5, and 6. Okay. And it takes on each of these values with probability, so that's wp, with probability 1 6th, with probability 1 6th and all the way down 1 6th. So, in this case, for example, the probability that x is greater than or equal to 4 is equal to, well, it's 1 6th for 4, 1 6th for 5, and 1 6th for 6, so that's equal to 1 6th plus 1 6th plus 1 6th equals 1 half. Likewise, we can compute the expected value of x. In this case, it is equal to 1 6th times 1 plus 1 6th times 2, and so on, plus 1 6th times 6. And that comes out to be 3 and a half. Okay. So, we also have the variance of a random variable. It's defined as the expected value of x minus the expected value of x, all to be squared. And if you expand this quantity out, you can see that you'll also get this alternative representation, so that the variance of x is also equal to the expected value of x squared minus the expected value of x, all to be squared. Okay. So, there, a discrete round of variables, probability mass function, and so on. So, let's look at a couple of distributions. The first distribution I want to talk about is the binomial distribution. We say that a random variable x has a binomial distribution, and we write it as x tilde binomial, or bin n, p, if the probability that x is equal to r, is equal to n choose r times p to the r by 1 minus p to the n minus r. And for those of you who have forgotten, n choose r is equal to n factorial divided by r factorial times n minus r factorial. So, the binomial distribution arises, for example, in the following situation. Suppose we toss a coin n times, and we count the number of heads. Well then, the total number of heads has a binomial distribution and we're assuming here that these are independent coin tosses so that the result of one coin toss has no impact or influence on the, the outcome of other coin tosses. The mean and variance of the binomial distribution are given to you by these quantities here. So, the expected value of x equals np, the variance of x equals np times 1 minus p. Now, there's actually an interesting application of the binomial distribution to finance. And it actually arises in the context of analyzing fund manager performance. We'll actually return to this example later in the course. But let me just give you a little flavor of it now. So, suppose, for example, a fund manager outperforms the market in any given year, with probability p. And that she underperforms the market at probability 1 minus p. So, we're assuming here that the fund manager either outperforms or underperforms the market, only two possible outcomes. And that they occur with probabilities p and 1 minus p respectively. Suppose this fund manager has a track record of ten years, and that she has outperformed the market in eight of these ten years. Moreover, let's assume that the performance, the fund manager performance in any one year is independent of the performance in other years. So, a question that many of us would like to ask is the following. How likely is a track record as good as this outperforming eight years out of ten, if the fund manager had no skill? And, of course, if the fund manager had no skill, we could assume maybe that p is equal 1 half. Okay. So, actually, we can answer this question using the binomial model, or the binomial distribution. So, let x be the number of outperforming years. Since the fund manager has no skill, then there are ten years, and the total number of outperforming years x, is then binomial, with n equals 10, 10 years, and p equals a half, okay? So, we can then compute the probability that the phone manager does at least as well as outperforming in eight years out of ten, by calculating the probability that X is greater than or equal to 8. So, what we're doing here is calculating the probability that the fund manager would have 8, 9, or 10 years out of 10 in which she outperformed the market. And that is given to us by the sum of these binomial probabilities here. So, these were the original binomial probabilities on each slide, and we summed them from r equals 8, to n. And n, in this case, of course, is 10, okay? So, that's one way to try and evaluate whether the fund manager has just been lucky or not. One can compute this probability and if it's very small, then you might conclude that the fund manager was not lucky and that she had some skill. But actually, this opens up a whole can of worms. There are a lot of other related questions that are very interesting. Suppose there are M fund managers, how well should the best one do over the ten-year period if none of them had any skill? So, in this case, you don't have just one fund manager as we had in this example so far, we now have M of them, okay? And it stands to reason that even if none of them had any skill, then as M gets large, you would expect at least one of them or even a few of them to do very well. Well, how can you analyze that? Again, you can use the binomial model and what are called order statistics of the binomial model to do this. And we'll actually return to this question later in the course. Okay. So, let's talk about another distribution that often arises in finance and financial engineering, that is the Poisson distribution. We say, that x has a Poisson lambda distribution so lambda is the parameter of the distribution. If the probability that x equals r is equal to the lambda to the power of r times e to the minus lambda, divided by r factorial. And for those who have forgotten factorials, I also used it in the binomial model a while ago. R factorial is equal to r times r minus 1 times r minus 2, all the way down to 2 times 1. Okay. So, this is the Poisson distribution. The expected value and the variance of a Poisson random variable are identical and equal to lambda. So, for example, we'll actually just show this result here. It's very simple and the mean is calculated as follows. We know that the expected value of x is equal to the sum of the possible values of x, so these are the r's, times the probability that x is equal to r and r runs from 0 to infinity. We can calculate that as follows. So, we have the summation of r and the probability that X equals r. We know from up here, okay, and we can substitute that down in here and now, we just evaluate the sum. The first thing to notice is that when r equals 0, this term in the sum is equal to 0. So, we can actually ignore the 0, the first element, the 0 element and replace the summation running from r equals 1. So then, we get this quantity here. We can cancel this r out with the first r up here and write, this is r minus 1 factorial. We can also pull one of these lambdas out here leaving us with a lambda to the r minus 1. And now, if we look at this quantity here, this summation here, we see that this is the same as changing this to run from r equals 1 to r equals 0 and replacing r minus 1 with r and r minus 1 factorial with r factorial here. This total we see is equal to the sum of the probabilities. These are the probability that x equals r, so this is the sum of the probabilities that x equals 0, x equals 1, x equals 2, so this is equal to 1. The total sum of probabilities must be equal to 1, so this is equal to lambda. Okay, let's talk a little bit now about Bayes' theorem. Let A and B be two events for which the probability of B is nonzero, then the probability if A given B, and this is notation we'll use throughout the course, this vertical line means it's a conditional probability. S,o it's the probability of A given that B has occurred, well, this is equal to the probability of A intersection B divided by the probability of B. Alternatively, we can actually write this, this numerator probably of A intersection B, as being the probability of B given A by the probability of A. So, this is another way to write a Bayes' theorem. And finally, if we like, we can actually expand the denominator here, the probability of B, and write it as the summation of the probability of B given Aj, by the probability of Aj. Let me sum over all Aj's. For the Aj's, form a partition of the sample-space. What do I mean by partition? Well, I mean the following. So, Ai intersection Aj is equal to the null set, for i not equal to j, and at least 1 Ai, at least, at least one Ai must occur. And, in fact, because Ai intersection Aj is equal to the null set, for i not equal to j, I can actually replace this condition with the following, exactly one Ai must occur. Okay. So, that's Bayes' theorem. Let's look at an example. So, here's an example where we're going to toss 2 fair 6-sided dice. So, Y1 is going to be the outcome of the first toss, and Y2 would be the outcome of the second toss. X is equal to the sum of the two, and that's what we plotted in the table here. So, for example, the 9 here comes from the 5 on the first toss and 4 on the second toss. So, 4 plus 5 equals 9. So, that's X equals Y1 plus Y2. So, the question we're interested in answering is the following. What is the probability of Y1 being greater than or equal to 4, given that x is greater than or equal to 8? Well, we can answer this using this guy here on the previous slide. So, this is equal to the probability that Y1 is greater than or equal to 4 and X is greater than or equal to 8, divided by the probability that X is greater than or equal to 8. Okay. So, how do we calculate these two quantities? Let's look at the numerator first of all. So, we need two events here. Y1 must be greater than or equal to 4 and X being greater than or equal to 8. Okay. So, the first event is clearly captured inside this box here, okay, because this corresponds to Y1 being greater than or equal to 4. So, all of these outcomes correspond to that event. The event that X is greater than or equal to 8 corresponds to this event or these outcomes. So therefore, the intersection of these two outcomes, where Y1 is greater than or equal to 4 and X is greater than or equal to 8, is this area here, which is very light, so let me do it a little bit darker. So, it's this area here. Now, each of these cells is equally probable and occurs at probability 1 over 36. There are a total of 3, 4, 7, plus 5, 12. So that's 12 cells here. So, the numerator occurs with probability 12 over 36. And the, the denominator, the probability that X is greater than or equal to 8, well, that's what we highlighted in the red here. And the probability of that occurring, well, there's 12 plus these 3 additional outcomes equals 15 outcomes. So, that's 15 over 36, and that is equal to 4 over 5. So, that's our application of, of Bayes' theorem. Okay. So, let me talk a little about continuous random variables. We say a continuous random variable x has a probability density function, or a PDF, f. If f of x is greater or equal to 0, and for all events, A, the probability that x is in A, or the probability that A has occurred is the integral of the density, f of y, dy over A. The CDF, cumulative distribution function, and the PDF are related as follows, f of x is equal to the integral from minus infinity to little x of f of y dy. And, of course, that's because we know that f of x, by definition, is equal to the probability that X is less than or equal to x, so this, of course, is equal to the probability that minus infinity is less than or equal to X, is less than or equal to little x. So, this is our event A here and this definition here. So, A is now integrated from, A is now the event minus infinity less than or equal to the random variable x, less than or equal to little x, so that's what we have over here. So, it's often convenient to recognize the following, that the probability that x is in this little integral here, x minus epsilon of 2 and x plus epsilon over 2. Well, that's equal to this integral, x minus epsilon over 2 to x plus epsilon over 2 times f of y dy, okay? And if you like, we can draw, something like this. So, this could be the density, f of x. This is x here, maybe we've got some point here which is little x, and this is x minus epsilon over 2. This is x plus epsilon over 2. So, in fact, what we're saying is that the probability is this shaded area, and it's roughly equal to this value, which is f of x times epsilon, which is the width of this interval here, okay? And, of course, the approximation clearly works much better as epsilon gets very small. Okay. So, there are continuous random variables. Let me talk briefly about the normal distribution. We say that X has a normal distribution or write X tilde N mu sigma squared if it has this density function here. So, f of x equals 1 over root 2 pi sigma squared times the exponential of minus x minus mu, all to be squared divided by 2 sigma squared. The mean and variance are given to us by mu and sigma squared respectively. So, the normal distributions are very important distribution in practice, its mean is at mu, its mode, the highest point in the density is also at mu and approximately 95% of the probability actually lies within plus or minus 2 standard deviations of the mean. So, this is approximately equal to 95% for a normal distribution. Okay. So, this is a very famous distribution. It arises an awful lot in finance. It certainly has its weaknesses and we'll discuss some of them as well later in the course. A related distribution is the log-normal distribution. And we will write that x has got a log-normal distribution with parameters mu and sigma squared if the log of x, is normally distributed with mean mu and variance sigma squared. The mean and variance of the log-normal distribution as given to us by these two quantities here, and again, the log-normal distribution plays a very important role in financial applications.

### 043. Review of Conditional Expectations and Variances

We're now going to review the concepts of conditional expectation and conditional variances. We'll see that conditional expectations identity as well as the conditional variance identity, and we'll see an example where we put them to work. This material is useful because we will use it later in the course when we discuss credit derivitives. When x and y be two random variables, then the conditional expectation identity states that the expected value of x can be calculated as follows. We first compute the expected value of x conditional on y and then we actually compute the expected value of that quantity. Likewise, the conditional variance identity states that we can compute the variance of x as the summation of two quantities. First of all, we can compute the expected value of x given y, and then compute the variance of this quantity. And then, also compute the variance of the expected value, sorry, then compute the variance of x given y and compute the expected value of this quantity. Okay. One thing I want to emphasize here is that the expected value of x given y, and the variance of x given y, are both functions of y, and are there for random variables themselves. So for example, I actually could write this as g of y, say, so this is also a g of y, and maybe the variance of x given y, I could write as h of y. So g of y, and h of y, are random variables. So in fact, I can write the expected value of x, as being the expected value of g of y, okay. And, I can write the variance, of x, as then being equal to the variance, of the random variable g of y. Plus the expected value of the random variable h of y. Okay so there the conditional expectation and conditional variance identities and they can be very useful in many applications. So we'll see one application here. So, we want to compute a random sum of random variables. In particular we're going to that w equal to x1 plus x2 and so on up to xn where the xi's are IID with mean ux and variance sigma x squared. But where n is also a random variable and this random variable is assumed to be independent of the variable xi's. So the question that arises is the following. What is the expected value w? Well I can compute the expected value of w using the conditional expectation identity. In particular the expected value of w. Well, over here I can write that as being equal to the expected value of the expected value of w given n. And this quantity here inside here is w. Okay. So the expected value of w, given n, if you think about it, the expected value of w, given n, is equal to the expected value of this summation, i equals 1 to n of the xi's. And because n is a constant, given n, I should have an n here, okay. This is equal to the sum, n, i equals 1, of the expected value of the xi's, and this is equal to, well this is equal to mu x. And there's n terms, so that's n mu x. And that's where this comes from here. Okay. So now the mu x is a constant. We can take it outside the outer expectation over here, and we're left with the expected value of N. So that's how we compute the expected value of w. How about the variance of w. Well, we can compute the variance of w by using the conditional variance identity. So this is the variance identity here. We've already calculated the expected value of w given n. It's equal to n times mu x, so that's what this quantity is down here. The variance of w given n, well that's the variance of this quantity given n. These are n IID rounding variables and the variance of n IID rounding variables is simply n times the variance of one of them, which is sigma x squared. And so we get n times sigma x squared here. So now, the variance of mu x times n, well mu x is a constant, so it comes out the variance, outside the variance is a square. And we're left with mu x squared times the variance of n. And over here, sigma x squared is a constant, and it comes outside the expectation, and we're left the expected value of n. So that's how we compute the variance of w. So here's an example with chickens and eggs. A hen lays n eggs where n is plus on with parameter lambda. Each egg hatches and yields a chicken with probability p independently of the other eggs and then. Let k be the number of chickens. So the first question I want to ask is, what is the expected value of k given n? And of course one of the reasons I want to ask this question is because I want to introduce indicator functions, which are often very useful in probability, and in fact we'll use them later in the course. We'll be using indicator functions later in the course to describe the event of companies defaulting on their bonds. So we'll use it to compute the expected number of defaults in the basket of bonds for example. So it's a good place right now, we could add here right now to introduce these indicator functions. So what we're going to do is we're going to write the total number of chickens, k, as being the sum from I equals 1 to capital N times one subscript hi where hi is the event that the ith egg hatches. Okay. So in particular, one subscript to hi. This is the indicator function, and it takes on 2 possible values. It takes on the value 1 if the ith egg hatches. And it takes on the value 0 otherwise. So in fact that's an indicator function in general it takes on two values one and zero. One if the event in question occurs zero otherwise. In this particular example the event in question is hi which is the event that the ith egg hatches. Okay so we've written k as the sum from i equals 1 to n of these indicator functions. It's also clear that the expected value of one of these indicator functions is easily computed. In particular, it takes on the value 1 with probability p. It takes on the value 0 with probability 1 minus p, and so this is equal to p. So the expected value of the indicator function 1 hi is equal to p. So now the expected value of k given n is the expected value of this quantity which is k given n and n is a constant at this point because of conditions on its value. So, we can just take the expectation inside the summation and get this, but we know the expected value of 1hi is equal to p. There's n of these terms, so we get np. So therefore the expected value of k given n equals n times p. Which of course is what you'd expect if you've got n eggs and each of them occurs with probability p. You would expect the total number of chickens to be n times p. Okay. So now, we can use the conditional expectation form to compute the expected value of k. The expected value of k is equal to the expected value of the expected value of k, given n. But that, we have calculated there. It's np. So now, the expected value of k is the expected value of np. P is a constant. So it can come outside over here. And the expected value of n? Well n is Poisson we're told and if we recall, the expected value of a Poisson random variable is equal to lamda and so that's why we get the lamda down here. And so we see that the expected number of chickens is equal to lambda times p.

## 023.II

### 044. Review of Multivariate Distributions

>> We're now going to review multivariate distributions. We'll talk about multivariate CDFs, multivariate PDFs, conditional distributions, and so on. Much of this material is a little tedious, a little dull, but we thought it was worthwhile collecting it all and having it in one place for your review if it crops up later in the course. Okay, so let's get started. Let x be a vector of random variables, x 1 up to x n. We say the joint CDF of x is given to us by the following. So, the joint CDF, Fx of little x is equal to the probability that X1 is less than or equal to little x1. X2 is less than or equal to little x2. Up to xn being less than or equal to little x n. And from this joint CDF, we can actually calculate the marginal CDF, so for example, the marginal CDF of Xi is given to us by just plugging infinity into all of the components in the joint CDF except for the ith component which is little xi. Okay, so we can go from the joint CDF to the marginal CDF. It is also straightforward to generalize the previous definition to joint marginal distributions. So for example, if I want the joint CDF of just xi and xj, I can also recover that from the joint CDF of 1 up to xn by placing infinity in all of the arguments, except for the ith argument where I have xi and the jth, where I have xj. We also say that x is a joint PDF or probability density function, f subscript x, if we can write the joint CDF as an integral like this. So, this is just the way we, we, we capture our joint CDF by integrating out the density function by appropriate limits. Okay. We can also talk about conditional CDFs. So what we're going to do is we're going to partition our vector x1 up to xn into two components. The first component is x1, which contains x1 up to xk. And the second component is this boldface x2 which contains xk plus 1 up to xn. And then we can talk about the conditional CDF of x2 given x1, and in fact, it's defined as following, as follows. So the conditional CDF of x2 given x1 is equal to the probability that the random vector x2 is less than or equal to little x2 conditional on x1 being equal to little x1. If x is a PDF, f of x, then the conditional PDF of xx2 is given to us by this quantity here. So it's the joint PDF divided by the marginal PDF of x1, which we can also write like this. Okay. And the conditional CDF, f of x2 given x1, can be determined by integrating the conditional PDF. So this is our conditional PDF, and we can integrate this out with respect to uk1 up to un and that will give us our conditional CDF. Okay, independence. We say the collection x is independent if the joint CDF can be factored into the product of marginal CDFs. So in particular the joint CDF here in the left hand side is equal to the product of the marginal PDFs over here on the right hand side. Similarly, actually, this implies that if x is a PDF fx, then we can also factorize the joint PDF into the product of the marginal PDFs over here. We can also see from one, and one is here on the previous slide. So we can use this, okay, to see that if x1 and x2 are independent, then the conditional PDF of x2 given x1, well by 1, that's equal to this ratio here. So the joint PDF of x divided by the margin PDF of x 1 and by independence here, we can replace the joint PDF by the product. Then these two cancel and we're left with the marginal PDF of x2. So what we're saying here is that if x1 and x2 are independent then the conditional PDF of x2 given x1 is simply the marginal PDF, f of x2. In other words, having information about x1 tells you nothing about x2 when x1 and x2 are independent. Okay. Some implications of independence. Well,and I expect we're all familiar with this, but let's, let's go through it anyway. Let X and Y be independent random variables. Then for any events A and B, the probability that X is in A and Y is in B, well, that factorize into the product of the probability of X being an A times the probability of Y being in B. More generally, for any functions, f and g, independence of X and Y implies the expected value of f of X times g of Y is equal to the expected value of f of X times the expected value of g of Y. And in fact, 2 follows from 3, okay? So the implication goes that way and it's easy to see this, because we can write this probability of X being in A and Y being in B as the expected value of the indicator function of X and A times the indicator function of Y and B. Just to remind ourselves what is this indicator function, while it takes on two possible values, it takes on the value 1 if X is in A and it takes on the value 0 otherwise. So therefore, the product of these two indicator functions is 1 or 0 and will only be 1 if X is in A and Y is in B. Okay? That occurs with probability X and A, and Y and B. So this statement here is correct. Okay, so we've got this first line. And now we can use the independents X and Y in condition three to break down this expectation down into the product of these two seperate expectations. Okay. But of course, this expectation is the probability that X is in A and this expectation is the probability that Y is in B. So indeed we do see that we can go from three to two. Okay. More generally, if X1 up to Xn are independent random variables, then we can write the expected value of f1 of X1, f2 of X2, and so on up to fn of Xn. That factorizes into a product of n separate expectations. The expected value of f1 of X1 times the expected value of f2 of X2 and so on. Random variables can also be conditionally independent. For example, we say that X and Y are conditionally independent given Z, if the expected value of f of X times g of Y given Z is equal to the expected value of f of X given Z times the expected value of g of Y given Z and I should mention this is for all functions f and g. Okay, and in fact, this idea of conditioned independence, we're going to see later in the course, because it's used in the, well, the now infamous Gaussian copula model for pricing CDOs. So just to give you a brief idea of how it might be used in a bond context or a CDO context, let Di be the event that the ith bond in a portfolio defaults, okay? So we'll assume that there is a portfolio of n bonds. Okay. It's not reasonable to assume that the Di's are independent. You might ask, why is that? Well, if you think about it, there will be all sorts of macroeconomic factors or industry specific factors, which will cause defaults to actually be dependent. So for example, maybe some industry crashes that might cause not just one firm to default but multiple firms in that industry to default. And so, it doesn't make sense to assume that these events, these Di's are independent. But, we might be able to say that they're conditionally independent given some other random variable zed. Zed, for example, might reflect some industry factor. Some, some factor that governs how well a particular industry is doing. In that case, if we assume that the default events are conditionally independent given zed, then we can write the probability of D1 up to Dn given Z as being the product of these factors here, probability of D1 given Z up to probability of Dn given Z. And it's actually often easy to compute these quantities. So we'll actually be using this kind of idea later in the course, as I said, when we discuss the Gaussian copula model for pricing CDOs. We'll also see it in a couple of other applications as well. Okay, so very briefly, I also want to mention the mean vector and covariance matrix of a vector round the variables X. I hope we're all familiar with this already, but let's go through it anyway. So the mean vector of X is simply the vector of expected values, expected value of X1 up to expected value of Xn and the covariance matrix of x is. Well, this matrix of covariances. Okay, so, formula is expected value of X minus expected value of X times X minus expected value of X transposed. And just to be clear, this is an n by 1 vector, and this is a 1 by n vector, so the product is n by n. And we get an n by n covariance matrix, with the i, jth element of sigma being the covariance of Xi and Xj. The covariance matrix is symmetric that of course is because the covariance of Xi, Xj is equal to the covariance of Xj and Xi. And this diagonal element satisfies sigma i greater or equal to 0, and of course, the diagonal elements are just the variances. So this is equal to the variance of Xi and variances are always nonnegative. It is also positive semi-definite, so this is a, an important well-known property of a covariance matrix, in particular, it means that X transpose sigma X is greater than or equal to 0 for all vectors X and Rn. The correlation matrix row X is similar to the covariance matrix except it has as its i, jth element, the correlation Xi with Xj itself is symmetric, positive semi-definite, and has 1's along the diagonal. And just to remind ourselves, the correlation of Xi and Xj, is equal to the covariance of Xi and Xj, divided by, well, the square root of the variance of Xi times the variance of Xj. Okay. For any matrix A, which is a k by n matrix and a k by 1 vector A, we can take a linear combination of AX plus little a and we can compute the mean of this vector. So the mean is a times expected value of X plus little a and the covariance matrix of this new vector of random variables is a times the covariance of X times A transpose. And of course, five actually implies this result, which you're probably familiar with, that is the variance of aX plus bY equals a squared variance of X plus b squared variance of Y plus 2ab the covariance of X, Y. Note that if X and Y are independent, then the covariance of X, Y equals 0, but the converse is not true in general. And some people tend to forget this, but it is not in general true that if the covariance of two random variables equals zero, then those two random variables are Independent. That is not true.

### 045. The Multivariate Normal Distribution

>> We are now going to discuss the multivariate normal distribution. The multivariate normal distribution is a very important distribution in finance. It crops up in many different applications including, for example, mean variance analysis and asset allocation, as well as geometric Brownian motion and the Black-Scholes[UNKNOWN]. So we say an n-dimensional vector, X, is multivariate normal with mean vector Mu and covariance matrix Sigma; if the PDF of X is given to us by this quantity here. Okay, so the PDF is equal to 1 over 2 pi to the power of n over 2, times the terminant of the covarience matrix raised to the power of a half, times the exponential of this quantity up here. And be right that X is multivariate normal Mu, sigma. The little subscript n here, denotes the dimensionality of the vector x. The standard multivariate normal, has mean vector mu equal to 0, and variance covariance matrix equal to the n by n identity matrix. And in this case, the xi's are independent. We can actually see that, because in this case we can write, the joint PD f of x, as being equal to the product. I equals one to in. One over route to pie e to the minus a half x i squared. And that follows just from this line here because mu equals zero so this term disappears, and Sigma is just the identity. So, in fact, you just end up with a sum of xi squared divided by 2. So as we saw in an earlier module on multivariant distributions. If the joint PDF factorizes into a product of marginal PDF's, then the random variables are independent. Okay. The moment generating function of x is given to us by this quantity here. So phi subscript x of s is actually a function of s. Okay this vector s. And it's the expected value of e, to the s transpose x. Okay, and this is equal to e to the s, transpose mu, plus a half s transpose sigma s. Now, you're probably familiar with this in the 1 dimensional case, we'll just recover here. Suppose x is really just a scale of random variable, then the moment generating function of x is equal to the expected value of e to the sx, and it's equal to e to the s mu plus the half sigma squared s squared. And this is the case where x is normal with mean mu and variance sigma squared. So this is the moment generating function of the scalar. Normal random variable. This is, it's generalization to a multivariate normal random vector, x. Okay. So, we call our partition we saw in an earlier module. We can break x into two blocks of vectors x1 and x2 as such. We can extend this notation, notation naturally. So we can write Mu equals 1 2, and equals to This sigma 11, sigma 12, sigma 21, sigma 22 and they are the mean vector and covariance matrix of x1, x2. So we have the following results on the marginal conditional distributions of x. The marginal distribution of a multivariate normal random variable is itself normal. In particular the marginal. Distribution of Xi is multivariate normal with mean vector Ui and variance covariance matrix sigma Ii. So for example X1 is multivariate normal, in fact it's k components, mu 1, sigman 1, 1. And similarly X2 is multivariate normal. Mu 2, sigma 2, 2, and this is n minus k components. And we have here an example of the bi-variance normal density function, where the correlation beween x1 and x2 is 80%. If we rotate the service you can see the correlation of 80 percent the large values of X 1 are associated with values of x 2 like all values of x 1 are related to all values of x 2. So we can also talk about the conditional distribution assuming sigma is positive definite. The conditional distribution of the multivariate normal distribution is also multivariate normal. In particular x 2, given that x 1 equals little x 1 is multivariate normal with mean vector mu 2.1. In the variance, covariance matrix, sigma 2.1. Where mu 2 1, is given to us by this expression here, and sigma 2.1 is given to us by this expression here. And we can get some intuition for this result, by just imaging the following situation; so we've got X one down here. We have X two over here, and imagine we plot some points from X one and X two if you like, we generate X one and X two from some distribution, from the bivariate normal distribution, in particular. So the mean of X one is, let's say mew one and the mean of X two is mew two. Okay. Now what if I tell you that we observe that X 1 was equal to this little value X 1. Well if that's the case, then you can come up here and you'll see that X 2 is more likely than not to be in this region as. I'll circle them right here. So in fact you would expect the conventional mean x one equals little x one to be maybe somewhere around here . And this would be near 2.1 okay? Likewise you can see just from this. Again, that the variance of x2 would have shrunk. Because knowing something about x1 would give us information about x2, and that would decrease our uncertainty about the location of x2. And in fact this expression here tells us how to actually do that. This mathematically. So, so they're conditional distributions. A conditional distribution of a multivariate normal is again, multivariate normal. We also mention that the linear combination, ax plus a, of multivariate normal random variable x, is normally distributed with mean, a times the expected value of x plus little a, and covariance mix, matrix a times covariance of x times A transpose.

### 046. Introduction to Martingales

>> In this module we're going to introduce Martingales. Martingales play a very important role in finance. They won't play a hugely important role in this course, but they will crop up now and again and it's worthwhile understanding what they are and seeing one or two examples of Martingales. We're going to have the following definition of a Martingale, a random process, Xn is a martingale, with respect to the information filtration Fn and probability distribution P, if these two conditions are satisfied. The first condition is just a technical integrability condition which states that the expected value of the absolute value of Xn must be finite for all n. The really important condition, is condition two here, which states that the expected value of Xn plus m, given Fn, is equal to Xn for all nm greater than or equal to 0. A quick comment on what I mean by information filtration. So the information filtration, Fn, is just a complicated way of recognizing the information we have at time n. So Fn will denote all of the information in our model that we know at time n. So usually, you will actually, it'd be the case that Fn is equal to the information given to you by X1 up to Xn. So basically, it's just recognizing that at time n, we've already seen the values X1 up to Xn. Returning to condition two here, we see that what this is really saying, is that the expected value of X, at any time in the future, is equal to its current value today. And so, Martingales have often been used to, to model what are called fair games, they've got a rich history in gambling, for example. Because this condition here, models the idea of a fair game, so your future pay-off, or your expected future pay-off, is equal to your current wealth today, Xm. We define a sub martingale, by replacing condition two with a greater than or equal to sign, And we define a super martingale by replacing condition two with a less than or equal to sign. A martingale then is both a sub martingale and a super martingale. Here's our first example of a martingale. We can construct one from a random walk. Let Sn be equal to the sum of the Xi's from i equals 1 to N, where the Xi's are IID with mean mu, then we can set Mn equal to Sn minus n times mu, and in that case, Mn is a martingale. We can see this because of the following, the expected value of Mn plus n, conditional time n information, is equal to, what we have over here on the right-hand side. So recall, Mn plus n will be equal to Sn plus m, minus n, plus m times mu. So this here is Sn, and here's our m plus m times is mu. Well were taking this expectation conditional on time n information, so in that case, what we can do is, we can take out the first nxi's, because they're known to us as a time end, so we can take them outside the expectation. And what we're left is the expectation of time n, of the sum of the xi's from i equals n plus 1 up to n plus m. Well, the xi's are IID, so knowing the value of the first nxi's tells us nothing about these. We also know that they've got mean mu, so therefore the expected value of this sum here, is equal to m times mu. We also have the n plus m mu over here. Now when we simplify all of this, this m-mu will cancel with this m-mu, we're left with the sum of the xi's and i equals 1 minus n times mu, and of course, we see that this is equal to Mn. So in fact, we have shown that the expected value of m, subscript m plus n, conditional on time n information is equal to Mn, and so it's a Martingale. In this example, we're going to consider what we will call a Martingale betting strategy. Let x1 x2 and so on be IID random variables, where xi can take on two possible values, it can take on 1 or minus 1, in each case it takes on that value with probability 1/2. So you can imagine xi representing the result of a coin-flipping game, you win $1 if coin comes up heads, and you lose $1 if coin comes up tails, that assumes that you bet, $1 on the game. What we're going to do now is to consider a doubling strategy, where we keep doubling the bet until we eventually win, once we win, we stop and our initial bet is $1. So the first thing to note, is that the size of the bet on the nth play is 2 to the n minus 1, and that's because of the following, so on the first play, we bet $1 which is equal to 2 to the 0. On the second play we bet $2, because we're doubling our bet, and this is equal to 2 to the power of 1. On the third play of the game we would double our bet again, so we would bet 4, and that's equal to 2 squared, and so on. So we can see that every time you played the game, we've doubled our bet and so the play, the size of the bet on the nth play is 2 to the n minus 1. That of course assumes we're still playing at time n, because we will only be playing at time n if we haven't yet won the game up until this point. Let Wn denote the total winnings after m coin tosses, And assume we start off with W0 equals 0. What we're going to show, then, is that Wn is a Martingale. To see this, first note that Wn can only take on two possible values, it can only take on the value 1, or it will take on the value minus 2 to the n plus 1, and that is true for all n. Why is this the case? Well, consider the following two situations. The first situation is as follows, suppose we win for the first time on the nth bet. Well in that case, Wn is equal to minus this sum here. Where does this sum come from? Well, we've lost $1 on the first bet, $2 on the second bet, and so on, up to 2 to the n minus $2, on the n minus first bet. Then on the nth bet we win and we win 2 to the power of n minus 1. Remember 2 to the power of n minus 1 is the size of the bet on the nth game, so therefor these are our winnings at time n, if we win for the first time on the nth bet. If you actually compute this sum, just using the, the formula for summing a geometric series, remember it's a to the 1 minus r to the power of n, all over 1 minus r, that's the general formula. In this case, this translates to 1 times 1 minus 2 to the power of n minus 1 divided by 1 minus 2, and that is equal to 2 to the power of n minus 1 minus 1, which is what we have here. So W n, if we win for the first time on the nth bet, is equal to minus 2 to the n minus 1 minus 1, plus 2 to the n minus 1, this term cancels with this term and we're left With 1. Thereafter of course, we're always left with 1 because we stop playing the game as soon as we win. So the other situation that can arise, is that we have not yet won after n bets, in that case, the winnings, Wn is equal to minus 1 plus 2 and so on up to 2 to the n minus 1. It's 2 to the n minus 1 because we also lost the nth bet, so in fact this is a minus, this becomes a minus down here, and we get this quantity here, we sum it up and we get a sum of minus 2 to the n plus 1. So therefore these are the two possible values of Wn, 1 and minus 2 to the power of n plus 1. To show Wn as a martingale, we only need to show the following, that the expected value of Wn plus 1, given Wn, is equal to Wn. And this follows by an iterated expectations argument. And the reason is as follows, suppose we want to calculate the expected value of Wn plus 2 given Wn. Well in that case, we can write this as the following, the expected value of the expected value of Wn plus 2, given Wn plus 1, all given Wn. Now this term inside here, is equal to Wn plus 1 by this result here. So by star, with n equals m plus 1, so by evaluating star but not taking n equals m plus 1 we get that this inner expectation here equals Wn plus 1. So therefore, this is equal to the expected value of Wn plus 1, given wn and of course, this is equal to Wn again by star. So in fact, for any value of little n, we can show that this result holds, just using this iterated expectations argument we did here. So all we need to do to show that Wn is martingale, is to establish star, and that's what we'll do now. There are two cases to consider. The first case is where Wn equals 1. Recall, we have shown that Wn can only take on two values, the first value is 1. So if Wn equals 1, then actually we stop playing the game, because it means we've already won at some point, we've stopped playing the game and therefore, Wn is always equal to 1 in every period after we have first won. So in this case, the probability that Wn plus 1 equals 1, given Wn equals 1, is indeed equal to 1. Which means, the expected value of Wn plus 1, given Wn equals 1 well it must be equal to 1 because that's the only value it can take. It takes on this value 1 with probability 1, so the, this expected value equals 1, which is equal to Wn. The other situation that can occur, is that Wn equals minus 2 to the power of n plus 1. If that's the case, then we will bet 2 to the power of n, on the n plus first toss. So in that case, Wn plus 1 will be either 1, if we win the n plus first toss, or it will be minus 2 to the power of n plus 1 plus 1, and this follows from our arguments on the previous slides. Wn plus 1 will take on this value with probability a half and it'll take on this value with probability half, and that follows because it's a fair coin, we win with probability a half and we lose with probability half. So therefore, we have these two expressions here, from which it immediately follows that the expected value of Wn plus 1, given Wn equals minus 2 to the power of n plus 1, it is equal to 1, with prob-, with probability a half and is equal to minus 2 to the n plus 1, plus 1 of probability a half. If we sum these two together, we get minus 2 to the n plus 1, and that of course is equal to Wn. So in both possible cases, case 1 and case 2, we have shown that the expected value of Wn plus 1, given Wn, is equal to Wn. And so we have shown that Wn is a Matingale. Now let me mention this example is quite complicated, but it was worthwhile introducing because it is easy to generalize this example to the case where you allow random bets on each play of the game, as long as those bets only depend on what you've seen up to that point, you will actually still get a Martingale. For a final example, we look at something called Polya's Urn, we won't go through all the details, in fact, you can complete the details yourself. Considering urn, which contains red balls and green balls, so we've got some urns like this, there are red balls in there and there are green balls inside this urn. And at each time step a ball is chosen randomly from the urn, if the ball is red, then it's returned to the urn with an additional red ball. If the ball is green, then it is returned to the urn with an additional green ball. So what we're going to do is we're going to see that there are n plus 2 balls in the urn, at time n. And this follows, because we begin with two balls, and after every play of the game we add an additional ball, either an additional red ball, or an additional green ball. So we have n plus 2 balls in the urn, after time n. Let Xn denote the number of red balls in the urn after n draws. Then, if Xn is equal to k, Xn plus 1 can only take on two possible values, it will take on the value k plus 1, or the value k. It will take on the value k plus 1, if the ball withdraw on the nth plus 1 play is a red ball and that will occur with probability k over n plus 2, k because there are k balls-, k red balls in the urn and n plus 2 because n plus 2 is the total number of balls in the urn. Likewise Xn plus 1 would be equal to k given Xn equals k, if we draw a green ball, because if we draw a green ball we will not be adding an additional red ball. So Xn plus 1 equals k, given Xn equals k that occurs with probability n plus 2 minus k divided by n plus 2. And now, what we claim and what you can easily check, is that Mn, which is equal to Xn divided by n plus 2, is a Martingale.

## 024.III

### 047. Introduction to Brownian Motion

>> We're now going to introduce Brownian Motion. Brownian Motion is a very commonly used stercastic process in finance. It is the process that underlies the Black-Scholes methodology and we're going to discuss it now. So, let's define our Brownian Motion first. We say that a random process or stercastic process xt where t greater than or equal to 0 is a Brownian motion with parameters mu and sigma if, for the following fixed times: t1 less than t2 up to tn. The following increments: xt2 minus xt1, xt3 minus xt2, up to xtn minus xtn minus 1, if they are mutually independent. For s greater than 0, xt plus s minus xt, must have a normal distribution with mean mu-s, and variance sigma squared s. So notice mu and sigma are the parameters of the Brownian motion, and the increment, so this is an increment of length s, it's xt plus s minus xt, that increment must have mean, mu-s variance sigma squared s and be normally distributed. And the third condition that must be satisfied is that xt is a continuous function of t. In other word, if I was to plot and we'll see this in a moment, Brownian Motion, okay through time, in fact it's actually a lot more jagged than I've shown you here, but it actually never jump. So I can draw a path of Brownian Motion with my pen never leaving the page. And that's what I mean when I say xt is a continuous function of t. We say that xt is a b-mu sigma Brownian motion. Mu is the drift, okay and sigma is the volatility. Property number one, is often called the Independent Increments Property. So they're among the first people to introduce Brownian Motion from a mathematical viewpoint as we've defined here. Were Bachelier in 1900 and Einstein in 1905, it's interesting that Bachelier, very little is known about him, he was a French mathematician and in fact, it turns out he, he has had a great role to play in, in, in finance. He was trying to model stock prices on the Paris stock exchange way back in 1900 and he tried to introduce the idea of a Brownian motion to do that. So it's very interesting to see, that a concept as important as Brownian motion, which is used throughout the physical sciences and engineering was actually introduced by Bachelier in a financial context. Wiener, in the 1920s, was the first to show that it actually exists as a well defined mathematical entity. So Brownian motion, it's a hugely important stochastic process, and it plays a very big role in, in finance as well. Some other pieces of information when mu equals 0 and sigma equals 1, we have what's called a standard Brownian motion. We will use wt to denote a standard Brownian motion, and, we also assume that it begins at 0. So w0 is equal to 0. Note that if Xt is a b-mu sigma Brownian motion and X0 equals little x then we can write Xt equals little x plus mu-t plus sigma Wt, where Wt is our standard Brownian motion. We therefore see that Xt, is normally distributed with mean x plus mu-t and variance sigma squared plus t. Because of course, if Xt equals this, then the expected value of Xt is equal to the constants X plus mu-t plus sigma times the expected value of Wt. Wt is a standard Brownian motion, so has mean mu equals 0 times t, so this is equal to, X plus mu-t and the variance of Xt. Well the constants don't matter, they don't factor into the variance, so the variance of Xt is equal to sigma squared times the variance of Wt. And the variance of a standard Brownian motion has sigma equals 1, So it's equal to sigma squared times t, and that's where we get this calculation from here. So here's a sample path for Brownian motion. I've been simulating this Brownian motion by simulating these increments, which are normally distributed between t equals 0, and t equals 2 years. So this axis represents, a time period of 2 years and I've been simulating a Brownian motion. I've-, assuming it's-, I've been assuming it starts at a hundred, so I'm thinking maybe of a security price, although you wouldn't model a security price as a Brownian motion typically, but for the purposes of this demonstration you can think of doing so. So, that's one sample path, here's another one. We can see there's lots of different behavior, very jagged, In fact if I was to zoom in here, you would see that jaggedness still up here. Key thing to note is that these paths they're continuous, even though they're very jagged none of them jump, okay so again, I could draw one of these paths, and make sure that my pen never leaves the page. It doesn't suddenly jump from here down to here, okay? So Brownian motion is continuous, the paths of it are continuous. On this slide, I want to introduce an important fact about Brownian motion, but before I do so, let us review by what we mean by an information filtration. For any random process, we will us Ft to denote the information available at time t. And then Ft for all values of t greater than or equal to 0 is called the information filtration. And we actually discussed this in a previous module when we spoke and introduced, when we spoke about and introduced Martingales. This quantity here, this expectation, conditional on Ft, then denotes an expectation conditional on the time t information that's available to us. And usually, it would be very clear what that information is. So really, this, this information filtration ss just a mathematical way of describing what is intuitively obvious to us anyway. The important fact I want to introduce is the following. The independent increments property of Brownian motion implies that any function of Wt plus s, minus Wt is independent of Ft. In other words, knowing all of the information available at time level t, that tells us nothing about the increment Wt plus s minus Wt. So that in the predictor means that Wt plus s minus Wt is normal with mean 0 and variant, variance s, and that's in-, and that's even conditional on time Ft information. So let's do a calculation with Brownian Motion. We probably won't use this calculation during the course, but there's no problem in doing such a calculation, and it helps improve our intuition of what's going on with the Brownian Motion. So let's compute the expected value at time 0, conditional times 0, information of Wt plus s times Ws. Well we can use a version of the conditional expectation identity to obtain the following. So Wt plus s, I can rewrite this as Wt plus s minus Ws plus Ws. Okay, and then i'm multiplying by Ws outside, so that's this second Ws out here. I can multiply through this Ws through the-, this term here and break it down into two terms. I get Ws times this term, so that's what comes into the first term here, and then I get Ws times Ws is Ws squared, and that goes to that term, so this goes here. So now I've got two terms. Well the first thing is, let's deal with this guy first. I claim that the expected value of Ws squared is equal to s, how do I know that? Well I know that because of the following. I know, that s is equal to the variance of Ws, but the variance of Ws is of course equal to the expected value of Ws squared minus the expected value of Ws all to b squared. But the expected value of, Ws is equal to 0, because it's a standard Brownian Motion, so therefore the variance at w s is just the expected value of Ws squared, and that's equal to s as we've seen over here.So that handles this second term on the right hand side of 9. How about the first term? Well a version of the conditional expectation identity implies the following. So I want to compute the expected value of Wt plus s minus Ws times Ws, so what I'm going to do is first condition on time s information. So I can actually rewrite this expectation by conditioning first of all in time s information, I get dou-, Wt plus s minus Ws times Ws, conditional on time s information this Ws term can actually come outside this inner expectation, which is where it is over here. And I'm left with, inside the inner expectation with Wt plus s minus Ws. But that important fact over here. So let's call this star. That important fact tells me, that this guy is normal with mean 0 and variance, in this case t. So therefore, the expect-, and it's independent of Fs. So therefore, this quantity here, this inner expectation, has expected value 0, and that's where the 0 comes from, and so I get 0 here. And so, therefore what we've shown, is that the expected value of Wt plus s, times Ws, is equal to s.

### 048. Geometric Brownian Motion

>> In this module we're going to discuss Geometric Brownian Motion. Geometric Brownian motion is a very important Stochastic process, a random process that's used everywhere in finance. We have the following definition, we say that a random process, Xt, is a Geometric Brownian Motion if for all t, Xt is equal to e to the mu minus sigma squared over 2 times t plus sigma Wt, where Wt is the standard Brownian motion. So we've discussed Brownian Motion, in a separate module, so you can look at that module, if you'd like, to remind yourself what a Brownian Motion is. But one thing to keep in mind with the Brownian Motion, is that Wt, has got a normal distribution, with mean 0, and variance t, This is one of the properties of a Brownian Motion. Recall mu the drift, sigma the volatility, and write Xt till GBM mu sigma. An interesting observation to make is the following, let's take a look at this expression, but let's replace t with t plus s, if we do that, we'll see that Xt plus s equals X0, and in fact I should have had an X0 here. So Xt plus s equals X0, e to the mu, minus sigma squared over 2 times t plus s, plus sigma plus Wt plus s. And now what we can do, is we can rewrite this expression up here in the exponential. We can subtract a minus Wt, and add a Wt here, and we can break this summation up into t times this plus s times this. If we do that, we get this term here in the right hand side, but what's interesting is that this quantity here, is actually equal to Xt. So we can write Xt plus s equals Xt times the exponential of mu minus sigma squared over 2 times s plus sigma times Wt plus s, and this representation is very useful, it's in fact very useful for simulating security prices, when those security prices follow a Geometric Brownian Motion. This quantity here, Wt plus s minus Wt, well that's just a normal random variable with mean 0, and variance s. Moreover, it is actually independent of Xt and this follows from the independent increment property of Brownian motion that we discussed in that other module on Brownian motion. So that means for example, suppose that we wanted to generate values of a Geometric Brownian Motion at time 0 and at time t, bit also may be at these intermediate times may be delta, 2 delta, 3 delta, and so on. Well, what we can do, so we want to generate x delta, x2 delta, x3 delta, and so on. Well, what we can do is we can actually simulate the Geometric Brownian Motion at these time periods by just simulating, and zero delta random variables, that's very easy to do in standard software, you can even do it easily in Excel. So you could generate a sample path of your Geometric Brownian Motion or a sample path of your stock. You start at time zero with x zero which you know, and then you get x delta, using this formula here, with t equal to 0 and Wt plus s minus Wt, well that's just equal to a normal mean 0 variance delta random variable, so that would give you x delta. You could then get x2 delta by taking t equal to delta and s equal to delta, so you will get x delta plus delta is x2 delta, that's equal to x delta times this quantity again here. And again, to generate this term you could just generate a standard normal random variable, with mean zero and variance delta. So it's actually very useful simulating a Geometric Brownian Motion and we may return to this again, later in the course. Here's a question, suppose Xt is a Geometric Brownian Motion with parameters mu and sigma, what is the expected value of Xt plus s given little t? Well from equation 10 of the previous slide, we know that Xt plus s is equal to Xt times the exponential of this term here. Well, at time t, all of this is known to us, so we can take this outside the expectation, and we're left with this times the expected value of each of the sigma Wt plus s minus Wt. Well this term here, as I've already said, is normal with mean 0 and variance s, so all you're trying to do when you compute this expectation, is actually compute the moment generating function of a normal rounding variable. How many have seen that before? Suppose Zed is normal with mean a and variance b squared. Then it implies that the expected value of e to the s times Zed is equal to e to the a s plus a half, b squared times s squared, so this the moment generating function of a normal rounding variable. And we can just use the standard result up here, to recognize that this must be equal to e to the sigma squared over 2 times s. This term, cancels with this term, and we get this expectation equals e to the mu s times Xt, so that the expected growth rate of Xt, is in fact, mu. Here are some sample paths of Geometric Brownian Motion. The important thing to notice with these paths, is that they are continuous, they are very jagged. If I was to zoom in, I would still see that they are very jagged and they are continuous as I said, so they do not jump. I can draw any one of these paths, by keeping my pen on the page. The following properties of Geometric Brownian Motion, follow immediately from the definition of Brownian Motion. Recall that we saw the following, so we know that Xt plus s, is equal to Xt, e to the mu minus sigma squared, over 2 times s, plus sigma times Wt plus s minus Wt. Okay so what are these three properties? Well the first property states, that these ratios xt2 over xt1, xt3 over xt2 and so on, they're mutually independent. And that follows, because if I divide across here by Xt, I can see I've got the only random variable here is this increment, and the independent property, independent increments property of Brownian Motion will actually imply this first property here. The second property is, the property I mentioned on the previous slide that is that the paths of Xt our continuous as a function of t, they do not jump. The third property states, that the log of Xt plus s over Xt has got a normal distribution as follows, and that also follows from equation 10, which I've rewritten here. So I can easily see that the log of Xt plus s divided by Xt is equal to, well it's just this term up here in the exponent, it's equal to mu, minus sigma squared over 2 times s, plus sigma times Wt plus s, minus Wt. This guy is normal with mean 0 and variance s, and so this quantity is normal with mean mu minus sigma squared over 2s, and variance sigma squared s, which is exactly what we have here. A couple of observations about Geometric Brownian Motion. It is clear #1, that if Xt is greater than 0, than Xt plus s is always positive for any value of s greater than 0. And again, let's write out equation 10 here just to see this more clearly. It's, so this is our equation 10 from an earlier slide. We can see that if Xt is greater than 0, then of course the exponential of this would be greater than 0, and so then Xt plus s would be greater than 0. So if we are using a Geometric Brownian Motion to model stock prices, then we can see that the limited liability of a stock price, i.e., the fact that the stock price cannot go negative, is not violated. Another observation, is that the distribution of Xt plus s divided by Xt, only depends on s and not on Xt. In fact, this was clear, from the previous slide where we had this result here. The log of Xt plus s is a normal distribution, and this normal distribution does not depend on Xt, it only depends on s and the parameters mu and sigma. And this is nice, because we wouldn't expect returns to depend on Xt, so we can view this as being the return on a stock the return between times t and t plus s and we don't expect in general that this return should depend n the current value of the stock. So again, this is another nice property that Geometric Brownian Motion has, that is generally reflected in stock prices as well. So these two properties suggest that Geometric Brownian Motion might be a reasonable model for stock prices. And indeed, Geometric Brownian Motion is the underlying model for the famous Black-Scholes option formula that we will also see in this course.

## 025.IV

### 049. Review of Vectors

>> In this module we'll review vectors. I will go over definitions of vectors, what are row vectors, column vectors. We're going to define linear independence, bases, transposes, inner products, lengths of vectors or norms. All of these concepts are going to be needed for doing some of the elementary linear algebra that's needed in this course. What's a vector? It's just a collection of real numbers. You can collect them, and put them in a row or you can put them in a column. So here is an example of a row vector. Where I've put everything as a row here's an example of a column vector and if you notice carefully both of these vectors have n components. So we will call a vector to have n components if it consists of n real numbers. A row vector or column vector and we will denote any of these vectors by the symbol r to the n. R to the n means that every component is a real number and they, there are n of them in the place. To just fix ideas it might be easier to think in terms of R2 which means these are vectors with just two components and it's easiest to think of these vectors as belonging to a plane. And we're used to calling this plane by the x axis and the y axis. So think of x axis being one of the components of the vector. Y axis being another component of the vector. So, let me just give you some examples of vectors that we going to use later on in this module. So, here's one vector. It's x component or the first component is going to be one and the second component is say going to be equal to two. So that the vector will be this vector. At the end of the dot the dot corresponds to a y axis of two and x axis of one. So was labeled this as V. This will simply be the vector one two. The first component equal to one in the second component equal to two. Here's another example. The x axis, or the first component equal to 4 and y axis equal to 1. So that's that point, and I'm going to be connecting it with this vector. And in the rest of this module, I'm going to referring to this vector as w. It has 4 in the first component, and 1 in the second component. By default in this course unless otherwise specified we will assume that all vectors are column vectors, that is all the components have been arranged as a column. So we now know what a vector is, they are collections of real numbers without, by default it's going to be a column vector. Now we want to understand what can we represent using these vectors, what happens with them and so on So the first thing that we want to do is multiply these vectors with real numbers and add them up. So v1 and v2 are vectors. And I want to multiply them by a real number, alpha 1. And a real number, alpha 2. And then get a final vector w. So, to give you an example, here is my vector, v1. One, here is my vector V two. And just to fix ideas, each of these V one and V two actually lives in R to the three. Why R to the three? Every component is a real number, and there are three components. So the three refers to the fact that there are three components. I'm going to multiply them by two real numbers, so two is going to play the role of alpha one. 4 is going to play the role of alpha 2. And what do I do? I take these real numbers, multiply them component by component and add them up. So, in order to get the first component, I take the 2, multiply it to the 1, take the 4, multiply it to the 0. I get 2 times 1 plus 4 times 0 equals 2. That gives me the first component. If I want to go to the second component then I take the 2 and multiply it to the second component 1. Take the 4 multiply it to the second component which is also 1, 2 times 1 is 2, 4 times 1 is 4 add it up together you get 6. Want to go to the third component the same thing, 2 times 0. 4 times z, 1, 2 times 0 is 0. 4 times 1 i 4. You get a total component 4. So when you write a vector w as a combination of vectors v1 and v2, we're going to say that this Vector w is linearly dependent on v1 and v2. Why the linear? Because I'm multiplying by a real number, and adding them up. Other words are, w's a linear combination of v1 and v2. Get another word. W belongs to the linear span of v1 and v2. All of these 3 things mean the same. Linear dependency, linear combination, linear span. Now, we'll, in the next set of ideas, we'll need a concept of linear independence. When can we say that we cannot write a vector as a linear combination of other vectors. To fix ideas, let's again go back to r2, and I'm going to use my favorite two vectors, v and w. So here's my vector v and here's my vector w. For now we don't really need what the components are so I'm not going to bother with that. Now we want to understand what does a linear span mean, what can I, what kind of vectors can I generate by scaling the w? What can I do by multiplying w by areal number? And you can convince yourself very easily That all the vector that you can get, are going to be on that straight line. When you scale it up you get, by a positive number you get up the line if you multiply by a negative number you go down the line. Similarly all the vector that can be gotten as linear combinations of v rely on this straight line. Now we want to ask ourself can I represent v as A multiple of w. Clearly that's not true because I can't, I can't, when I scale the w I get points on this line, v doesn't belong to that line so I can't do anything about that. Similarly, w is not written as a linear combination of v and therefore we'll say that v and w are linearly independent. Let's throw in another vector now, x. It's again a vector in r 2 and I want to ask myself, is this linearly independent of v and w? Is it possible that x can not be written as a linear combination of v and w? Again it's very easy to convince yourself that if you just draw a line parallel to v, you can write, your vector x as a combination of vector that starts from the origin, it's aligned to the vector w and comes up to this point. So therefore, this vector is some alpha 1 times w. This vector here is, is parallel to the vector v. So I can write it at sum scale multiple alpha 2 times v. And because, now, x is the sum of this vector and that vector, you end up getting that x is actually equal to alpha 1 times w, plus alpha 2 times v which means that x is linearly dependent, LD just for short, linearly dependent on v and w. In fact we'll see in the next slide that in R2 if I give you any 2 linearly independent vectors you can write any other vector as a linear combination of these 2. And that set of vectors, say these two, v and w, would actually be called a basis. So that's the next concept that I want to learn about vectors. A basis is a linearly independent set of vectors that spans the entire space. Any basis for Rn, meaning a vector which has n components, has exactly n elements. So basis for Rn has exactly n elements. In the last page I showed you an example of R2, and this should have just two elements. V and W are linearly independent, there were two of them, and therefore I know, that this must be a basis. Now it will turn out that its much easier to think in terms of a standard basis. What's a standard basis is shown here. Its a collection of vectors such that they have only one in one of the components and all of the other components are equal to zero. So the vector E1 will have 1 in the first component, the vector E2 is going to have a 1 in the second component, and the vector En is going to have a 1 in the last, or the nth, component. Now if you give me any vector W which belongs to Rn meaning that it has n components, I can very easily write it as a linear combination of E1 through En. Why, because in each of these vectors is exactly one element that's not zero. So if I want to get the first element of w, right? I have to, say, take it to be w1 times e1, because everything else has zero contribution. If I want the second component, right, I have to take w2 times e2, nnd so on up to wn times en. And therefore, this basis. I can split any vector w as a linear combination very easily. And we will see that, in practice, these terms ought to be very convenient. Again, to put it in perspective. Here's r2. Here is my x asix. Here is my y axis. And when I showed you in the first slide, x axis refers to the first component. And y axis refers to the second component. So the vector e1 is just this one. It has one component one in the x direction and zero in the y direction. E2 is this one, it has a component one in the y direction and zero in every other direction and it's very easy if I take a vector x, all I have to do is drop it down here and This, this length down here on the x-axis is x1, on the y-axis is x2. And it's a very easy way to combine. But any other set of linearly independent vectors, two of them will make sure that this is going to be a basis. So, again, this was v, and this was w from the last page. And v and w is also a basis. This is also a basis. And E1, E2, which is are these 2 special ones, are also a basis. The second basis is special. And we'll just call it the standard basis, because it turns out it's very convienent to work in terms of this basis. Alright. So, so far what do we know? We know what are vectors. We know linear dependence, we know linear independence. We know that if I am a vector in Rn, meaning it has n components, I can find a basis of n linearly independent vectors, such that every vector can be written as a combination of these. So what's the next concept? The next concept that we want to learn, is that of a length of a vector. Vector. So let's start with the basics. And then we'll generalize is to what I want here. So, if I give you r2. And let's take a vector which has the x component equal to, let's say, 4. And the y component equal to, let's say. So this vector, has a representation four, three. Then our high school trigonometry tells us that the length of this vector is nothing but 4 squared plus 3 squared. So I'm taking the x-axis and squaring it. I'm taking the y-axis and squaring it. Square root. So that gives me 16. Plus 9 square root which gives me 25 square root equaled to 5. So that's nice. I have a, I have a definition of length. What does this definition of length satisfy? It satisfies several properties. It satisfies that the length of any vector is always great than equal to 0. If the length of a vector is equal to zero, then that vector itself must be zero. So you cannot have a vector which is not equal to zero who's length is equal to zero. And the intuition follows from this triangular expression as well. If I scale a vector by an amount alpha it doesn't matter whether I scale it positively or negatively. The length just gets scaled by the absolute value. So, here's the idea here's the value of vector v if I double it. >> I get this vector if I multiply it by minus 2 I get that vector, the length of this vector and the length of that vector is the same. The direction has changed, but the length remains the same. That's what this absolute value does. The third one here. Tells you the relationship between lengths of additional vectors and the original lengths, and this is known as a triangle inequality. The way you remember this geometrically is that if you've got one vector here, you've got another vector there, the sum of the vectors is this one, the length, this length is always going to be, let's call it l. Three is always going to be lessthan equal to L1 plus L2. This is the basic geometic fact L3 has to be less than equal to L1 plus L2. And this particular fact is encapsulated in this little >> Statement over here, and that's why it's also called the tirangle inequality. Now mathematicians have looked at this concept of length, this particular concept of length that I've been talking about which is take each of the components, square it, add it up, take the square root and now they're calling it the I2 norm. The 2 stands for the fact that I'm squaring it and take the square root and you'll notice that the properties that I want. The fact that the length is greater or equal to zero. The fact that triangle inequality holds. The fact that if I scale things remain the same is true for other definitions of length. Now, since I am taping this in New York, I'm going to try to tell you about a particular notion of language, which is called the L1 norm, otherwise known as the Manhattan distance. I'm sitting at a particular point here, I want to travel to another point, I can only go In blocks north and south or east and west, and I want to figure out how much do I need to walk in order to get from this point to that point. So I have to walk from this point to this point and then walk from that point to that point. So this distance is 4, that distance is 3, so the L1 distance, or the L1 length, or the Manhattan distance is 4 plus 37. The L two distance is five because I can sort of cut across. The L one distance is seven. L one also satisfies all the properties of a norm or a length and therefor it's sometimes convenient to encapsulate all of them as just norms and lengths. For the purposes of this course we will mostly be focusing on L two. But I just wanted you to know, that there are other definitions of length, that are interesting, and sometimes become important in applications. Alright, now we know vectors, we know linear combination, we know lengths. Now we want to go to the next concept, which is that of an angle. And in order to get to an angle, I have to introduce this idea of an inner product or a dot product. So the dot product of any two vectors v and w, so v and w are vectors in Rn. They have n components. So the dot product between v and w is simply going to be taking the ith component of v, taking the ith component of w, multiplying them together, and adding them up. For those of you who are experts in Excel, this is nothing but sum product, take the product of the components and add them up. The sum product function in excel is nothing but an inner product or dot product. If you review back, into the last slide we had defined the L 2 norm there to be every component's squared square root and that can now be written that length L 2 norm of the vector is simply take the vector v, take its dot product. So v, dot product with v, and take the square root. So now we want to understand an angle between these two vectors, so to do that, here's a picture. Here's my w, here's my v, here's an angle theta between them. So in order to understand how the inner product relates to the angle, the length of this vector is The length we, the length of this vector is w. So that inner product of v and w, simply is, take a, take the component of v along w and multiply to the length of w. So if you drop down an orthogonal point over here, this component. Is exactly equal to the norm, or the length, of v cosine of theta, and that I'm going to multiply with the length of w, and that should give me v dot w, which ends up giving me the cosine of theta Is exactly equal to vw divided by the norm of v, and the norm of w, or the length of v, and the length of w. And, to emphasize the fact that these are all 2 norms. I'm just going to put a 2 there. All of that is encapsulated in this slide. Cosine of theta is v.w divided by v and w. And this is true, not just in our 2, but in our n. You an define angles in rn. I'm going to show you in the next module that v dot w is actually a combination of two operations, the transpose operation and the matrix multiplication operation. But that has to wait until we get to the module of matrixes. So that pretty much brings us to the end of the introduction to vectors. This is all we need to do in terms of vectors, and this is all we're going to be using in the course. In the next prerequisite module, the next, the module that comes up next, we're going to review concepts about matrixing

## 026.V

### 050. Review of Matrices

>> In this module, we're going to review matrices. We'll define matrices, we're going to define operations such as transposes, inverses. We're going to talk about linear functions, and how they are related to matrices. We're going to define concepts such as rank, which will play a role later on in the course in defining complete markets, and hedging instruments. To start at the very basic, what is a matrix? A matrix is simply a rectangular array of real numbers, and we represent the matrix by the number of rows, and the number of columns. So I'll walk you through some examples. So this matrix a, has 2 rows, row 1, row 2. It has 3 columns, 1, 2, and 3, and therefore, we're going to call it a 2 by 3 matrix. 2 rows, 3 columns, 2 by 3 matrix. Its elements, I'm going to index by the row index and the column index. So if you have, if I'm talking about an in, an element called a 1 2. So the first index is going to be the row index. The second index is going to be the column index. So, it's going to be row 1 column 2. So that's the number that I am talking about. So, a 1 2 is equal to 3. Similarly, if I talked about another element a 2 3, so remember the first index refer to the row, so we're talking about the second row. The second index is going refer to the column. The third column, so that's this element down here, so a 2 3, is equal to 5. So every matrix is a rectangular array, we say a matrix is an m by n matrix, if it has m rows and n columns, so that's down here. So this is the general a that I'm talking about. This particular matrix has m rows. So if you look at a partic, elements over here, it goes from a 1, 1. And remember, the row index always comes first. So it's a, 1, 1, a, 2, 1, and so on, these dot, dot, dot means, and so on. A m 1, it has n columns so the column index comes second. It's a 1, 1, a 1 2, a 1 3, and so on, and a 1 n, and the last one is a m n. Here's another example; b, it has 1 row and 3 columns, that's a row vector. In the col, in the module and vectors, we noticed that there were two kinds of vectors, so column vectors and row vectors. Row vectors have row equal to 1, and a many number of columns. Column vectors have column equal to 1, and several rows. So here's an example of a column vector; w equals, 3, 4, 1. 3 rows, 1 column, so either, I can think of it either as a vector in r 3, or as a matrix in r 3 times 1. The second 1 says it's got 1 column and 3 rows. So the first thing that I want to do, is introduce an operation called transpose. Transpose really takes rows to columns and columns to rows. So, the easiest way to start thinking about it is to think in terms of column vectors and row vectors. I've got a column vector here, v. It's got 1 column and 3 rows, 1, 2, 3 rows. If I take it's transpose, if I put the operation transpose on this vector v, I'll go from column to row. So v transpose is simply this row vector. Now, we want to do the same thing, to matrices. I want to pretend that the matrix is nothing but a collection of columns. I'll take every column and flip it and make it into a row, and that's what transpose does. I have a column 2, 1 over here, I'm going to flip it, and make it a row, 2 1. Same thing that I did with the vector. I have 2 6 4, 2 6 4, 2 1, 2 1. I take the second column, and I flip it, I get the second row. I take the third column and I flip it, I get the third row. So columns go to rows and vice versa, rows go to columns. It's, it's symmetric in that sense. More generally, here's a matrix a which is r m times d. To remind, to remind you once more, m is the row index, d is the column index. So it has m rows and d columns. If I put the transpose operator, that's what this is doing, I'm going to take this column and transform it into a row, and that's what I'm going to do to everyone of them. So now, after the transposition is done, you end up getting that the number of columns becomes the number of rows, and number of rows becomes the number of columns. And so a matrix which is in r n times d, ends up being a matrix in r d times m. In the module on vectors, we had learned, that the inner product between 2 vectors, involves a transpose and a multiplication, so we figured out the transpose part. It's going to take a column vector into a row vector. Now we're going to try to see what happens, how do I multiply matrices? So the next concept is that of a matrix. So I've a matrix which is rm times d. So it's the, the row index is m, the column index, I'm going to put them in red just to make, emphasize the fact. The column index here is d, the row index for the matrix b that I'm going to multiply to it, must be the same as the column index of a. The inner multiplication dimension should be the same, otherwise it cannot multiply these matrices. And the column index of b could be anything, say p in this particular case. So when you multiply these matrices, you get a new matrix. So the inner index that was there this d index, it disappears, and the new matrix c that you end up getting, is going to be in m times p. So the m in the row index, becomes the row index here, and p which is the column index, becomes a column index there. So you end up getting a matrix which is in r m times p. The inner dimensions have to be the same in order the multiplication to happen. And when the multiplication happen, that disappears. There's a general formula for how to get the elements of c, but before going there, let me give you some examples, so that this idea becomes clearer. So I've got 2 matrices down here. I've got this matrix, which is in r, 2 times 3, 2 rows, 3 columns. This is a vector, but I'm going to treat it as a matrix, which is an r 3 times 1, 3 rows and 1 column. Now, if I apply the general rule that I just talked about, I should end up getting a matrix, which should be r 2 times 1, because I end up getting that the inner dimension which is the same for the multi, for the vec, matrix a and the matrix b. That will disappear and the outer dimensions are what are going to define the product. So this is the matrix c that I'm going to get, that's in r, 2 times 1, as I expected. So, how do I get the elements of this matrix c? What I do, is I take the rows, and multiply them to the corresponding columns. So in order to get c 1, 1, so I have, this is the row index, this is the column index. In order to get this element c 1, 1, I'm going to take the first row of a, and multiply it to the first column of b. I've got the first row, I've got the first column, and what does it mean to multiply a row and a column? I multiply them component by component add them up, sum product. So I take the 2, multiply to that 2. I take the 3, multiply to 6, take the 7, multiply to 4. And that's what I have written up here. 2 times 2, plus 3 times 6, plus 7 times 4. In order to make it clear what I'm trying to do here, the elements in the brackets correspond to the column, the elements outside the bracket corresponds to the row, and the first component ends up being 50. So let's look at c 2 1. Second row, first column, same story. So I've got the second row here, and that's going to multiply the same column, and I'll get elements 1 times 2, 1 times 2, 6 times 6, and 5 times 4. And, if you multiply, multiply all of that together you get 58, and that's how matrix multiplication works. So let's now go back and look at the more general case about matrix a, which is r m times d. I've got a matrix b which is r b times p, their inner dimension disappears. I get a matrix c, which is r m times p. If i'm looking at a particular element c i j, this is the row index, that's the column index. How do I get this element? I take the ith row of a and multiply it to the jth column of b. So the ith row of a, is a i 1, a i 2, the row index remains the same all the way through. Over here, I have b one j, b two j, up through b d j. So these last indices actually should be d not n. If you multiply them together using the rule that we just generated, I'm going to multiply this element with that element and component wise, and then add it up. We'll end up getting, this is the same as the sum over l going from 1 through d, a, i, l, b, l, d, which is exactly what we have done down here. So once we know how to multiply matrixes, I can start simplifying a lot of things. L 2 norm, remember, in the modular and vectors we talked about L 2 norm? We had said that L 2 norm is the sum of the components squared, square root. We'd also shown that this is nothing but a dot product square root. Now I'm going to show you a different interpretation for it. So I've got a vector 1 and minus 2. It's, L 2 norm is 1 squared plus minus 2 squared square root. I'm going to write that as 1 minus 2, that's a row vector times 1 minus 2, which is a column vector, and why do I do that? Because if I write out the expression for what this multiplication means, its the first component times the first component, second component times the second component, square root. So that's 1 squared, plus minus 2 squared, the same thing as down here. Now this row vector, I can also write it as, this vector, 1 minus 2, which is a column vector transpose, a transpose takes it to a row. Now we have the same vector, a vector 1 minus 2 transpose times itself square root, and that's what is written down here. The inner product between 2 vectors is nothing but take the first vector, take it's transpose, and multiply it to the second vector. This is a reminder, we had said in the, in the module for vectors, that if I don't specify it, every vector is a column vector. So, w is a column vector, v by itself is a column vector, I take it's transpose, I get a row vector, row vectors times a column vector always gives me a real number. And that's why the inner product turns out to be the real number. Alright. We know what our matrices now, the rectangular arrays of numbers. We know how to take its transpose, we know how to take its multiplication. Now we want to take the next step, and try to figure out what can matrices do, how are matrices and vectors connected to each other? And their connection turns out to be, coming from linear functions. So that's our next component of this module, linear functions. I'm going to call a function linear, if it has the following property. I take a vector x, and I take a vector y, I multiply this vector by a number alpha, and I multiply the vector y with the number beta, beta and alpha are real numbers. Back in the modular on vectors, we had talked about that alpha x plus beta y is another vector. All we do is making, multiply every component of x by alpha, every component of y by beta, and add them both component by component. So, now alpha x plus beta y is a new vector. I'm going to take the function at this new vector. If it so turns out that for any choice of x, any choice of y, any choice of alpha and beta, the function evaluated at this combination vector, is nothing but the same combination of evaluations of x and y. So, what's, what's important in terms of linearity, is that in one case I'm taking the liner combination inside the bracket, in the other case I'm taking the linear combination outside the bracket, and the 2 answers are the same, alpha x plus beta y. The function evaluated at this vector does nothing but the function evaluated at the vector x multiplied by alpha, plus the function evaluated at the vector y multiplies by beta. If this is true for all x, y, alpha, beta the function is linear. There is a simple theorem, we won't get into it, that a function is linear, if and only if, I can write that function as the multiplication of the vector by a matrix. So f of x is a linear function, if and only if, I can find some matrix a, such that f of x is nothing but a times x. It's just a multiplication by a matrix a, and that's why this is the next mod, next component to understanding what matrices can do. So, if I want to have a linear function from r 3 to r, I have to take vectors in r 3, and I have to get a number in r. So what should be a? So this multiplication, if a is going to be an r tie, m times d, and x is going to be an r d, a times x is going to be a vector in r to the m. Now, I want to map r 3, to r and therefore, the row index of a should be 1, and the column index should be exactly equal to d in effect, this should be a row vector. So here's a particular row vector 2 3 4, just as an example, if you look at the combination, if you look at the multiplication of 2 3 4 to the vector x1 X2, x3, you end up getting 2x 1, plus 3x 2, plus 4x 3. It takes vectors and maps it to real numbers. Take it one step further, here's another matrix a. Now this matrix has 2 rows and 3 columns, it's going to multiply a vector with 3 rows. And you'll end up getting another vector which has 2 components. Why 2? Because the row index is 2. So again, component by component multiplication. 2 times x1, plus 3 times x2, plus 4 times x3, that gives you the first component. 1 times x1, 0 times x2, 2 times x3, that gives you the second component, and that's what linear functions are. Linear functions take vectors, multiply them by a matrix, and give another vector. So, in most of this course, we won't really be interested in just functions, we'll be interested in constraints, we'll be interested in sets of vectors that are defined by functions. These might be portfolios, these might be values of options, these might be other kinds of things that are, random variables and so on. So we're going to talk about 2 different kinds of constraints, a linear equality. It would mean all those vectors x, such that they satisfy some linear equality. This is a linear function, it's equal to some given vector b. We'll all talk about linear inequalities, which means that all vectors x, such that ax is less than, equal to b. When I mean less than here, I mean component by component. So I'm going to say a vector 2, 3, is less than equal to a vector 4, 5, because component by component, 2 is less than 4, 3 is less than 5. But the same vector 2, 3, is not less than equal to the vector 4 1. Why? Because the first component is less than 4, but the second component is not. So therefore, this vector is not less than 4 1, but this vector 2 3, is less than 4 5. So if I say a vector a x, meaning the vector obtained by multiplying, a to x, is less than or equal to b. I mean that by component by component that vector should be less than b. Why did I only show you 1 inequality? Because, if you had an inequality, which is going the other way, ax greater than equal to b, that's nothing but minus a x, less than or equal to minus b. So, without loss of generality, I can just look at 1 side of the inequality, it turns out that it becomes easier to keep track of various things, if I just look at 1 side of the inequalities. Alright. I've got linear functions, I've got the notion of linear constraints. Now the next concept that I want to know about matrices, is what can linear functions do? How complicated can a set can linear function generate? And, that's going to be important when we start talking about spans of matrices, and how we can think in terms of what these spans do. So the next concept that we're going to learn is that of a rank of a matrix. There are 2 notions, I call them rank of a matrix, and a row rank of a matrix. Let's look through the examples, and we'll come back and look at more general ideas. And another related concept to rank, is the range of a matrix, and we'll, we'll try to make all of this clearer by looking at an example. So, down here is an example, I've got a matrix a, which is a 2 by 3 matrix, 2 rows, 3 columns. We know that this matrix induces a linear function, and what that linear function does is it takes a vector x which is in r3, so x is in r3, meaning it has three components. If you multiply this vector by the matrix a, you end up getting a vector ax, which is in r2. So, it maps 3 dimensional vectors into 2 dimensional vectors. This concept is important when we talk about ranges. But before we get there, let's start talking about a column rank. Column rank, I want to look at the rank, columns of this matrix, and ask myself, how many linear independent columns are there. How many columns can I take and write, and still leave them linearly independent? So I know for a fact, that because the columns are 2 dimensional, meaning that each column is an r 2, I can at most get 2 vectors. Back in the module, for vectors, we had talked about linear independent, and we said that in r 2, 2 vectors can be linearly independent, and the third vector will become linearly independent. So at most, I can get 2 columns that are linearly independent, but it turns out, that for this particular matrix, only 1 column is linear independent. Why? Because if I take the first column, 1 2, I can get the second column simply by multiplying the first column by 2. I can get the third column by simply multiplying the first column by 3. So the second and the third column are not linearly independent of the first column. So the column rank, which is the number of linearly independent columns, is 1, because I can only get 1 column. Now let's do the same thing for the rows, and we end up getting a concept of a row rank. So, here's my row 1, now it turns out, that if I take that row and multiply it by 2, I get the second row. So the row rank is also equal to 1. That's not a coincidence, there is a theorem which says that their row rank and the column rank are equal always for any matrix. So it turns out for this matrix the row rank is equal to 1, the column rank is equal to 1 and the rank itself is just equal to 1. So, next let's look at this notion of range. So, what we want to do, is we want to understand what does this matrix a do to the vectors in r3. So, now I want to think of this matrix not really as a matrix, but as a function since taking vectors in r3 and mapping them into vectors in r2. What kind of vectors I can get? What is the largest set of vectors that I can generate by this transformation? So, it, I'm going to multiply them by different components, so the vector ax is going to be equal to x1 plus 2 times x2 plus 3 times x3. The second component is going to be equal to 2 times x1, plus 4 times x 2, plus 6 times x3. That is what this vector a x 3 is going to be. So, x1 plus 2, times, x2 plus 3, times, x3 times 1, gives me the first component, x1 plus 2, times x2 plus 3, times, x3 times 2, gives me the second component. So every vector that I can generate by multiplying by the vector x, is of the form some real number, let's just call it lambda, times the vector 1 2, and that's exactly what is written down here. The range of a, the set of all vectors that I can generate by multiplying to the right hand side of a, by sum vector x, is all the vectors of the form lambda times 1 2. What does that mean? Now, going back to the notion r2 is this plane, one chooses the second component is equal to 2, the first component is equal to 1, that's this vector 1 2. In, in the r2 plane, all the, all the vectors that are possible, are represented by this r2 plane. But this matrix a, can only generate vectors on the straight line, nothing else can be generated by multiplying it by the vector x, and this is exactly what it means to have a rank 1. Rank 1, means that although the vector is sitting in r2, meaning that it has 2 components, really it's a one dimensional thing, that's what this 1 dimensional line tells me. On the other hand if this matrix a had rank 2, then that would tell me, that I should be able to generate everything in r2. Because it would, it would mean that there are two independent vectors that I could generate, and I know that in r2, using 2 independent vectors, I can generate anything, and so on. In the in this course, we will never get down to the details of how do I compute the rank, and so on. We'll work mostly with the, sort of the idea of what a rank is. And the idea that I want you to keep in mind is, the rank tells you the rich. Higher rank means that you can get a lot more things out of this linear function, lower rank means that you get less out of this linear function. In the next module, we're going to start talking about hedging, and bringing an optimization problem. And, there we'll notice that the rank, of the matrix will tell me how many different payoffs can I, can hedge. Before we finish this module on matrices, there's 1 last concept, and that's of inverse. If I've got a matrix a, which is a square matrix n by n, both the row column, row index, and the column index is the same. And the rank of the matrix is n, meaning that all the columns are linearly independent, all the rows are linearly independent, then, this matrix is invertible. What does that mean? It means that there exists a matrix a inverse, such that a inverse times a, is the same as, a times a inverse, and which is the same as identity. So this i, remember, was identity.

## 027.VI

### 051. Review of Linear Optimization

>> . In this module, we will be walking through a review of linear optimization using a hedging example. We are going to see how there are two kinds of optimization problems, something called a primal optimization problem, something called a dual optimization problem, how they are related. And we also introduced the idea of La Grangian relaxation. Here's the hedging problem that we are interested in. I've got d assets. So take d, just to fix ideas, take d to be 3 or 4. But some number of assets that are there in the market. The price of these assets at time 0 is r to the d. It's some price vector, which has d components, where every component tells me the price of that particular asset. At time t equal to 1, the market outcomes are uncertain. I don't know what, which state the market is going to be, it's going to be in one of m possible states. So here's the situation at time T equal to zero, and I'm in state zero, And I could go to one of n different possible states. Go from one, two, all the way to, down to m. What do I mean by a state? For my purposes, state is simply telling me what are the different prices that can happen. So I'm going to characterize every state by the prices of the asset in that particular state And I can do it in 2 different ways. I could either tell you, what is the price of all the assets in any given state, Or I can tell you the price of a given in all possible states and we'll flip between these two ideas as we go through. We'll use the power of matrices to see what it means, sometimes, it's easier to represent it one way, Sometimes it's easier to represent it the other way. And understanding it both ways gives us an insight of which one is more beneficial for the particular application that I'm looking for. So, to motivate that, I'm going to define something called Sj. So S sub j, will be a column vector, and it will tell me the price of asset j in all possible states, So it's s1j, s2j all the way down to smj. J is fixed, it's asset j and the number of states would ran-, go from 1 to m. Now how do I represent all the assets in the market? I'm just going to take these column and stack them. S1 would refer to the column corresponding to S, asset one S2, asset two and so one up to S D. If I write them out in gory detail, you end up getting this matrix. The matrix has M rows, because it's got M states, its got D columns because its got D assets. And what going on here, every row here, tells you the price of all the assets in a particular state. So what I've circled here, are the prices in state 1, S1d, 12S, 11S, 12, all the way up to S1D. Genetically, somewhere it's going to be Sm1, Sm2 , all to Smd. So every row tells me what happens to all the assets in a given state, every column tells me what happens to a particular asset in all the different states. Alright, so that's how I'm going to describe my market. At times 0 I know the price, at time 1, which is the place where the market opens again, I don't know the price, it's uncertain, it's going to be one of n possible states, but I know that if the state is given to me, what the prices are. Now you might think that this is a very simple representation of the market, and indeed it is. But it turns out, that even in the most modern methods, of risk management, like value at risk, and conditional value at risk, people represent what happens to the market By a model which looks very much like this. Except instead of talking about states, we'll talk about simulations. I'm going to simulate returns and I'm going to say, depending on all of these different scenarios, what happens? But essentially the, the main ideas are going to be captured by this simple toy model. Alright, I know what happens to the asset. Now, what I want to do with these assets is to hedge an obligation. I'm going to walk through what does hedging mean. So, I have an obligation. What is an obligation? It's a vector x in rm. Why m? Because the obligation depends on the state. In a good state I might had to pay more, in a bad state I might had to pay less. So depending upon which state occurs, I'm going to pay an obligation xi, if this state i occurs. And what I want to do, is I want to buy a portfolio now, I want to buy a certain number of shares of the assets right now, in order to have enough money to pay my obligation. So, I'm going to choose a portfolio theta. Theta-1 through theta-d are going to be the number of shares that I'm going to purchase of each of these assets. I'm going to allow for the possibility of short selling, so thetas could be negative, or I'll buy them long, which is, when thetas are positive. And I want to do, I want to choose this portfolio, so I can hedge the obligation that, That I'm interested in hedging. So I'll step you through what it means and what, what hedging will ensue and then we'll go to what is the linear optimization problem that we end up getting. Okay! So at time 0, I'm going to put, buy a position theta at rd. Why d? Because it's got d different assets. So theta J's the number of shares of assets J that I purchased, where J goes from 1 through d. What's the cost of this purchase? The cost of the position theta, is simply the price of every asset times the number of shares that I produce. A lot of those assets! So it's pj times theta j, sum from j equal to 1 through d. It's the inner product of the vector p, with the vector theta. And we know that inner products are nothing but p transpose times theta. What happens at time t equal to 1? So, if a state i occurs, then I'm going to liquidate my position. And when I liquidate positions, I'm going to sell the assets. And what's going to happen? In state i, the price of asset j is s, i, j, I hold theta j positi-, shares of this asset, so by selling asset j I get Sij times theta j But I'm going to liquidate the entire portfolio. So j I'm going to sum from 1 equal to d and that's the amount of money, that's the pay-off that I'm going to get in the stake. Its just Sij time theta j sum from j equal to 1 through d, That gives me yi. And if you just think about it for a moment, if I stock up all the pay-offs as a vector. If I call a vector y to be y1, y2, all the way up to y m, the pay-offs in the m states This is nothing but the matrix S, Times the vector theta. Just to remind you, this is my matrix S, it has prices for every state as rows. So the payoff in the first state would be this row times the vector. And the second state would be this row times the vector. And that's exactly what is being done here. Sij, as j goes from 1 through D, is a row. You take the i'th row, multiply it by the vector, you get the payoff in the i'th state. And therefore, the vector y is simply the matrix, times theta. Now I want to look at this, in a different way. I want to think of this, as not multiplying row, row by row but column by column. So, instead of looking at this matrix S, as row by row as we have done so far, I'm going to put them in columns. I've got the column for the first asset, column for the second asset, column for the d asset and, that's going to multiply theta-1 theta-2 up to theta-d. And you can see that this multiplication is nothing but, this row, times this column, so you'll get theta j times Sj. J is summed from 1 through, that should not be an n, but a d. It goes from j equals 1, through d. Interpreting it this way, you end up getting a different interpretation of what is going on. Now, the pay-offs ys are nothing but linear combinations of the columns. So vector y, will, I can represent, I can generate a particular pay-off, if it's in the range of the matrix S. Remember in the concept, we had introduced this concept in the model of matrices, that a vector y, belongs to the range, of s, if these are all vectors s-theta, where theta is in, r to the d. And therefore, y belongs to the range of S. And remember, we had also introduced the notion of rank. We had said, that rank tells me how rich that space is. Can I, how many different vectors can I generate in the range? So if the rank of the matrix S is n, is equal to m, meaning all possible pay-offs can be generated, then I can hedge everything. If on the other hand, the rank of the matrix s, is less than m, that means there are certain pay-offs. There are certain pay-off vectors that can not be generated because they can not be produced as if I'm make, taking the matrix S and multiplying it to theta. So that's the concept that's going to play a role in the course.We're going to talk about complete markets and incomplete markets, and that has to do with the rank of this matrix. Before we get there, here's a simpler notion. We'll say that a pay-off y hedges x, if y is greater than or equal to x. Component by component, the pay-off that I've generated using my portfolio is greater than the pay-off that I need to hedge or give-, the payoff that I need to give at time 1. Alright, now comes our first optimization problem. What's the optimization problem? I want to minimize the price of the portfolio such that it hedges my obligation. I want to minimize p transpose theta, such that s-theta is greater or equal to x. And, what are some features about this optimization problem? The objective! What I'm trying to maximize or minimize is a linear function, linear function of theta. The constraints! Constraints, and what thetas that I can choose, are again linear constraints, as theta must be greater than or equal to x. Linear or inequality. So any optimization problem, which has a linear objective function, either minimization or maximization it doesn't matter, and all the constraints are either linear inequalities, as is the case here, or linear equalities. We will call that problem, a linear optimization problem, or a linear program. It turns out that linear programs are very rich, there's a rich theory about them, and you can do a lot of interesting things with them. You can model lots of problems, you can solve them very efficiently, you can get a lot of interpretation out of them. So the one thing that we're going to focus on in linear optimization, and the interpretation of linear optimization is the notion of duality. And what do I mean by the notion of duality? For every linear program, I can write another linear program which is intimately connected to it, and this connection is called duality. So I've got a linear program here minimize x, c transpose x, Ax greater than or equal to b. Here's another linear program. Maximize B transpose U, A transpose U equal to C and U is greater than or equal to 0. Min goes to max. Now, for the purposes of this course, you will not be responsible for how I generated the dual linear program from the primal linear program, or the second linear program from the first linear program, we will give you that in the course. The only thing that you're going to be responsible for is, to understand the relationship, and we'll emphasize this again during the course. They're here from-, some of the interesting resolve that comes from this duality concept. The first thing is something called weak duality. What it says is that this minimization problem. So the way I, the picture that I have, I wanted to keep in mind is that here's my value P. For all feasible values, for all xs, such that Ax is greater than or equal to wha-, b, I get some numbers on this side. Why do I get greater? Because I'm trying to minimize. So I get the lowest possible number is p. I've got another number d. Which is the value of this second linear program down here. For all Us that are feasible, meaning that satisfies A transpose U equal to C, and U is greater than or equal to 0, I'll get values that are less than this D. Why? Because this is a maximization problem. The largest possible thing that I can get is B transpose U, is going to be equal to D. The first theorem says, that in fact, this picture that I'm drawing is correct. That P is going to be greater than D. There's no reason for it to be that way, they could have crossed. But the nice thing is, if you construct the dual linear program correctly, and in the next slide I'm going to show you a simple example. Again let me emphasize you're not responsible for knowing it. Just walking through the exercise, and understanding how I'm going to use the duality. So the primal and the dual are intimately connected; the optimum value of the primal P is greater than equal to the optimum value of the dual D. And because this is true, you end up getting a chain of inequalities that are very good. We know that c transpose x is greater than equal to p. Why? Because I''m trying to minimize c transpose x, so for any feasible x, anything that satisfies the inequality Ax greater than equal to b, I'll get a value greater that b. The second piece is also true, D is greater than equal to b, transpose u because I'm trying to maximize b transpose u. And the inner part comes because of the v duality. So now this gives you a very interesting way, if I can find an x, and I can find a u, such that c transpose x is close to b transpose u, then I know that the x must be very close to optimal, And u must also be very close to optimal for the dual. Why? Because P is greater than, equal to D, if these two at, points are very close, it must, it must be that P is also very close to c transpose x, which means that it's optimum. Similarly, b transpose u must be close to D, which means that is optimum. You end up, you can go one step further, and say that when either P, or D, is finite, either the primal value is finite, or the dual value is finite, then in fact, they must be equal. And finally, the reason why we call them dual, is because if you go from the primal to the dual, and from, you take the dual of the dual, you get back the primal, and that's why they're called dual linear programs. Going a little bit further. Here's another pair of primal dual linear programs that we'll be, that we'll be using in the course. Minimize over x, c transpose x, Ax equals b, they, it's equal to maximize u, b transpose u, A transpose u equal to c. And this equality, I'm putting it there to emphasize the fact that there is strong duality between them. But to keep in mind that this equality holds only if you can show that either this one, p or this one, b is finite. So if p, or d is less than, is less than, is not equal to let's say, plus infinity or minus infinity, in that case these two values are the same, and in that sense they are equal. So, the last piece in this module, we're going to walk through and tell you how to construct a duel, it's a very general concept called La Grangian relaxation. And we'll use that in the next module on non linear programming, as well. So here's the problem. The primal problem is, minimize c transpose x, Ax, greater than or equal to b. Now I'm going to take a vector u, which is greater than or equal to zero. And so u is component wise greater then or equal to 0, and remember Ax is going to be greater than equal to b. So Ax minus b is component wise greater than equal to 0, you take some vector which is component wise greater than equal to the oh, multiplied to another vector that is component wise greater than equal to 0, you end up getting a number, which is greater than or equal to 0. So I'm subtracting it, so I'm getting a number, which is less than c transpose x. So this linear program, which has a changed objective function involving this vector u, is going to have a value, which is going to be less than equal to P. B transpose U does not involve the decision x, it does not involve the minimization, the minimization is going on over x, it does not involve x, so I pull that out. I end up getting a new problem, which is minimize c minus a transpose u times x. And what happened to this constraint? I threw it away! Why did I throw it away? It's complicated. I don't know how to deal with constraints, so I threw it away. But I'm guaranteed that if I throw away these constraints my set over which I can optimize, the xs over that I can chose become larger, and therefore this minimum only becomes smaller. So I end up getting that this quantity, is going to be smaller than the previous line. Now, because I don't have any constraints, I have a very simple problem. I've got some vector, let's call this vector d. I've got d transpose x. So I want to minimize d transpose x. So here's my d vector. I want to minimize this, d transpose x, and I can choose my x to be anything. So what am I going to do? I'm going to choose my x to be in the negative direction and going off to infinity. Here's my b, here's my x! If I multiply d and x together I get a very large negative number. So if I have vector d which is not equal to 0, I can make this optimization problem equal to minus infinity and that's what this says. If d is not equal to 0 and, just to emphasize d's equal to c minus A transpose u, if this is not equal to 0 you get to minus infinity. If in fact, d is equal to 0, which means that c is equal to A transpose u, then I can't do anything over here. This vector is equal to 0, I multiply to any other vector, I'll get a 0. So you end up getting that this minimization problem has a value equal to 0. And p is greater then equal to b transpose u. Now u is arbitrary, the only thing that I needed to do was, which is missed over here, is that I needed to have that u must be greater than equal to zero. So now, you have p must be greater than equal to maximize b transpose u, which is the value here, provided A transpose u is equal to c and u is greater than equal to 0. That immediately gives you a weak duality, a little bit more work gives you a strong duality. So here's the connection. Max-, minimize C transpose x, Ax greater than or equal to B is equal to maximize B transpose U, A transpose U equal to C, and U greater than equal to 0. That's what we derived over here. What we did, we dualize constraints, and this word will show up some times during the course. Dualize means I take the constraints and multiply them by a variable which has a particular sign. We had a constraint Ax minus b, I multiplied by a vector of u which is greater than equal to 0, that's dualization and then I'd relax the constraint. I have this constraint Ax greater than equal to b, I didn't like it, it was too complicated, I threw it away. I'd relaxed them! And by doing dualization and relaxation, you end up getting something called a La Grangian relaxation, which gives you duals, And gives you some very nice properties that we'll explore more in the course. .

### 052. Review of Nonlinear Optimization

>> In this module, we are going to talk about nonlinear optimization. We will review unconstrained optimization, and then briefly talk about constrained optimization and in particular, Lagrangian relaxation and its two applications. One on some utility maximization problem and another one on a mean-variance portfolio selection problem. Let's start with unconstrained nonlinear optimization. What does unconstrained mean? It means that I'm allowed to choose any vector that I like to try to minimize a function. To keep everything general, we will assume that I've got a function f of x, and what is x? X is a vector, in Rn. It's a vector with n different components. It's a unconstrained problem so I can minimize my f of x, the function, over the entire space. It turns out that for non-linear optimization, we have to differentiate between two kinds of minimum problems. Ordinarily, we just want to find a vector x which takes the minimum possible value. So, here's a picture. I've got a one-dimensional function. Here's my x, here's my function f of x. Now, when I'm trying to minimize this function f of x, all I need is this point. This is my point x star the minimum. It's the global minimum. It's the best point that I want in the entire real line. But as we'll go through this lecture, note, we will see that, when it comes down to nonlinear programming, we try to find these points by looking at derivatives. By taking first derivative, which will give me the gradient, or the second derivative, which will give me the Hessian matrix. Derivatives, unfortunately, can look only in the neighborhood of a point. They can't go look far away, because derivatives are defined by taking limits of points coming arbitrarily close. So, in order to be able to work with derivatives, we have to have another notion, which is that of a local minimum. So, this point here is a local minimum. Why is it a local minimum? Because if I just go in a neighborhood of this point, if I look for points that live in this little interval around here, then for this little local neighborhood, this point is actually optimum. It is true that if I leave neighborhood I get other points that are better, x star over here is a global optimum point. And therefore, that's better than this local optimum point or at least as good as the local optimum point. But within this interval, I can't get any other point. So, for nonlinear optimization, we have this notion, two different notion. Global optimum point, that's where we want to get to. Local optimum point, which are locally optimum, that's what we can get because we use derivatives. So now, we are going to describe what are the conditions that we need in order to get a local minimum. Remember, local means only in the neighborhood. It means that these criteria are given by taking derivatives. A point is a local minimum if the gradient at that point is going to be 0, meaning that, what's a gradient? It's a vector, remember this function? Is a function from Rn, meaning that it's got a vector x, which has n components. Therefore, the gradient is simply the partial derivatives. I take the function, I take the partial derivative with respect to the first component, the partial derivative with respect to the second component, partial derivative with respect to the nth component and stack it up as a vector. When I say that gradient is equal to 0, I mean that every component is equal to 0. Here's a simple example. Let's take F of x is equal to 2x squared x1 squared plus 3x2. So, the partial of f with respect to the first component, is going to be 4x1. The partial of f with respect to the second component is going to be equal to 3, because the x2 goes away. So, the gradient is going to be 4x1 and 3. So, when is it equal to 0? That means, that x1 must be equal to 0. So, for any local minimum, it must be the case that x1 is equal to 0. But that's not sufficient. We have to take a matrix of second derivatives, and that matrix must be positive, semi-definite at any local minimum, and positive definite, if you want to be sure, that, that point is a local minimum. How do I construct this matrix? I take the partial derivatives and stack them up as a matrix. First component, remember, for any matrix, this is going to be the one, one component. So, I take the partial derivative with respect to x1 and take another partial derivative with respect to x1. This point here is 1, 2, so I take the partial derivative with respect to x1 and then a partial derivative with the respect to x2. Just a, just to recall that if a function is twice differentiable, meaning you can take two derivatives then it doesn't matter the order in which you take the derivative. Whether you first take it with respect to x1 and then you take it with respect to x2 or vice versa. And we'll see an example in a moment. You stack them up on the matrix, that matrix must have all non-negative eigenvalues. We won't get into the detail of eigenvalues because we don't really explicitly need it. They can be easily computed in MATLAB. You can just give a command called eig, it will tell you the eigenvalues of the matrix. If all the Eigenvalues are non-negative, then it'll turn out that it's a local minimum. If it turns out that all the eigenvalues are strictly positive, then it's definitely a local minimum. Now, functions that are going to be useful are called convex functions and when we use these functions, we are going to remind you in the course. But the picture that I have, I want you to keep in mind is the function is convex if it looks like this. I take any two point and I draw the straight line joining those two points and the function. The straight line lies above the function. So, this is a convex function. Here's a function that is not a convex function because if I take these two points and join them, that's not lying above the function. So, convex functions are particularly nice if I'm trying to minimize a convex function that I don't even have to check the Hessian. I just get the gradient, set it equal to 0 and I'm done. We'll walk you through to two examples of what is going on here. So, first example is unconstrained nonlinear optimization. Here's the problem that I want to solve. I want to minimize over x in our two, two components, this function. X1 squared plus 3x1 x2 plus x2 cubed. I first take the derivative and set it equal to 0. I get 2x1 plus 3x2 as the partial derivative with respect to x1. I get 3x1 plus 3x squared as the partial derivative with respect to x2. I set it equal to zero, and I solve it. The first equation tells me how x1 and x2 are related. I plug that into the second equation. That gives me a quadratic, which has two roots. It turns out that the two roots are x equal to 0 or x equal to minus 9 over 4, and 3 over 2. So, the first component is minus 9 over 4. The second component is 3 over 2. If I take the partial derivative, the second partial derivative, I take this one and take its partial derivative with respect to x1, I get 2. I take the same and I take the partial derivative with respect to x2, I get 3. For this one, if I take the partial derivative with respect to x1, I get 3 but I should have known that already because it doesn't matter the order in which I take derivatives. So, the off diagonal-terms are always the same. If I take this,[UNKNOWN] take the second derivative with respect to x2, I get 3 times 2, 6x2. If I plug x equals to 0, which means x2 is equal to 0, I get this matrix. That's not positive definite, so it's not a local minimum. It has actually one positive eigenvalue and one negative eigenvalue. If I put x equal to minus 9 over 4, 3 over 2, it turns out that this matrix is positive semi-definite, meaning it has non-negative eigenvalues and, in fact, it's positive definite, meaning that it has all positive eigenvalues, and therefore, I know that this is a local minimum. That's all that we need to know as far as this course goes about unconstrained nonlinear optimization. Take the gradients that are equal to 0, figure out what's happened to the Hessian, or the second-order matrix. Next, we want to take this idea and apply to constraint problems. So, here's a constraint problem. A typical problem like this will show up in a utility maximization problem. I have two different things that I could do. I could either invest in 1s, one particular business or another particular business and I have a total wealth of 12. So, x1 plus x2 equals 12. If I put money into the first business, I get 2 times log 1 plus x1 as my return. If I put it in the other business, I get 4 times log 1 plus x2 as the second return. Now, log, logs are going to have diminishing returns so eventually, even though I put money in the second one, which gives me incrementally the better return, I'll end up getting lesser and lesser and so at some point, the first project will become more competitive. Now, the constraint tells me the total amount of money that I have is just 12. If this, if there were no constraints, I would solve this problem easily. But this constraint makes my problem harder. It's a convex problem because log is a concave function and trying to maximize a concave function with respect to some linear constraints. And this is a convex problem so in theory, this is easy. So, in order to get rid of the constraints, what we do is we multiply it by a variable and add it to the objective. So, I've got 2 log 1 plus x1, 4 log 1 plus x2. This is just the objective. Here is my multiplier and it's, it has a mean which is sometimes called the Lagrange multiplier because Lagrange was the first, first mathematician who came up with using this idea. Try take the Lagrange multiplier, v, multiply it to the constraints x1 plus x2 minus 12, what's happened to the minus 12, I moved the 12 on to the other side that becomes my constraint and subtract it from the objective. Now, I throw away the constraints. Remember, we had done something very similar to this in the module linear optimization. We dualized the constraints, multiplied them by a quantity that is a multiplier which had to have some sort of particular sign. In this particular case, I threw away the signs as well. We can be anything and then I threw away the constraints, I relaxed and it just optimized the objective, in order to get the dual linear problem. I'm doing the same thing here. I've got a nonlinear objective, I'm subtracting a multiplier times the constraint and then, I'm going to throw away the constraints and pretend that this is an unconstrained problem. In order, I know that this problem is convex so in order to get the optimum point, all I have to do is find the gradient and find its solution. So, I take the gradient of this Lagrangian function. From here, I get 2 over 1 plus x1. From here, I get minus v. That's the partial derivative with respect to x1. Partial derivative with respect to x2, I get 4 divided by 1 plus x2 minus v, from this one, and that is equal to 0. If I solve this, I get x 1 is equal to 2 or v minus 1, x2 is equal to 4 over v minus 1. How do I get this v? I know that the optimal solution, x1 plus x2, must equal 12, so I plug it in to the equations, and I end up getting an equation that says, 6 over v must equal 14, or v must equal 3 over 7. Once I know the value of v, I plug it back into the expression for x, I get x is equal to 11 over 3 and 25 over 3. So intuitively, it makes sense, you're going to invest more in the second, second opportunity, because it has a higher return. But as you scale up that return, as you scale up your investment, you have diminishing return, so at some point, it becomes profitable to go to the first one, and the correct balance is in the ratio 11 is to 25. And look how easily we were able to solve for this problem by including a Lagrange multiplier, taking the gradients, and then solving it to find what x1 and x2 is. The last piece of this module will show us how to apply this for a particular problem, which comes up over and over again in financial engineering, which is portfolio selection. Now, what's going on here, I've got a bunch of assets, so my x belongs to R to the n. It has n different assets, so it's a vector with n components, what does this constraint say? If I take the vector of all ones and multiply it to x, I get 1. This multiplication just gives me the sum of j going from 1 through n of xj. So, if I add up all the components of my portfolio, I have 1 dollar to invest. And what do I want to do? I want to choose a portfolio that maximizes my return minus a risk aversion parameter lambda times the variance. This is the return or the mean return on my portfolio, v transpose xv, gives me the variance of my portfolio. And I want to do the portfolio x, which sums to 1, and which maximize the, the risk adjusted return. Again, the constraints makes this problem harder, so I'm going to take the constraints, multiply it by a Lagrange multiplier, and put it into the objective. Here's my objective, mu transpose x minus lambda times x transpose vx minus v times 1 transpose x minus 1. Again, a convex problem, it has no constraints, I'm going to take the derivative and set it equal to 0. If I take the gradient with respect to x, I get mu from here. Just to make this thing a little bit clearer, let me get rid of this. This mu is coming from the gradient of that quantity. Minus 2 lambda vx is coming from the gradient of the second quantity. V times 1 is coming from the gradient of this quantity. I set it equal to 0. Now, I solve for x. What is x? X is 1 over 2 lambda v inverse mu minus v1. What do I do? I take this minus 2 lambda vx term onto the other side so this minus becomes plus. And I take the 1 over 2 lambda, divided, take the inverse of the v, multiply it onto the other side, I get x. So now again, like in the simple example that we saw before, I now have x in terms of v. How do I get the v? Plug it into the constraints. 1 transpose x, must equal 1. I put the equation here, I get 1 transpose v inverse mu minus v1 must equal 2 lambda, v is just a scalar. I rearrange terms, I get v is equal to 1 transpose v inverse mu minus 2 lambda divided by 1 transpose v inverse 1. I know the value of v now, I can plug it, plug that value v here, and get expressions for x. And again, this complicated portfolio selection problem has been solved by just taking Lagrange multipliers. We will use this in the course to show how, by using this technique, we can generate efficient frontiers, we can characterize what the shape of these frontiers are, we can say that any point of this efficient frontier can be generated by a small set of mutual funds and that, ultimately, will lead to the capital asset pricing model, which is a very important methodology for pricing assets in the market.

