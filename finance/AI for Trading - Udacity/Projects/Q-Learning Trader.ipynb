{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -nc https://lazyprogrammer.me/course_files/sp500_closefull.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSCO</th>\n",
       "      <th>UAL</th>\n",
       "      <th>TROW</th>\n",
       "      <th>ISRG</th>\n",
       "      <th>PRGO</th>\n",
       "      <th>TPR</th>\n",
       "      <th>DVN</th>\n",
       "      <th>MRO</th>\n",
       "      <th>BA</th>\n",
       "      <th>VRTX</th>\n",
       "      <th>...</th>\n",
       "      <th>M</th>\n",
       "      <th>CRM</th>\n",
       "      <th>PGR</th>\n",
       "      <th>WAT</th>\n",
       "      <th>BWA</th>\n",
       "      <th>LRCX</th>\n",
       "      <th>NWL</th>\n",
       "      <th>UAA</th>\n",
       "      <th>BLK</th>\n",
       "      <th>PPL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>24.690001</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>54.400002</td>\n",
       "      <td>102.923332</td>\n",
       "      <td>40.349998</td>\n",
       "      <td>36.310001</td>\n",
       "      <td>76.570000</td>\n",
       "      <td>19.153616</td>\n",
       "      <td>56.180000</td>\n",
       "      <td>44.240002</td>\n",
       "      <td>...</td>\n",
       "      <td>17.059999</td>\n",
       "      <td>18.705000</td>\n",
       "      <td>18.030001</td>\n",
       "      <td>61.630001</td>\n",
       "      <td>16.889999</td>\n",
       "      <td>39.880001</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>238.580002</td>\n",
       "      <td>30.242558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>24.580000</td>\n",
       "      <td>13.910000</td>\n",
       "      <td>55.009998</td>\n",
       "      <td>102.459999</td>\n",
       "      <td>38.790001</td>\n",
       "      <td>36.750000</td>\n",
       "      <td>76.650002</td>\n",
       "      <td>19.171511</td>\n",
       "      <td>58.020000</td>\n",
       "      <td>42.779999</td>\n",
       "      <td>...</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>60.790001</td>\n",
       "      <td>17.695000</td>\n",
       "      <td>39.610001</td>\n",
       "      <td>15.110000</td>\n",
       "      <td>3.615000</td>\n",
       "      <td>239.610001</td>\n",
       "      <td>29.851370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>24.420000</td>\n",
       "      <td>13.270000</td>\n",
       "      <td>54.150002</td>\n",
       "      <td>103.946663</td>\n",
       "      <td>38.299999</td>\n",
       "      <td>37.470001</td>\n",
       "      <td>76.419998</td>\n",
       "      <td>19.595024</td>\n",
       "      <td>59.779999</td>\n",
       "      <td>42.029999</td>\n",
       "      <td>...</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>18.592501</td>\n",
       "      <td>17.790001</td>\n",
       "      <td>60.900002</td>\n",
       "      <td>18.344999</td>\n",
       "      <td>39.430000</td>\n",
       "      <td>15.380000</td>\n",
       "      <td>3.695000</td>\n",
       "      <td>234.669998</td>\n",
       "      <td>29.916569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>24.530001</td>\n",
       "      <td>13.550000</td>\n",
       "      <td>54.110001</td>\n",
       "      <td>103.556664</td>\n",
       "      <td>37.990002</td>\n",
       "      <td>37.490002</td>\n",
       "      <td>75.970001</td>\n",
       "      <td>19.475725</td>\n",
       "      <td>62.200001</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.490000</td>\n",
       "      <td>18.510000</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>61.160000</td>\n",
       "      <td>18.594999</td>\n",
       "      <td>39.360001</td>\n",
       "      <td>15.820000</td>\n",
       "      <td>3.651250</td>\n",
       "      <td>237.250000</td>\n",
       "      <td>29.627834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>24.660000</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>53.900002</td>\n",
       "      <td>102.986664</td>\n",
       "      <td>37.779999</td>\n",
       "      <td>37.270000</td>\n",
       "      <td>76.120003</td>\n",
       "      <td>19.505550</td>\n",
       "      <td>61.599998</td>\n",
       "      <td>40.669998</td>\n",
       "      <td>...</td>\n",
       "      <td>16.920000</td>\n",
       "      <td>18.537500</td>\n",
       "      <td>17.709999</td>\n",
       "      <td>61.209999</td>\n",
       "      <td>18.254999</td>\n",
       "      <td>40.349998</td>\n",
       "      <td>15.770000</td>\n",
       "      <td>3.643750</td>\n",
       "      <td>238.919998</td>\n",
       "      <td>29.534695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-21</th>\n",
       "      <td>41.849998</td>\n",
       "      <td>81.470001</td>\n",
       "      <td>86.779999</td>\n",
       "      <td>446.019989</td>\n",
       "      <td>37.029999</td>\n",
       "      <td>32.810001</td>\n",
       "      <td>21.910000</td>\n",
       "      <td>13.450000</td>\n",
       "      <td>304.549988</td>\n",
       "      <td>156.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>28.200001</td>\n",
       "      <td>122.910004</td>\n",
       "      <td>59.419998</td>\n",
       "      <td>176.559998</td>\n",
       "      <td>33.770000</td>\n",
       "      <td>127.160004</td>\n",
       "      <td>18.860001</td>\n",
       "      <td>16.959999</td>\n",
       "      <td>369.160004</td>\n",
       "      <td>28.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-24</th>\n",
       "      <td>40.279999</td>\n",
       "      <td>79.120003</td>\n",
       "      <td>84.949997</td>\n",
       "      <td>434.890015</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>32.299999</td>\n",
       "      <td>20.980000</td>\n",
       "      <td>12.660000</td>\n",
       "      <td>294.160004</td>\n",
       "      <td>151.910004</td>\n",
       "      <td>...</td>\n",
       "      <td>28.150000</td>\n",
       "      <td>121.330002</td>\n",
       "      <td>57.070000</td>\n",
       "      <td>173.539993</td>\n",
       "      <td>33.200001</td>\n",
       "      <td>123.279999</td>\n",
       "      <td>17.950001</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>361.769989</td>\n",
       "      <td>27.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-26</th>\n",
       "      <td>42.470001</td>\n",
       "      <td>83.800003</td>\n",
       "      <td>89.650002</td>\n",
       "      <td>461.980011</td>\n",
       "      <td>40.700001</td>\n",
       "      <td>33.889999</td>\n",
       "      <td>22.709999</td>\n",
       "      <td>14.170000</td>\n",
       "      <td>313.929993</td>\n",
       "      <td>161.839996</td>\n",
       "      <td>...</td>\n",
       "      <td>30.129999</td>\n",
       "      <td>130.839996</td>\n",
       "      <td>59.330002</td>\n",
       "      <td>181.190002</td>\n",
       "      <td>34.400002</td>\n",
       "      <td>130.839996</td>\n",
       "      <td>18.910000</td>\n",
       "      <td>17.820000</td>\n",
       "      <td>381.230011</td>\n",
       "      <td>28.309999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-27</th>\n",
       "      <td>42.910000</td>\n",
       "      <td>83.040001</td>\n",
       "      <td>91.309998</td>\n",
       "      <td>468.700012</td>\n",
       "      <td>39.619999</td>\n",
       "      <td>34.150002</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>14.290000</td>\n",
       "      <td>317.140015</td>\n",
       "      <td>162.369995</td>\n",
       "      <td>...</td>\n",
       "      <td>30.040001</td>\n",
       "      <td>135.199997</td>\n",
       "      <td>60.200001</td>\n",
       "      <td>185.179993</td>\n",
       "      <td>34.770000</td>\n",
       "      <td>133.279999</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>387.799988</td>\n",
       "      <td>28.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <td>42.770000</td>\n",
       "      <td>83.169998</td>\n",
       "      <td>91.339996</td>\n",
       "      <td>471.200012</td>\n",
       "      <td>39.919998</td>\n",
       "      <td>33.810001</td>\n",
       "      <td>22.459999</td>\n",
       "      <td>14.080000</td>\n",
       "      <td>316.380005</td>\n",
       "      <td>161.419998</td>\n",
       "      <td>...</td>\n",
       "      <td>30.020000</td>\n",
       "      <td>134.679993</td>\n",
       "      <td>59.650002</td>\n",
       "      <td>184.759995</td>\n",
       "      <td>34.509998</td>\n",
       "      <td>135.419998</td>\n",
       "      <td>18.379999</td>\n",
       "      <td>17.520000</td>\n",
       "      <td>388.230011</td>\n",
       "      <td>28.350000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2263 rows Ã— 429 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CSCO        UAL       TROW        ISRG       PRGO        TPR  \\\n",
       "Date                                                                            \n",
       "2010-01-04  24.690001  12.800000  54.400002  102.923332  40.349998  36.310001   \n",
       "2010-01-05  24.580000  13.910000  55.009998  102.459999  38.790001  36.750000   \n",
       "2010-01-06  24.420000  13.270000  54.150002  103.946663  38.299999  37.470001   \n",
       "2010-01-07  24.530001  13.550000  54.110001  103.556664  37.990002  37.490002   \n",
       "2010-01-08  24.660000  13.330000  53.900002  102.986664  37.779999  37.270000   \n",
       "...               ...        ...        ...         ...        ...        ...   \n",
       "2018-12-21  41.849998  81.470001  86.779999  446.019989  37.029999  32.810001   \n",
       "2018-12-24  40.279999  79.120003  84.949997  434.890015  36.500000  32.299999   \n",
       "2018-12-26  42.470001  83.800003  89.650002  461.980011  40.700001  33.889999   \n",
       "2018-12-27  42.910000  83.040001  91.309998  468.700012  39.619999  34.150002   \n",
       "2018-12-28  42.770000  83.169998  91.339996  471.200012  39.919998  33.810001   \n",
       "\n",
       "                  DVN        MRO          BA        VRTX  ...          M  \\\n",
       "Date                                                      ...              \n",
       "2010-01-04  76.570000  19.153616   56.180000   44.240002  ...  17.059999   \n",
       "2010-01-05  76.650002  19.171511   58.020000   42.779999  ...  16.860001   \n",
       "2010-01-06  76.419998  19.595024   59.779999   42.029999  ...  17.100000   \n",
       "2010-01-07  75.970001  19.475725   62.200001   41.500000  ...  17.490000   \n",
       "2010-01-08  76.120003  19.505550   61.599998   40.669998  ...  16.920000   \n",
       "...               ...        ...         ...         ...  ...        ...   \n",
       "2018-12-21  21.910000  13.450000  304.549988  156.500000  ...  28.200001   \n",
       "2018-12-24  20.980000  12.660000  294.160004  151.910004  ...  28.150000   \n",
       "2018-12-26  22.709999  14.170000  313.929993  161.839996  ...  30.129999   \n",
       "2018-12-27  22.900000  14.290000  317.140015  162.369995  ...  30.040001   \n",
       "2018-12-28  22.459999  14.080000  316.380005  161.419998  ...  30.020000   \n",
       "\n",
       "                   CRM        PGR         WAT        BWA        LRCX  \\\n",
       "Date                                                                   \n",
       "2010-01-04   18.705000  18.030001   61.630001  16.889999   39.880001   \n",
       "2010-01-05   18.625000  17.969999   60.790001  17.695000   39.610001   \n",
       "2010-01-06   18.592501  17.790001   60.900002  18.344999   39.430000   \n",
       "2010-01-07   18.510000  17.549999   61.160000  18.594999   39.360001   \n",
       "2010-01-08   18.537500  17.709999   61.209999  18.254999   40.349998   \n",
       "...                ...        ...         ...        ...         ...   \n",
       "2018-12-21  122.910004  59.419998  176.559998  33.770000  127.160004   \n",
       "2018-12-24  121.330002  57.070000  173.539993  33.200001  123.279999   \n",
       "2018-12-26  130.839996  59.330002  181.190002  34.400002  130.839996   \n",
       "2018-12-27  135.199997  60.200001  185.179993  34.770000  133.279999   \n",
       "2018-12-28  134.679993  59.650002  184.759995  34.509998  135.419998   \n",
       "\n",
       "                  NWL        UAA         BLK        PPL  \n",
       "Date                                                     \n",
       "2010-01-04  15.200000   3.510000  238.580002  30.242558  \n",
       "2010-01-05  15.110000   3.615000  239.610001  29.851370  \n",
       "2010-01-06  15.380000   3.695000  234.669998  29.916569  \n",
       "2010-01-07  15.820000   3.651250  237.250000  29.627834  \n",
       "2010-01-08  15.770000   3.643750  238.919998  29.534695  \n",
       "...               ...        ...         ...        ...  \n",
       "2018-12-21  18.860001  16.959999  369.160004  28.400000  \n",
       "2018-12-24  17.950001  16.750000  361.769989  27.590000  \n",
       "2018-12-26  18.910000  17.820000  381.230011  28.309999  \n",
       "2018-12-27  18.400000  17.910000  387.799988  28.340000  \n",
       "2018-12-28  18.379999  17.520000  388.230011  28.350000  \n",
       "\n",
       "[2263 rows x 429 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = pd.read_csv('sp500_closefull.csv', index_col=0, parse_dates=True)\n",
    "df0.dropna(axis=0, how='all', inplace=True)\n",
    "df0.dropna(axis=1, how='any', inplace=True)\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n",
      "/tmp/ipykernel_58407/121027654.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_returns[name] = np.log(df0[name]).diff()\n"
     ]
    }
   ],
   "source": [
    "df_returns = pd.DataFrame()\n",
    "for name in df0.columns:\n",
    "    df_returns[name] = np.log(df0[name]).diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntest = 1000\n",
    "train = df_returns.iloc[:-Ntest].copy()\n",
    "test = df_returns.iloc[-Ntest:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    def __init__(self, df, feats):\n",
    "        self.df = df\n",
    "        self.n = len(df)\n",
    "        self.current_idx = 0\n",
    "        self.action_space = [0, 1, 2]  # BUY, SELL, HOLD\n",
    "        self.invested = 0\n",
    "        \n",
    "        self.states = self.df[feats].to_numpy()\n",
    "        self.rewards = self.df['SPY'].to_numpy()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_idx = 0\n",
    "        return self.states[self.current_idx]\n",
    "    \n",
    "    def step(self, action):\n",
    "        # need to return (next_state, reward, done)\n",
    "        self.current_idx += 1\n",
    "        \n",
    "        if self.current_idx >= self.n:\n",
    "            raise Exception(\"Episode already done\")\n",
    "        \n",
    "        if action == 0:  # BUY\n",
    "            self.invested = 1\n",
    "        elif action == 1:  # SELL\n",
    "            self.invested = 0\n",
    "        \n",
    "        # Compute reward\n",
    "        if self.invested:\n",
    "            reward = self.rewards[self.current_idx]\n",
    "        else:\n",
    "            reward = 0\n",
    "        \n",
    "        # State transition\n",
    "        next_state = self.states[self.current_idx]\n",
    "        \n",
    "        # Check if the episode is done\n",
    "        done = (self.current_idx == self.n - 1)\n",
    "        \n",
    "        return next_state, reward, done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateMapper:\n",
    "    def __init__(self, env, n_bins=6, n_samples=10_000):\n",
    "        # First, collect sample states from the environment\n",
    "        states = []\n",
    "        done = False\n",
    "        s = env.reset()\n",
    "        self.D = len(s)  # Number of elements we need to bin\n",
    "        states.append(s)\n",
    "        \n",
    "        for _ in range(n_samples):\n",
    "            a = np.random.choice(env.action_space)\n",
    "            s2, _, done = env.step(a)\n",
    "            states.append(s2)\n",
    "            if done:\n",
    "                s = env.reset()\n",
    "                states.append(s)\n",
    "        \n",
    "        # Convert to numpy array for easy indexing\n",
    "        states = np.array(states)\n",
    "        \n",
    "        # Create the bins for each dimension\n",
    "        self.bins = []\n",
    "        for d in range(self.D):\n",
    "            column = np.sort(states[:, d])\n",
    "            \n",
    "            # Find the boundaries for each bin\n",
    "            current_bin = []\n",
    "            for k in range(n_bins):\n",
    "                boundary = column[int(n_samples / n_bins * (k + 0.5))]\n",
    "                current_bin.append(boundary)\n",
    "            self.bins.append(current_bin)\n",
    "\n",
    "    def transform(self, state):\n",
    "        x = np.zeros(self.D)\n",
    "        for d in range(self.D):\n",
    "            x[d] = int(np.digitize(state[d], self.bins[d]))\n",
    "        return tuple(x)\n",
    "    \n",
    "    def all_possible_states(self):\n",
    "        list_of_bins = []\n",
    "        for d in range(self.D):\n",
    "            list_of_bins.append(list(range(len(self.bins[d]) + 1)))\n",
    "        # print(list_of_bins)\n",
    "        return itertools.product(*list_of_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, action_size, state_mapper):\n",
    "        self.action_size = action_size\n",
    "        self.gamma = 0.8  # Discount rate\n",
    "        self.epsilon = 0.1\n",
    "        self.learning_rate = 1e-1\n",
    "        self.state_mapper = state_mapper\n",
    "\n",
    "        # Initialize Q-table randomly\n",
    "        self.Q = {}\n",
    "        for s in self.state_mapper.all_possible_states():\n",
    "            s = tuple(s)\n",
    "            for a in range(self.action_size):\n",
    "                self.Q[(s, a)] = np.random.randn()\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(self.action_size)\n",
    "\n",
    "        s = self.state_mapper.transform(state)\n",
    "        act_values = [self.Q[(s, a)] for a in range(self.action_size)]\n",
    "        return np.argmax(act_values)  # returns action\n",
    "\n",
    "    def train(self, state, action, reward, next_state, done):\n",
    "        s = self.state_mapper.transform(state)\n",
    "        s2 = self.state_mapper.transform(next_state)\n",
    "\n",
    "        if done:\n",
    "            target =reward\n",
    "        else:\n",
    "            act_values = [self.Q[(s2, a)] for a in range(self.action_size)]\n",
    "            target = reward + self.gamma * np.amax(act_values)\n",
    "\n",
    "        self.Q[(s, action)] += self.learning_rate * (target-self.Q[(s, action)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_episode(agent, env, is_train):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        if is_train:\n",
    "            agent.train(state, action, reward, next_state, done)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "    return total_reward\n",
    "\n",
    "num_episodes = 500\n",
    "\n",
    "feats = ['AAPL', 'MSFT', 'AMZN']\n",
    "train_env = Env(train, feats)\n",
    "test_env = Env(test, feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = len(train_env.action_space)\n",
    "state_mapper = StateMapper(train_env)\n",
    "agent = Agent(action_size, state_mapper)\n",
    "\n",
    "train_rewards = np.empty(num_episodes)\n",
    "test_rewards = np.empty(num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1/500, Train Reward: 0.23286, Test Reward: -0.02492\n",
      "Episode: 2/500, Train Reward: 0.36763, Test Reward: -0.09907\n",
      "Episode: 3/500, Train Reward: 0.44214, Test Reward: -0.15572\n",
      "Episode: 4/500, Train Reward: 0.14158, Test Reward: -0.03877\n",
      "Episode: 5/500, Train Reward: 0.46183, Test Reward: -0.07498\n",
      "Episode: 6/500, Train Reward: 0.11787, Test Reward: -0.01374\n",
      "Episode: 7/500, Train Reward: 0.16263, Test Reward: -0.00838\n",
      "Episode: 8/500, Train Reward: 0.29683, Test Reward: 0.00548\n",
      "Episode: 9/500, Train Reward: 0.29608, Test Reward: 0.07075\n",
      "Episode: 10/500, Train Reward: 0.26466, Test Reward: 0.03212\n",
      "Episode: 11/500, Train Reward: 0.59957, Test Reward: 0.07252\n",
      "Episode: 12/500, Train Reward: 0.10676, Test Reward: 0.00658\n",
      "Episode: 13/500, Train Reward: 0.39778, Test Reward: -0.04343\n",
      "Episode: 14/500, Train Reward: 0.26843, Test Reward: 0.15025\n",
      "Episode: 15/500, Train Reward: 0.07506, Test Reward: 0.02199\n",
      "Episode: 16/500, Train Reward: 0.26116, Test Reward: 0.01025\n",
      "Episode: 17/500, Train Reward: 0.31255, Test Reward: -0.07308\n",
      "Episode: 18/500, Train Reward: 0.52339, Test Reward: 0.19742\n",
      "Episode: 19/500, Train Reward: 0.20458, Test Reward: 0.10852\n",
      "Episode: 20/500, Train Reward: 0.13291, Test Reward: 0.02935\n",
      "Episode: 21/500, Train Reward: 0.29544, Test Reward: -0.00042\n",
      "Episode: 22/500, Train Reward: 0.26133, Test Reward: 0.07567\n",
      "Episode: 23/500, Train Reward: 0.47502, Test Reward: -0.09071\n",
      "Episode: 24/500, Train Reward: 0.33415, Test Reward: 0.16628\n",
      "Episode: 25/500, Train Reward: 0.33073, Test Reward: -0.09934\n",
      "Episode: 26/500, Train Reward: 0.14197, Test Reward: -0.03741\n",
      "Episode: 27/500, Train Reward: 0.45942, Test Reward: -0.06342\n",
      "Episode: 28/500, Train Reward: 0.18951, Test Reward: -0.12820\n",
      "Episode: 29/500, Train Reward: 0.36734, Test Reward: 0.07410\n",
      "Episode: 30/500, Train Reward: 0.39707, Test Reward: 0.04788\n",
      "Episode: 31/500, Train Reward: 0.49901, Test Reward: -0.08515\n",
      "Episode: 32/500, Train Reward: 0.17694, Test Reward: -0.08939\n",
      "Episode: 33/500, Train Reward: 0.31368, Test Reward: 0.01173\n",
      "Episode: 34/500, Train Reward: 0.34980, Test Reward: 0.02137\n",
      "Episode: 35/500, Train Reward: 0.17844, Test Reward: -0.09497\n",
      "Episode: 36/500, Train Reward: 0.33278, Test Reward: -0.14654\n",
      "Episode: 37/500, Train Reward: 0.18121, Test Reward: -0.07771\n",
      "Episode: 38/500, Train Reward: 0.65530, Test Reward: 0.10697\n",
      "Episode: 39/500, Train Reward: 0.30926, Test Reward: -0.02550\n",
      "Episode: 40/500, Train Reward: 0.48976, Test Reward: -0.02687\n",
      "Episode: 41/500, Train Reward: 0.37806, Test Reward: -0.01717\n",
      "Episode: 42/500, Train Reward: 0.75046, Test Reward: 0.17405\n",
      "Episode: 43/500, Train Reward: 0.26695, Test Reward: -0.13133\n",
      "Episode: 44/500, Train Reward: 0.59635, Test Reward: 0.06775\n",
      "Episode: 45/500, Train Reward: 0.44405, Test Reward: 0.13481\n",
      "Episode: 46/500, Train Reward: 0.60775, Test Reward: 0.18415\n",
      "Episode: 47/500, Train Reward: 0.37589, Test Reward: 0.00827\n",
      "Episode: 48/500, Train Reward: 0.49258, Test Reward: 0.04641\n",
      "Episode: 49/500, Train Reward: 0.50600, Test Reward: -0.06288\n",
      "Episode: 50/500, Train Reward: 0.41128, Test Reward: 0.23025\n",
      "Episode: 51/500, Train Reward: 0.78352, Test Reward: -0.02968\n",
      "Episode: 52/500, Train Reward: 0.57805, Test Reward: 0.12026\n",
      "Episode: 53/500, Train Reward: 0.57365, Test Reward: 0.18309\n",
      "Episode: 54/500, Train Reward: 0.44072, Test Reward: 0.21599\n",
      "Episode: 55/500, Train Reward: 0.62291, Test Reward: -0.05927\n",
      "Episode: 56/500, Train Reward: 0.38588, Test Reward: 0.18796\n",
      "Episode: 57/500, Train Reward: 0.63787, Test Reward: -0.07976\n",
      "Episode: 58/500, Train Reward: 0.87670, Test Reward: -0.10489\n",
      "Episode: 59/500, Train Reward: 0.34207, Test Reward: -0.05757\n",
      "Episode: 60/500, Train Reward: 0.51509, Test Reward: -0.13270\n",
      "Episode: 61/500, Train Reward: 0.84976, Test Reward: 0.23347\n",
      "Episode: 62/500, Train Reward: 0.54854, Test Reward: 0.08737\n",
      "Episode: 63/500, Train Reward: 0.45337, Test Reward: 0.14850\n",
      "Episode: 64/500, Train Reward: 0.53506, Test Reward: 0.05976\n",
      "Episode: 65/500, Train Reward: 0.44650, Test Reward: -0.00874\n",
      "Episode: 66/500, Train Reward: 0.50625, Test Reward: -0.05738\n",
      "Episode: 67/500, Train Reward: 0.36240, Test Reward: -0.11547\n",
      "Episode: 68/500, Train Reward: 0.50713, Test Reward: -0.04123\n",
      "Episode: 69/500, Train Reward: 0.36819, Test Reward: 0.20675\n",
      "Episode: 70/500, Train Reward: 0.45358, Test Reward: 0.20309\n",
      "Episode: 71/500, Train Reward: 0.51746, Test Reward: 0.03989\n",
      "Episode: 72/500, Train Reward: 0.67482, Test Reward: -0.07062\n",
      "Episode: 73/500, Train Reward: 0.55096, Test Reward: 0.04309\n",
      "Episode: 74/500, Train Reward: 0.61119, Test Reward: 0.04469\n",
      "Episode: 75/500, Train Reward: 0.26672, Test Reward: 0.10479\n",
      "Episode: 76/500, Train Reward: 0.46595, Test Reward: 0.00068\n",
      "Episode: 77/500, Train Reward: 0.61369, Test Reward: 0.06904\n",
      "Episode: 78/500, Train Reward: 0.47515, Test Reward: 0.11829\n",
      "Episode: 79/500, Train Reward: 0.90178, Test Reward: -0.01248\n",
      "Episode: 80/500, Train Reward: 0.86723, Test Reward: 0.14804\n",
      "Episode: 81/500, Train Reward: 0.40860, Test Reward: 0.16910\n",
      "Episode: 82/500, Train Reward: 0.43702, Test Reward: 0.27652\n",
      "Episode: 83/500, Train Reward: 0.59869, Test Reward: 0.16886\n",
      "Episode: 84/500, Train Reward: 0.66896, Test Reward: 0.21269\n",
      "Episode: 85/500, Train Reward: 0.54269, Test Reward: 0.20673\n",
      "Episode: 86/500, Train Reward: 0.45361, Test Reward: -0.00623\n",
      "Episode: 87/500, Train Reward: 0.38686, Test Reward: 0.08660\n",
      "Episode: 88/500, Train Reward: 0.59296, Test Reward: 0.14146\n",
      "Episode: 89/500, Train Reward: 0.56654, Test Reward: 0.15510\n",
      "Episode: 90/500, Train Reward: 0.60235, Test Reward: 0.27311\n",
      "Episode: 91/500, Train Reward: 0.57462, Test Reward: -0.11473\n",
      "Episode: 92/500, Train Reward: 0.91775, Test Reward: 0.18443\n",
      "Episode: 93/500, Train Reward: 0.77861, Test Reward: -0.01171\n",
      "Episode: 94/500, Train Reward: 0.92689, Test Reward: 0.03195\n",
      "Episode: 95/500, Train Reward: 0.81359, Test Reward: -0.01477\n",
      "Episode: 96/500, Train Reward: 0.78520, Test Reward: 0.03981\n",
      "Episode: 97/500, Train Reward: 0.84049, Test Reward: 0.16404\n",
      "Episode: 98/500, Train Reward: 0.68103, Test Reward: -0.00266\n",
      "Episode: 99/500, Train Reward: 0.62983, Test Reward: 0.14100\n",
      "Episode: 100/500, Train Reward: 0.95378, Test Reward: 0.05420\n",
      "Episode: 101/500, Train Reward: 0.75013, Test Reward: 0.01098\n",
      "Episode: 102/500, Train Reward: 0.79499, Test Reward: 0.31752\n",
      "Episode: 103/500, Train Reward: 0.72325, Test Reward: 0.28765\n",
      "Episode: 104/500, Train Reward: 0.88325, Test Reward: 0.02109\n",
      "Episode: 105/500, Train Reward: 0.71641, Test Reward: 0.07194\n",
      "Episode: 106/500, Train Reward: 1.03333, Test Reward: 0.13492\n",
      "Episode: 107/500, Train Reward: 0.92555, Test Reward: 0.21175\n",
      "Episode: 108/500, Train Reward: 1.01802, Test Reward: -0.01174\n",
      "Episode: 109/500, Train Reward: 0.88440, Test Reward: 0.26682\n",
      "Episode: 110/500, Train Reward: 0.89023, Test Reward: 0.15394\n",
      "Episode: 111/500, Train Reward: 1.05879, Test Reward: 0.09495\n",
      "Episode: 112/500, Train Reward: 1.07107, Test Reward: 0.04223\n",
      "Episode: 113/500, Train Reward: 1.07028, Test Reward: 0.00669\n",
      "Episode: 114/500, Train Reward: 0.92310, Test Reward: 0.17744\n",
      "Episode: 115/500, Train Reward: 1.09097, Test Reward: 0.16016\n",
      "Episode: 116/500, Train Reward: 1.27291, Test Reward: 0.23442\n",
      "Episode: 117/500, Train Reward: 1.34857, Test Reward: 0.07990\n",
      "Episode: 118/500, Train Reward: 1.10371, Test Reward: 0.19553\n",
      "Episode: 119/500, Train Reward: 1.21463, Test Reward: 0.10294\n",
      "Episode: 120/500, Train Reward: 1.07823, Test Reward: 0.20200\n",
      "Episode: 121/500, Train Reward: 0.91005, Test Reward: 0.03338\n",
      "Episode: 122/500, Train Reward: 0.90437, Test Reward: 0.16635\n",
      "Episode: 123/500, Train Reward: 1.16196, Test Reward: 0.21106\n",
      "Episode: 124/500, Train Reward: 1.20842, Test Reward: 0.09749\n",
      "Episode: 125/500, Train Reward: 1.11642, Test Reward: -0.02538\n",
      "Episode: 126/500, Train Reward: 0.94719, Test Reward: 0.10543\n",
      "Episode: 127/500, Train Reward: 1.03057, Test Reward: 0.08033\n",
      "Episode: 128/500, Train Reward: 1.08589, Test Reward: 0.07473\n",
      "Episode: 129/500, Train Reward: 1.17831, Test Reward: 0.20031\n",
      "Episode: 130/500, Train Reward: 1.18166, Test Reward: 0.03192\n",
      "Episode: 131/500, Train Reward: 1.12748, Test Reward: 0.06187\n",
      "Episode: 132/500, Train Reward: 1.08237, Test Reward: 0.02120\n",
      "Episode: 133/500, Train Reward: 1.00540, Test Reward: 0.09604\n",
      "Episode: 134/500, Train Reward: 1.00875, Test Reward: 0.08179\n",
      "Episode: 135/500, Train Reward: 1.08462, Test Reward: 0.14164\n",
      "Episode: 136/500, Train Reward: 1.28642, Test Reward: 0.05312\n",
      "Episode: 137/500, Train Reward: 1.19731, Test Reward: 0.02685\n",
      "Episode: 138/500, Train Reward: 1.07456, Test Reward: 0.09157\n",
      "Episode: 139/500, Train Reward: 1.03267, Test Reward: 0.01848\n",
      "Episode: 140/500, Train Reward: 1.12563, Test Reward: 0.10306\n",
      "Episode: 141/500, Train Reward: 1.18764, Test Reward: 0.02599\n",
      "Episode: 142/500, Train Reward: 1.11857, Test Reward: -0.04507\n",
      "Episode: 143/500, Train Reward: 1.21736, Test Reward: -0.08229\n",
      "Episode: 144/500, Train Reward: 1.22619, Test Reward: -0.04746\n",
      "Episode: 145/500, Train Reward: 0.99390, Test Reward: 0.06890\n",
      "Episode: 146/500, Train Reward: 1.23400, Test Reward: 0.15809\n",
      "Episode: 147/500, Train Reward: 1.19379, Test Reward: 0.14921\n",
      "Episode: 148/500, Train Reward: 1.23162, Test Reward: 0.00733\n",
      "Episode: 149/500, Train Reward: 1.15049, Test Reward: 0.04720\n",
      "Episode: 150/500, Train Reward: 1.11693, Test Reward: -0.10414\n",
      "Episode: 151/500, Train Reward: 1.30797, Test Reward: 0.11191\n",
      "Episode: 152/500, Train Reward: 1.21856, Test Reward: 0.03300\n",
      "Episode: 153/500, Train Reward: 1.34220, Test Reward: 0.15551\n",
      "Episode: 154/500, Train Reward: 1.28412, Test Reward: -0.02061\n",
      "Episode: 155/500, Train Reward: 1.35441, Test Reward: 0.12738\n",
      "Episode: 156/500, Train Reward: 1.22611, Test Reward: 0.02989\n",
      "Episode: 157/500, Train Reward: 1.29459, Test Reward: 0.00772\n",
      "Episode: 158/500, Train Reward: 1.43997, Test Reward: 0.05515\n",
      "Episode: 159/500, Train Reward: 1.42578, Test Reward: 0.13054\n",
      "Episode: 160/500, Train Reward: 1.29001, Test Reward: 0.13997\n",
      "Episode: 161/500, Train Reward: 1.43198, Test Reward: 0.05373\n",
      "Episode: 162/500, Train Reward: 1.29475, Test Reward: -0.02179\n",
      "Episode: 163/500, Train Reward: 1.25827, Test Reward: 0.02438\n",
      "Episode: 164/500, Train Reward: 1.10547, Test Reward: -0.00106\n",
      "Episode: 165/500, Train Reward: 1.25025, Test Reward: 0.08289\n",
      "Episode: 166/500, Train Reward: 1.24550, Test Reward: 0.04285\n",
      "Episode: 167/500, Train Reward: 1.35155, Test Reward: 0.05247\n",
      "Episode: 168/500, Train Reward: 1.17764, Test Reward: 0.01206\n",
      "Episode: 169/500, Train Reward: 1.32905, Test Reward: 0.03723\n",
      "Episode: 170/500, Train Reward: 1.32332, Test Reward: -0.00490\n",
      "Episode: 171/500, Train Reward: 1.27347, Test Reward: 0.10518\n",
      "Episode: 172/500, Train Reward: 1.30931, Test Reward: 0.02693\n",
      "Episode: 173/500, Train Reward: 1.43583, Test Reward: 0.07192\n",
      "Episode: 174/500, Train Reward: 1.26246, Test Reward: 0.17790\n",
      "Episode: 175/500, Train Reward: 1.19761, Test Reward: 0.21473\n",
      "Episode: 176/500, Train Reward: 1.28345, Test Reward: 0.14481\n",
      "Episode: 177/500, Train Reward: 1.33385, Test Reward: 0.20799\n",
      "Episode: 178/500, Train Reward: 1.48112, Test Reward: 0.15742\n",
      "Episode: 179/500, Train Reward: 1.47118, Test Reward: 0.22149\n",
      "Episode: 180/500, Train Reward: 1.39513, Test Reward: 0.08815\n",
      "Episode: 181/500, Train Reward: 1.18815, Test Reward: 0.20081\n",
      "Episode: 182/500, Train Reward: 1.19914, Test Reward: 0.19227\n",
      "Episode: 183/500, Train Reward: 1.44768, Test Reward: 0.25473\n",
      "Episode: 184/500, Train Reward: 1.50089, Test Reward: 0.20478\n",
      "Episode: 185/500, Train Reward: 1.66557, Test Reward: 0.26827\n",
      "Episode: 186/500, Train Reward: 1.37136, Test Reward: 0.20833\n",
      "Episode: 187/500, Train Reward: 1.51391, Test Reward: 0.19907\n",
      "Episode: 188/500, Train Reward: 1.35861, Test Reward: 0.28210\n",
      "Episode: 189/500, Train Reward: 1.25665, Test Reward: 0.26949\n",
      "Episode: 190/500, Train Reward: 1.47206, Test Reward: 0.18044\n",
      "Episode: 191/500, Train Reward: 1.31905, Test Reward: 0.25578\n",
      "Episode: 192/500, Train Reward: 1.35971, Test Reward: 0.15642\n",
      "Episode: 193/500, Train Reward: 1.51572, Test Reward: 0.19867\n",
      "Episode: 194/500, Train Reward: 1.37905, Test Reward: 0.22157\n",
      "Episode: 195/500, Train Reward: 1.58371, Test Reward: 0.15530\n",
      "Episode: 196/500, Train Reward: 1.58631, Test Reward: 0.22817\n",
      "Episode: 197/500, Train Reward: 1.51833, Test Reward: 0.07532\n",
      "Episode: 198/500, Train Reward: 1.58741, Test Reward: 0.16114\n",
      "Episode: 199/500, Train Reward: 1.50673, Test Reward: 0.08159\n",
      "Episode: 200/500, Train Reward: 1.43994, Test Reward: 0.20713\n",
      "Episode: 201/500, Train Reward: 1.45571, Test Reward: 0.14422\n",
      "Episode: 202/500, Train Reward: 1.53958, Test Reward: 0.28416\n",
      "Episode: 203/500, Train Reward: 1.45247, Test Reward: 0.17856\n",
      "Episode: 204/500, Train Reward: 1.55109, Test Reward: 0.25633\n",
      "Episode: 205/500, Train Reward: 1.57368, Test Reward: 0.16834\n",
      "Episode: 206/500, Train Reward: 1.57100, Test Reward: 0.18962\n",
      "Episode: 207/500, Train Reward: 1.46747, Test Reward: 0.12467\n",
      "Episode: 208/500, Train Reward: 1.44101, Test Reward: 0.16710\n",
      "Episode: 209/500, Train Reward: 1.60108, Test Reward: 0.09795\n",
      "Episode: 210/500, Train Reward: 1.56448, Test Reward: 0.16238\n",
      "Episode: 211/500, Train Reward: 1.54855, Test Reward: 0.10624\n",
      "Episode: 212/500, Train Reward: 1.48216, Test Reward: 0.17768\n",
      "Episode: 213/500, Train Reward: 1.49780, Test Reward: 0.19282\n",
      "Episode: 214/500, Train Reward: 1.46674, Test Reward: 0.20680\n",
      "Episode: 215/500, Train Reward: 1.38580, Test Reward: 0.26098\n",
      "Episode: 216/500, Train Reward: 1.57388, Test Reward: 0.33358\n",
      "Episode: 217/500, Train Reward: 1.46842, Test Reward: 0.23640\n",
      "Episode: 218/500, Train Reward: 1.55866, Test Reward: 0.28265\n",
      "Episode: 219/500, Train Reward: 1.67499, Test Reward: 0.16363\n",
      "Episode: 220/500, Train Reward: 1.65328, Test Reward: 0.21246\n",
      "Episode: 221/500, Train Reward: 1.46276, Test Reward: 0.21232\n",
      "Episode: 222/500, Train Reward: 1.44327, Test Reward: 0.22368\n",
      "Episode: 223/500, Train Reward: 1.51113, Test Reward: 0.19125\n",
      "Episode: 224/500, Train Reward: 1.59777, Test Reward: 0.17643\n",
      "Episode: 225/500, Train Reward: 1.53743, Test Reward: 0.21621\n",
      "Episode: 226/500, Train Reward: 1.64405, Test Reward: 0.28548\n",
      "Episode: 227/500, Train Reward: 1.39908, Test Reward: 0.25602\n",
      "Episode: 228/500, Train Reward: 1.38835, Test Reward: 0.24604\n",
      "Episode: 229/500, Train Reward: 1.48766, Test Reward: 0.29332\n",
      "Episode: 230/500, Train Reward: 1.51178, Test Reward: 0.30622\n",
      "Episode: 231/500, Train Reward: 1.34740, Test Reward: 0.24026\n",
      "Episode: 232/500, Train Reward: 1.41385, Test Reward: 0.28470\n",
      "Episode: 233/500, Train Reward: 1.56419, Test Reward: 0.22177\n",
      "Episode: 234/500, Train Reward: 1.43689, Test Reward: 0.30578\n",
      "Episode: 235/500, Train Reward: 1.27276, Test Reward: 0.20056\n",
      "Episode: 236/500, Train Reward: 1.36262, Test Reward: 0.27044\n",
      "Episode: 237/500, Train Reward: 1.40005, Test Reward: 0.24115\n",
      "Episode: 238/500, Train Reward: 1.45303, Test Reward: 0.21457\n",
      "Episode: 239/500, Train Reward: 1.55498, Test Reward: 0.24269\n",
      "Episode: 240/500, Train Reward: 1.54025, Test Reward: 0.25576\n",
      "Episode: 241/500, Train Reward: 1.57107, Test Reward: 0.28710\n",
      "Episode: 242/500, Train Reward: 1.40109, Test Reward: 0.25708\n",
      "Episode: 243/500, Train Reward: 1.57623, Test Reward: 0.26394\n",
      "Episode: 244/500, Train Reward: 1.53128, Test Reward: 0.22625\n",
      "Episode: 245/500, Train Reward: 1.54291, Test Reward: 0.27891\n",
      "Episode: 246/500, Train Reward: 1.64767, Test Reward: 0.23636\n",
      "Episode: 247/500, Train Reward: 1.60750, Test Reward: 0.28409\n",
      "Episode: 248/500, Train Reward: 1.55183, Test Reward: 0.30272\n",
      "Episode: 249/500, Train Reward: 1.56581, Test Reward: 0.23368\n",
      "Episode: 250/500, Train Reward: 1.64207, Test Reward: 0.33067\n",
      "Episode: 251/500, Train Reward: 1.58110, Test Reward: 0.24821\n",
      "Episode: 252/500, Train Reward: 1.49152, Test Reward: 0.22648\n",
      "Episode: 253/500, Train Reward: 1.72434, Test Reward: 0.24206\n",
      "Episode: 254/500, Train Reward: 1.61744, Test Reward: 0.24331\n",
      "Episode: 255/500, Train Reward: 1.68704, Test Reward: 0.26289\n",
      "Episode: 256/500, Train Reward: 1.64915, Test Reward: 0.24733\n",
      "Episode: 257/500, Train Reward: 1.71728, Test Reward: 0.26741\n",
      "Episode: 258/500, Train Reward: 1.75252, Test Reward: 0.22931\n",
      "Episode: 259/500, Train Reward: 1.44994, Test Reward: 0.23277\n",
      "Episode: 260/500, Train Reward: 1.42590, Test Reward: 0.22839\n",
      "Episode: 261/500, Train Reward: 1.52732, Test Reward: 0.25602\n",
      "Episode: 262/500, Train Reward: 1.56011, Test Reward: 0.21464\n",
      "Episode: 263/500, Train Reward: 1.67130, Test Reward: 0.21107\n",
      "Episode: 264/500, Train Reward: 1.54649, Test Reward: 0.21493\n",
      "Episode: 265/500, Train Reward: 1.70884, Test Reward: 0.25038\n",
      "Episode: 266/500, Train Reward: 1.56085, Test Reward: 0.23741\n",
      "Episode: 267/500, Train Reward: 1.82753, Test Reward: 0.22008\n",
      "Episode: 268/500, Train Reward: 1.65547, Test Reward: 0.29724\n",
      "Episode: 269/500, Train Reward: 1.43708, Test Reward: 0.26055\n",
      "Episode: 270/500, Train Reward: 1.64535, Test Reward: 0.25930\n",
      "Episode: 271/500, Train Reward: 1.64548, Test Reward: 0.25930\n",
      "Episode: 272/500, Train Reward: 1.60797, Test Reward: 0.25930\n",
      "Episode: 273/500, Train Reward: 1.67079, Test Reward: 0.26164\n",
      "Episode: 274/500, Train Reward: 1.59477, Test Reward: 0.26577\n",
      "Episode: 275/500, Train Reward: 1.59902, Test Reward: 0.22476\n",
      "Episode: 276/500, Train Reward: 1.59967, Test Reward: 0.29970\n",
      "Episode: 277/500, Train Reward: 1.66739, Test Reward: 0.26823\n",
      "Episode: 278/500, Train Reward: 1.63504, Test Reward: 0.25091\n",
      "Episode: 279/500, Train Reward: 1.73025, Test Reward: 0.31182\n",
      "Episode: 280/500, Train Reward: 1.66821, Test Reward: 0.26276\n",
      "Episode: 281/500, Train Reward: 1.48291, Test Reward: 0.22255\n",
      "Episode: 282/500, Train Reward: 1.65817, Test Reward: 0.17106\n",
      "Episode: 283/500, Train Reward: 1.45171, Test Reward: 0.28816\n",
      "Episode: 284/500, Train Reward: 1.48199, Test Reward: 0.20974\n",
      "Episode: 285/500, Train Reward: 1.58946, Test Reward: 0.23773\n",
      "Episode: 286/500, Train Reward: 1.57110, Test Reward: 0.21290\n",
      "Episode: 287/500, Train Reward: 1.51457, Test Reward: 0.23822\n",
      "Episode: 288/500, Train Reward: 1.64782, Test Reward: 0.21066\n",
      "Episode: 289/500, Train Reward: 1.59063, Test Reward: 0.19192\n",
      "Episode: 290/500, Train Reward: 1.51867, Test Reward: 0.18668\n",
      "Episode: 291/500, Train Reward: 1.65752, Test Reward: 0.20541\n",
      "Episode: 292/500, Train Reward: 1.44484, Test Reward: 0.20892\n",
      "Episode: 293/500, Train Reward: 1.56844, Test Reward: 0.24298\n",
      "Episode: 294/500, Train Reward: 1.59705, Test Reward: 0.18023\n",
      "Episode: 295/500, Train Reward: 1.61808, Test Reward: 0.23784\n",
      "Episode: 296/500, Train Reward: 1.43692, Test Reward: 0.22079\n",
      "Episode: 297/500, Train Reward: 1.69404, Test Reward: 0.24523\n",
      "Episode: 298/500, Train Reward: 1.59323, Test Reward: 0.28381\n",
      "Episode: 299/500, Train Reward: 1.62759, Test Reward: 0.27168\n",
      "Episode: 300/500, Train Reward: 1.51923, Test Reward: 0.30434\n",
      "Episode: 301/500, Train Reward: 1.62852, Test Reward: 0.31834\n",
      "Episode: 302/500, Train Reward: 1.61680, Test Reward: 0.29357\n",
      "Episode: 303/500, Train Reward: 1.63677, Test Reward: 0.27553\n",
      "Episode: 304/500, Train Reward: 1.53400, Test Reward: 0.32783\n",
      "Episode: 305/500, Train Reward: 1.52483, Test Reward: 0.20385\n",
      "Episode: 306/500, Train Reward: 1.66964, Test Reward: 0.24373\n",
      "Episode: 307/500, Train Reward: 1.69572, Test Reward: 0.24739\n",
      "Episode: 308/500, Train Reward: 1.67706, Test Reward: 0.27885\n",
      "Episode: 309/500, Train Reward: 1.70727, Test Reward: 0.15435\n",
      "Episode: 310/500, Train Reward: 1.70589, Test Reward: 0.26411\n",
      "Episode: 311/500, Train Reward: 1.74292, Test Reward: 0.22576\n",
      "Episode: 312/500, Train Reward: 1.52669, Test Reward: 0.22576\n",
      "Episode: 313/500, Train Reward: 1.84986, Test Reward: 0.22428\n",
      "Episode: 314/500, Train Reward: 1.53724, Test Reward: 0.24235\n",
      "Episode: 315/500, Train Reward: 1.60336, Test Reward: 0.18203\n",
      "Episode: 316/500, Train Reward: 1.64225, Test Reward: 0.15444\n",
      "Episode: 317/500, Train Reward: 1.83403, Test Reward: 0.25337\n",
      "Episode: 318/500, Train Reward: 1.74445, Test Reward: 0.25072\n",
      "Episode: 319/500, Train Reward: 1.86562, Test Reward: 0.24795\n",
      "Episode: 320/500, Train Reward: 1.73543, Test Reward: 0.28727\n",
      "Episode: 321/500, Train Reward: 1.65174, Test Reward: 0.22382\n",
      "Episode: 322/500, Train Reward: 1.68237, Test Reward: 0.18965\n",
      "Episode: 323/500, Train Reward: 1.61817, Test Reward: 0.24106\n",
      "Episode: 324/500, Train Reward: 1.49148, Test Reward: 0.21441\n",
      "Episode: 325/500, Train Reward: 1.77406, Test Reward: 0.15839\n",
      "Episode: 326/500, Train Reward: 1.75918, Test Reward: 0.26121\n",
      "Episode: 327/500, Train Reward: 1.80233, Test Reward: 0.22644\n",
      "Episode: 328/500, Train Reward: 1.68696, Test Reward: 0.21804\n",
      "Episode: 329/500, Train Reward: 1.60931, Test Reward: 0.16058\n",
      "Episode: 330/500, Train Reward: 1.61769, Test Reward: 0.15843\n",
      "Episode: 331/500, Train Reward: 1.46808, Test Reward: 0.21740\n",
      "Episode: 332/500, Train Reward: 1.78215, Test Reward: 0.17366\n",
      "Episode: 333/500, Train Reward: 1.58375, Test Reward: 0.15880\n",
      "Episode: 334/500, Train Reward: 1.65415, Test Reward: 0.25942\n",
      "Episode: 335/500, Train Reward: 1.55988, Test Reward: 0.22801\n",
      "Episode: 336/500, Train Reward: 2.02927, Test Reward: 0.22741\n",
      "Episode: 337/500, Train Reward: 1.45723, Test Reward: 0.17597\n",
      "Episode: 338/500, Train Reward: 1.64119, Test Reward: 0.25029\n",
      "Episode: 339/500, Train Reward: 1.40298, Test Reward: 0.25812\n",
      "Episode: 340/500, Train Reward: 1.52156, Test Reward: 0.22805\n",
      "Episode: 341/500, Train Reward: 1.73099, Test Reward: 0.17410\n",
      "Episode: 342/500, Train Reward: 1.60553, Test Reward: 0.19479\n",
      "Episode: 343/500, Train Reward: 1.61819, Test Reward: 0.15842\n",
      "Episode: 344/500, Train Reward: 1.47809, Test Reward: 0.21794\n",
      "Episode: 345/500, Train Reward: 1.64642, Test Reward: 0.24279\n",
      "Episode: 346/500, Train Reward: 1.71491, Test Reward: 0.24870\n",
      "Episode: 347/500, Train Reward: 1.64338, Test Reward: 0.21006\n",
      "Episode: 348/500, Train Reward: 1.63496, Test Reward: 0.19332\n",
      "Episode: 349/500, Train Reward: 1.64761, Test Reward: 0.17153\n",
      "Episode: 350/500, Train Reward: 1.66739, Test Reward: 0.27241\n",
      "Episode: 351/500, Train Reward: 1.76644, Test Reward: 0.25753\n",
      "Episode: 352/500, Train Reward: 1.76087, Test Reward: 0.24499\n",
      "Episode: 353/500, Train Reward: 1.74843, Test Reward: 0.21941\n",
      "Episode: 354/500, Train Reward: 1.83703, Test Reward: 0.20712\n",
      "Episode: 355/500, Train Reward: 1.53076, Test Reward: 0.20526\n",
      "Episode: 356/500, Train Reward: 1.66442, Test Reward: 0.19608\n",
      "Episode: 357/500, Train Reward: 1.69989, Test Reward: 0.26696\n",
      "Episode: 358/500, Train Reward: 1.51632, Test Reward: 0.17156\n",
      "Episode: 359/500, Train Reward: 1.62728, Test Reward: 0.18990\n",
      "Episode: 360/500, Train Reward: 1.64782, Test Reward: 0.24797\n",
      "Episode: 361/500, Train Reward: 1.56712, Test Reward: 0.21991\n",
      "Episode: 362/500, Train Reward: 1.73978, Test Reward: 0.22707\n",
      "Episode: 363/500, Train Reward: 1.79181, Test Reward: 0.21251\n",
      "Episode: 364/500, Train Reward: 1.77589, Test Reward: 0.22398\n",
      "Episode: 365/500, Train Reward: 1.81025, Test Reward: 0.24452\n",
      "Episode: 366/500, Train Reward: 1.74849, Test Reward: 0.23474\n",
      "Episode: 367/500, Train Reward: 1.80237, Test Reward: 0.19552\n",
      "Episode: 368/500, Train Reward: 1.67691, Test Reward: 0.22261\n",
      "Episode: 369/500, Train Reward: 1.68689, Test Reward: 0.24475\n",
      "Episode: 370/500, Train Reward: 1.74816, Test Reward: 0.21617\n",
      "Episode: 371/500, Train Reward: 1.58444, Test Reward: 0.23062\n",
      "Episode: 372/500, Train Reward: 1.66998, Test Reward: 0.22987\n",
      "Episode: 373/500, Train Reward: 1.65620, Test Reward: 0.23148\n",
      "Episode: 374/500, Train Reward: 1.82587, Test Reward: 0.21147\n",
      "Episode: 375/500, Train Reward: 1.66375, Test Reward: 0.18546\n",
      "Episode: 376/500, Train Reward: 1.65575, Test Reward: 0.21585\n",
      "Episode: 377/500, Train Reward: 1.75985, Test Reward: 0.30091\n",
      "Episode: 378/500, Train Reward: 1.69286, Test Reward: 0.23176\n",
      "Episode: 379/500, Train Reward: 1.64750, Test Reward: 0.21382\n",
      "Episode: 380/500, Train Reward: 1.67045, Test Reward: 0.23478\n",
      "Episode: 381/500, Train Reward: 1.87387, Test Reward: 0.24555\n",
      "Episode: 382/500, Train Reward: 1.72963, Test Reward: 0.23695\n",
      "Episode: 383/500, Train Reward: 1.41891, Test Reward: 0.21871\n",
      "Episode: 384/500, Train Reward: 1.93030, Test Reward: 0.22668\n",
      "Episode: 385/500, Train Reward: 1.68838, Test Reward: 0.18306\n",
      "Episode: 386/500, Train Reward: 1.70746, Test Reward: 0.20132\n",
      "Episode: 387/500, Train Reward: 1.60813, Test Reward: 0.18084\n",
      "Episode: 388/500, Train Reward: 1.76112, Test Reward: 0.20770\n",
      "Episode: 389/500, Train Reward: 1.73922, Test Reward: 0.24759\n",
      "Episode: 390/500, Train Reward: 1.88426, Test Reward: 0.32973\n",
      "Episode: 391/500, Train Reward: 1.73297, Test Reward: 0.28687\n",
      "Episode: 392/500, Train Reward: 1.86958, Test Reward: 0.28626\n",
      "Episode: 393/500, Train Reward: 1.83525, Test Reward: 0.33037\n",
      "Episode: 394/500, Train Reward: 1.79926, Test Reward: 0.26504\n",
      "Episode: 395/500, Train Reward: 1.64951, Test Reward: 0.31405\n",
      "Episode: 396/500, Train Reward: 1.65427, Test Reward: 0.34901\n",
      "Episode: 397/500, Train Reward: 1.70770, Test Reward: 0.35032\n",
      "Episode: 398/500, Train Reward: 1.39167, Test Reward: 0.32104\n",
      "Episode: 399/500, Train Reward: 1.68310, Test Reward: 0.32853\n",
      "Episode: 400/500, Train Reward: 1.66585, Test Reward: 0.28888\n",
      "Episode: 401/500, Train Reward: 1.70255, Test Reward: 0.24620\n",
      "Episode: 402/500, Train Reward: 1.75950, Test Reward: 0.36359\n",
      "Episode: 403/500, Train Reward: 1.62613, Test Reward: 0.29714\n",
      "Episode: 404/500, Train Reward: 1.85832, Test Reward: 0.27732\n",
      "Episode: 405/500, Train Reward: 1.83747, Test Reward: 0.32358\n",
      "Episode: 406/500, Train Reward: 1.73495, Test Reward: 0.29049\n",
      "Episode: 407/500, Train Reward: 1.88922, Test Reward: 0.30877\n",
      "Episode: 408/500, Train Reward: 1.75145, Test Reward: 0.29661\n",
      "Episode: 409/500, Train Reward: 1.74949, Test Reward: 0.27913\n",
      "Episode: 410/500, Train Reward: 1.76115, Test Reward: 0.31151\n",
      "Episode: 411/500, Train Reward: 1.64893, Test Reward: 0.31151\n",
      "Episode: 412/500, Train Reward: 1.77931, Test Reward: 0.28322\n",
      "Episode: 413/500, Train Reward: 1.68453, Test Reward: 0.27478\n",
      "Episode: 414/500, Train Reward: 1.71378, Test Reward: 0.29476\n",
      "Episode: 415/500, Train Reward: 1.77449, Test Reward: 0.27175\n",
      "Episode: 416/500, Train Reward: 1.74168, Test Reward: 0.16303\n",
      "Episode: 417/500, Train Reward: 1.79400, Test Reward: 0.08848\n",
      "Episode: 418/500, Train Reward: 1.76059, Test Reward: 0.25796\n",
      "Episode: 419/500, Train Reward: 1.70141, Test Reward: 0.22724\n",
      "Episode: 420/500, Train Reward: 1.75144, Test Reward: 0.32377\n",
      "Episode: 421/500, Train Reward: 1.64635, Test Reward: 0.23097\n",
      "Episode: 422/500, Train Reward: 1.64561, Test Reward: 0.27777\n",
      "Episode: 423/500, Train Reward: 1.91874, Test Reward: 0.27499\n",
      "Episode: 424/500, Train Reward: 1.68464, Test Reward: 0.24205\n",
      "Episode: 425/500, Train Reward: 1.75249, Test Reward: 0.20895\n",
      "Episode: 426/500, Train Reward: 1.60329, Test Reward: 0.16504\n",
      "Episode: 427/500, Train Reward: 1.64051, Test Reward: 0.19328\n",
      "Episode: 428/500, Train Reward: 1.81350, Test Reward: 0.22945\n",
      "Episode: 429/500, Train Reward: 1.69173, Test Reward: 0.18771\n",
      "Episode: 430/500, Train Reward: 1.62333, Test Reward: 0.12237\n",
      "Episode: 431/500, Train Reward: 1.86066, Test Reward: 0.18020\n",
      "Episode: 432/500, Train Reward: 1.57983, Test Reward: 0.12977\n",
      "Episode: 433/500, Train Reward: 2.01557, Test Reward: 0.17832\n",
      "Episode: 434/500, Train Reward: 1.84231, Test Reward: 0.26654\n",
      "Episode: 435/500, Train Reward: 1.82020, Test Reward: 0.18722\n",
      "Episode: 436/500, Train Reward: 1.72216, Test Reward: 0.26669\n",
      "Episode: 437/500, Train Reward: 1.65495, Test Reward: 0.25218\n",
      "Episode: 438/500, Train Reward: 1.87708, Test Reward: 0.28283\n",
      "Episode: 439/500, Train Reward: 1.59349, Test Reward: 0.32013\n",
      "Episode: 440/500, Train Reward: 1.87512, Test Reward: 0.33120\n",
      "Episode: 441/500, Train Reward: 1.72898, Test Reward: 0.34379\n",
      "Episode: 442/500, Train Reward: 1.61565, Test Reward: 0.32090\n",
      "Episode: 443/500, Train Reward: 1.78901, Test Reward: 0.31587\n",
      "Episode: 444/500, Train Reward: 1.71264, Test Reward: 0.32066\n",
      "Episode: 445/500, Train Reward: 1.78659, Test Reward: 0.27251\n",
      "Episode: 446/500, Train Reward: 1.84508, Test Reward: 0.28873\n",
      "Episode: 447/500, Train Reward: 1.92045, Test Reward: 0.29453\n",
      "Episode: 448/500, Train Reward: 1.78959, Test Reward: 0.26214\n",
      "Episode: 449/500, Train Reward: 1.97749, Test Reward: 0.35305\n",
      "Episode: 450/500, Train Reward: 1.73241, Test Reward: 0.31902\n",
      "Episode: 451/500, Train Reward: 1.77101, Test Reward: 0.29981\n",
      "Episode: 452/500, Train Reward: 1.80853, Test Reward: 0.27227\n",
      "Episode: 453/500, Train Reward: 1.94509, Test Reward: 0.28841\n",
      "Episode: 454/500, Train Reward: 1.86599, Test Reward: 0.27172\n",
      "Episode: 455/500, Train Reward: 1.78458, Test Reward: 0.10869\n",
      "Episode: 456/500, Train Reward: 1.88690, Test Reward: 0.24785\n",
      "Episode: 457/500, Train Reward: 1.97966, Test Reward: 0.23060\n",
      "Episode: 458/500, Train Reward: 1.84123, Test Reward: 0.07012\n",
      "Episode: 459/500, Train Reward: 1.73686, Test Reward: 0.21097\n",
      "Episode: 460/500, Train Reward: 1.73934, Test Reward: 0.19451\n",
      "Episode: 461/500, Train Reward: 1.72888, Test Reward: 0.23669\n",
      "Episode: 462/500, Train Reward: 1.66344, Test Reward: 0.19335\n",
      "Episode: 463/500, Train Reward: 1.95900, Test Reward: 0.19813\n",
      "Episode: 464/500, Train Reward: 1.82408, Test Reward: 0.18041\n",
      "Episode: 465/500, Train Reward: 1.68730, Test Reward: 0.19261\n",
      "Episode: 466/500, Train Reward: 1.61863, Test Reward: 0.21194\n",
      "Episode: 467/500, Train Reward: 1.82360, Test Reward: 0.25043\n",
      "Episode: 468/500, Train Reward: 1.68992, Test Reward: 0.26140\n",
      "Episode: 469/500, Train Reward: 1.92513, Test Reward: 0.31244\n",
      "Episode: 470/500, Train Reward: 1.79810, Test Reward: 0.32178\n",
      "Episode: 471/500, Train Reward: 1.68386, Test Reward: 0.28593\n",
      "Episode: 472/500, Train Reward: 1.53454, Test Reward: 0.30335\n",
      "Episode: 473/500, Train Reward: 1.85910, Test Reward: 0.25571\n",
      "Episode: 474/500, Train Reward: 1.70208, Test Reward: 0.25477\n",
      "Episode: 475/500, Train Reward: 1.68176, Test Reward: 0.27615\n",
      "Episode: 476/500, Train Reward: 1.66090, Test Reward: 0.21282\n",
      "Episode: 477/500, Train Reward: 1.83239, Test Reward: 0.22706\n",
      "Episode: 478/500, Train Reward: 1.89814, Test Reward: 0.18216\n",
      "Episode: 479/500, Train Reward: 1.65880, Test Reward: 0.24799\n",
      "Episode: 480/500, Train Reward: 2.03623, Test Reward: 0.27452\n",
      "Episode: 481/500, Train Reward: 1.89296, Test Reward: 0.24905\n",
      "Episode: 482/500, Train Reward: 1.89875, Test Reward: 0.27243\n",
      "Episode: 483/500, Train Reward: 1.88301, Test Reward: 0.30588\n",
      "Episode: 484/500, Train Reward: 1.86490, Test Reward: 0.23080\n",
      "Episode: 485/500, Train Reward: 1.88641, Test Reward: 0.26487\n",
      "Episode: 486/500, Train Reward: 1.89413, Test Reward: 0.20003\n",
      "Episode: 487/500, Train Reward: 1.86394, Test Reward: 0.23015\n",
      "Episode: 488/500, Train Reward: 1.79658, Test Reward: 0.28694\n",
      "Episode: 489/500, Train Reward: 1.91614, Test Reward: 0.26990\n",
      "Episode: 490/500, Train Reward: 1.76298, Test Reward: 0.19659\n",
      "Episode: 491/500, Train Reward: 1.78285, Test Reward: 0.17928\n",
      "Episode: 492/500, Train Reward: 1.68638, Test Reward: 0.23217\n",
      "Episode: 493/500, Train Reward: 1.77332, Test Reward: 0.30850\n",
      "Episode: 494/500, Train Reward: 1.86189, Test Reward: 0.30980\n",
      "Episode: 495/500, Train Reward: 1.79986, Test Reward: 0.26304\n",
      "Episode: 496/500, Train Reward: 1.71703, Test Reward: 0.20126\n",
      "Episode: 497/500, Train Reward: 1.82710, Test Reward: 0.18889\n",
      "Episode: 498/500, Train Reward: 1.71800, Test Reward: 0.24843\n",
      "Episode: 499/500, Train Reward: 1.86385, Test Reward: 0.20739\n",
      "Episode: 500/500, Train Reward: 1.78507, Test Reward: 0.27794\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for e in range(num_episodes):\n",
    "    r = play_one_episode(agent, train_env, is_train=True)\n",
    "    train_rewards[e] = r  # Store the reward from the training episode\n",
    "    \n",
    "    # Test on the test set\n",
    "    tmp_epsilon = agent.epsilon\n",
    "    agent.epsilon = 0.  # Set epsilon to 0 for testing\n",
    "    tr = play_one_episode(agent, test_env, is_train=False)\n",
    "    agent.epsilon = tmp_epsilon  # Restore the original epsilon\n",
    "    \n",
    "    test_rewards[e] = tr  # Store the reward from the testing episode\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Episode: {e + 1}/{num_episodes}, Train Reward: {r:.5f}, Test Reward: {tr:.5f}\")\n",
    "\n",
    "# Plot the rewards\n",
    "plt.plot(train_rewards, label='Train Rewards')\n",
    "plt.plot(test_rewards, label='Test Rewards')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
