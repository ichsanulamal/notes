{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week_1-Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom\n",
    "\n",
    "# Function to plot the binomial distribution for a sequence of n values\n",
    "def plot_binomial_distributions(nlist, p):\n",
    "    for n in nlist:\n",
    "        k = np.arange(0, n+1)\n",
    "        f = binom.pmf(k, n, p)\n",
    "        plt.bar(k, f)\n",
    "        plt.xlabel('Number of Successes')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.title(f'Binomial Distribution, p={p} n={n}')\n",
    "        plt.show()\n",
    "\n",
    "# Function to plot the rescaled binomial distributions\n",
    "def plot_rescaled_binomial_distributions(nlist, p, zmax):\n",
    "    for n in nlist:\n",
    "        k = np.arange(0, n+1)\n",
    "        z = (k - n*p) / np.sqrt(n*p*(1-p))\n",
    "        zi = np.abs(z) <= zmax\n",
    "        f = binom.pmf(k, n, p)\n",
    "        plt.bar(z[zi], f[zi])\n",
    "        plt.xlabel('Scaling Variable z')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.title(f'Binomial Distribution, p={p} n={n}')\n",
    "        plt.show()\n",
    "\n",
    "# Parameters\n",
    "nlist = [1, 2, 5, 10, 20, 50, 100, 1000]\n",
    "p = 0.1\n",
    "zmax = 5\n",
    "\n",
    "# Plot the binomial distributions\n",
    "plot_binomial_distributions(nlist, p)\n",
    "\n",
    "# Plot the rescaled binomial distributions\n",
    "plot_rescaled_binomial_distributions(nlist, p, zmax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week_2-Introduction_to_Discrete-Time_Stochastic_Processes\n",
    "\n",
    "## AR(1) Process Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "phi = 0.8\n",
    "mu = 0\n",
    "sigma = 1\n",
    "n = 100\n",
    "\n",
    "# Generate white noise\n",
    "epsilon = np.random.normal(0, sigma, n)\n",
    "\n",
    "# Initialize the series\n",
    "X = np.zeros(n)\n",
    "\n",
    "# Simulate the AR(1) process\n",
    "for t in range(1, n):\n",
    "    X[t] = mu + phi * X[t-1] + epsilon[t]\n",
    "\n",
    "# Plot the series\n",
    "plt.plot(X)\n",
    "plt.title('AR(1) Process Simulation')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('X_t')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "title: \"Testing the Random Walk\"\n",
    "author: \"Paul F. Mende\"\n",
    "date: \"Summer 2021\"\n",
    "output: \n",
    "  html_notebook:\n",
    "  df_print: paged\n",
    "  toc: yes\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll load packages.\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tootsie Roll\n",
    "\n",
    "Let's load some data and look at default summary stats for data from Tootsie Roll (TR).\n",
    "\n",
    "**Technical note:** Data is often exchanged using \"flat files,\" which are plain text files that can be read using a simple text editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch some test data from Yahoo! Finance\n",
    "\n",
    "# Define query parameters\n",
    "ticker = \"TR\"\n",
    "date_first = \"1987-12-31\"\n",
    "date_last = \"2017-12-31\"\n",
    "\n",
    "# Get the data\n",
    "TR = yf.download(ticker, start=date_first, end=date_last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is what the price looks like over time\n",
    "\n",
    "plt.plot(TR.index, TR['Adj Close'], label='Adjusted Price')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.title('TR Adjusted Price 1988-2017')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the returns\n",
    "P = TR['Adj Close']\n",
    "r = np.diff(np.log(P))\n",
    "N = len(r)\n",
    "\n",
    "# The returns can also be stored as a new column in TR.\n",
    "TR['r'] = np.append([np.nan], r)\n",
    "\n",
    "# Trim off the first row, which has return NA\n",
    "TR = TR.dropna()\n",
    "\n",
    "plt.plot(TR.index, TR['r'], label='Daily Returns')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('TR Daily Returns 1988-2017')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The daily return series is noisy, and the mean value is barely visible.\n",
    "# Compare the graph above with the simulation below, in which simulated returns have the same average volatility and zero mean.\n",
    "\n",
    "plt.plot(TR.index, np.random.normal(scale=np.std(TR['r']), size=len(TR)), label='White Noise')\n",
    "plt.ylim(-0.18, 0.18)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('White Noise Process with TR Volatility')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ## Summary statistics and return distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are high-level summary stats that pandas provides for any data frame.\n",
    "TR.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annualization conventions\n",
    "# Annualized return = 252 * (Daily return)\n",
    "# Annualized std. dev. = sqrt(252) * (Daily std. dev)\n",
    "\n",
    "mean_return_annualized = np.mean(r) * 252\n",
    "volatility_annualized = np.std(r) * np.sqrt(252)\n",
    "\n",
    "mean_return_annualized, volatility_annualized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The histogram of returns has fat tails (and therefore a thin middle).\n",
    "\n",
    "plt.hist(r, bins=50)\n",
    "plt.title('Histogram of TR Daily Returns')\n",
    "plt.show()\n",
    "\n",
    "# ## Lo & MacKinlay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following Lo & MacKinlay, we ask whether the measured sample variance of returns grows linearly as a function of the observation interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variance = [np.var(np.diff(np.log(P)))]\n",
    "\n",
    "for n in range(2, 101):\n",
    "    Variance.append(np.var(np.diff(np.log(P[::n]))))\n",
    "\n",
    "plt.plot(Variance)\n",
    "plt.xlabel('n')\n",
    "plt.title('Variance of Returns From n-day Observations')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ## Variance and Ratios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for $\\widehat \\sigma^2_c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_c(X, q):\n",
    "    T = len(X) - 1\n",
    "    mu = (X[-1] - X[0]) / T\n",
    "    m = (T - q) * (T - q + 1) * q / T\n",
    "    sumsq = sum((X[t + 1] - X[t - q + 1] - q * mu) ** 2 for t in range(q, T))\n",
    "    return sumsq / m\n",
    "\n",
    "def z_stat(X, q):\n",
    "    T = len(X) - 1\n",
    "    c = np.sqrt(T * (3 * q) / (2 * (2 * q - 1) * (q - 1)))\n",
    "    M = variance_c(X, q) / variance_c(X, 1) - 1\n",
    "    return c * M\n",
    "\n",
    "Vc = [variance_c(np.log(P), q) for q in range(1, 101)]\n",
    "zstats = [z_stat(np.log(P), q) for q in range(2, 101)]\n",
    "pValues = [2 * (1 - np.abs(np.random.normal(0, 1))) for z in zstats]\n",
    "\n",
    "plt.bar(range(2, 101), zstats)\n",
    "plt.xlabel('q')\n",
    "plt.ylabel('z')\n",
    "plt.title('z Statistics of Variance Ratio Test')\n",
    "plt.show()\n",
    "\n",
    "# ## Interpreting the test statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test statistic $z(q)$ was constructed to be normally distributed as ${\\cal N}(0,1)$ if the data followed a random walk and scaled accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = [np.sqrt(252) * np.std(np.diff(np.log(P)))]\n",
    "for n in range(2, 101):\n",
    "    sigma.append(np.sqrt(252 / n) * np.std(np.diff(np.log(P[::n]))))\n",
    "\n",
    "plt.bar(range(1, 101), sigma)\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('Standard Deviation (annualized) / sqrt(n)')\n",
    "plt.title('Volatility Scaling of Returns From n-day Observations (TR)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation of returns with similar volatility\n",
    "\n",
    "P_MC = np.exp(np.cumsum(np.random.normal(scale=0.02, size=N)))\n",
    "sigma_MC = [np.sqrt(252) * np.std(np.diff(np.log(P_MC)))]\n",
    "\n",
    "for n in range(2, 101):\n",
    "    sigma_MC.append(np.sqrt(252 / n) * np.std(np.diff(np.log(P_MC[::n]))))\n",
    "\n",
    "plt.bar(range(1, 101), sigma_MC)\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('Standard Deviation (annualized) / sqrt(n)')\n",
    "plt.title('Volatility Scaling of Returns From n-day Observations (Sim)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple 20-step random walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set probability of \"success\" and \"failure\"\n",
    "p = 0.5\n",
    "q = 1 - p\n",
    "\n",
    "# Number of time steps\n",
    "Nt = 20\n",
    "\n",
    "# Number of sample paths\n",
    "Np = 1\n",
    "\n",
    "# Generate a set of uniform random draws\n",
    "z = np.random.rand(Nt, Np)\n",
    "\n",
    "# Transform to binomial random variable +/- 1\n",
    "x = np.sign(p - z)\n",
    "\n",
    "# Initial value for random walk\n",
    "s = np.zeros((Nt + 1, Np))\n",
    "\n",
    "# Perform the random walk\n",
    "for t in range(Nt):\n",
    "    s[t + 1, :] = s[t, :] + x[t, :]\n",
    "\n",
    "# Plot the resulting path\n",
    "plt.plot(s, marker='o')\n",
    "plt.xlabel('Time step')\n",
    "plt.ylabel('Position')\n",
    "plt.title('Random Walk')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many simulations of a one-year daily walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set probability of \"success\" and \"failure\"\n",
    "p = 0.5\n",
    "q = 1 - p\n",
    "\n",
    "# Number of trading days in a year\n",
    "Nt = 252\n",
    "\n",
    "# Number of simulations\n",
    "Np = int(1e4)\n",
    "\n",
    "# Generate a set of uniform random draws\n",
    "z = np.random.rand(Nt, Np)\n",
    "\n",
    "# Transform to binomial random variable +/- 1\n",
    "x = np.sign(p - z)\n",
    "\n",
    "# Initialize and reserve space for random paths\n",
    "s = np.zeros((Nt + 1, Np))\n",
    "\n",
    "# Perform the random walk\n",
    "for t in range(Nt):\n",
    "    s[t + 1, :] = s[t, :] + x[t, :]\n",
    "\n",
    "# Plot the first three paths\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(s[:, :3])\n",
    "plt.xlabel('Time step')\n",
    "plt.ylabel('Position')\n",
    "plt.title('Random Walk Simulations')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating a lognormal price process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set parameters\n",
    "sigma = 0.3  # Annualized volatility (30%)\n",
    "mu = 0.1     # Annualized drift/return (10%)\n",
    "dt = 1 / 252 # Time step scale factor (daily)\n",
    "\n",
    "# Number of trading days in a year\n",
    "Nt = 252\n",
    "\n",
    "# Number of simulations\n",
    "Np = int(1e4)\n",
    "\n",
    "# Generate a set of standard normal random draws\n",
    "z = np.random.randn(Nt, Np)\n",
    "\n",
    "# Draw daily returns from scaled N(mu, sigma^2)\n",
    "r = mu * dt + z * sigma * np.sqrt(dt)\n",
    "\n",
    "# Initialize and reserve space for paths\n",
    "s = np.zeros((Nt + 1, Np))\n",
    "\n",
    "# Simulate the paths\n",
    "for t in range(Nt):\n",
    "    s[t + 1, :] = s[t, :] + r[t, :]\n",
    "\n",
    "# Calculate prices using exponential of the cumulative returns\n",
    "P = np.exp(s)\n",
    "\n",
    "# Plot the first three paths\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(P[:, :3], linewidth=1)\n",
    "plt.xlabel('Time step')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Simulated Stock Price Paths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Assuming P is already defined from the previous code\n",
    "R = P[-1, :] - 1  # Calculate returns\n",
    "\n",
    "# Calculate mean and expected return\n",
    "mean_R = np.mean(R)\n",
    "expected_return = np.exp(mu + sigma**2 / 2) - 1\n",
    "\n",
    "# Calculate standard deviation\n",
    "sd_R = np.std(R)\n",
    "expected_sd = np.sqrt(np.exp(2 * mu + sigma**2) * (np.exp(sigma**2) - 1))\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean of R: {mean_R}\")\n",
    "print(f\"Expected return: {expected_return}\")\n",
    "print(f\"Standard deviation of R: {sd_R}\")\n",
    "print(f\"Expected standard deviation: {expected_sd}\")\n",
    "\n",
    "# Histograms\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(R, bins=50, edgecolor='k')\n",
    "plt.title('Histogram of R')\n",
    "plt.xlabel('Returns')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(np.log1p(R), bins=50, edgecolor='k')\n",
    "plt.title('Histogram of log(1 + R)')\n",
    "plt.xlabel('Log Returns')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ECDF plot\n",
    "sns.ecdfplot(1 + R)\n",
    "plt.title('ECDF of 1 + R')\n",
    "plt.xlabel('1 + R')\n",
    "plt.ylabel('ECDF')\n",
    "plt.show()\n",
    "\n",
    "# Bar plot of sorted returns\n",
    "plt.bar(range(len(R)), np.sort(1 + R))\n",
    "plt.title('Sorted 1 + R')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Sorted Returns')\n",
    "plt.show()\n",
    "\n",
    "# QQ plot\n",
    "stats.probplot(1 + R, dist=\"norm\", plot=plt)\n",
    "plt.title('QQ Plot of 1 + R')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "lambda_ = 0.4\n",
    "mu = 0.1\n",
    "Nt = 100  # Number of time steps\n",
    "Np = 10   # Number of processes\n",
    "sigma = 1  # Standard deviation of noise\n",
    "dt = 1    # Time increment\n",
    "\n",
    "# Initialize matrices\n",
    "R = np.zeros((Nt, Np))\n",
    "epsilon = np.random.normal(scale=sigma * np.sqrt(dt), size=(Nt, Np))  # Simulate noise\n",
    "\n",
    "# Run simulation process forward in time\n",
    "for t in range(1, Nt):\n",
    "    R[t, :] = (1 + lambda_) * (mu * dt) - lambda_ * R[t - 1, :] + epsilon[t, :]\n",
    "\n",
    "r = np.log(1 + R)  # Continuous return\n",
    "\n",
    "# Calculate and plot autocorrelation function\n",
    "acf_values = sm.tsa.acf(R[:, 0], fft=True)\n",
    "plt.plot(acf_values)\n",
    "plt.title('Autocorrelation of R')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('ACF')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "title: \"Time Series Data and Models\"\n",
    "subtitle: \"Model Identification and Estimation\"\n",
    "author: \"Paul F. Mende\"\n",
    "date: \"Summer 2021\"\n",
    "output: \n",
    "  html_notebook:\n",
    "  df_print: paged\n",
    "  toc: yes\n",
    "---\n",
    "\n",
    "# ## The right model?\n",
    "\n",
    "# Making inferences from real-world data and building effective models is a challenging process.  The data rarely fits exactly, and models may stop working.  So it always requires judgment, not just stats and number crunching, in applying modeling and forecasting techniques. For that reason, Monte Carlo simulations provide an excellent testing laboratory for identifcation techniques.  We can be sure that a \"right answer\" exists, then see which analytics identify it and how much uncertainty remains in a best-case scenario.\n",
    "\n",
    "# - Given a model, estimate its parameters\n",
    "# - Given a class of models, determine the best\n",
    "\n",
    "# ## Order determination:  AR(2) Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll load packages.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate AR(2) process\n",
    "c_0 = 0.001\n",
    "c_1 = -0.1\n",
    "c_2 = 0.4\n",
    "sigma = 1\n",
    "Nt = 1000\n",
    "r = np.zeros(Nt)\n",
    "z = np.random.normal(size=Nt)\n",
    "\n",
    "for t in range(2, Nt):\n",
    "    r[t] = c_0 + c_1 * r[t - 1] + c_2 * r[t - 2] + sigma * z[t]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(r))\n",
    "plt.title('AR(2) Sample Path')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('r')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(r, title=\"AR(2) Sample Autocorrelation Function\")\n",
    "plot_pacf(r, title=\"AR(2) Sample Partial Autocorrelation Function\")\n",
    "plt.show()\n",
    "\n",
    "# ## Model estimation: AR(2) example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method (1) Numerical estimation using ordinary least squares\n",
    "y = r[2:]\n",
    "x1 = r[1:-1]\n",
    "x2 = r[:-2]\n",
    "\n",
    "X = np.column_stack([x1, x2])\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method (2): Using the arima function\n",
    "model_ar2 = sm.tsa.ARIMA(r, order=(2, 0, 0)).fit()\n",
    "print(model_ar2.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we get the order incorrect?\n",
    "model_ar5 = sm.tsa.ARIMA(r, order=(5, 0, 0)).fit()\n",
    "print(model_ar5.summary())\n",
    "\n",
    "# ## Order determination: MA(2) Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate MA(2) process\n",
    "mu = 0.0\n",
    "sigma = 1.0\n",
    "phi_1 = -0.1\n",
    "phi_2 = 0.4\n",
    "r = np.zeros(Nt)\n",
    "z = np.random.normal(size=Nt)\n",
    "\n",
    "r[0] = mu + sigma * z[0]\n",
    "r[1] = mu + sigma * z[1] + phi_1 * z[0]\n",
    "for t in range(2, Nt):\n",
    "    r[t] = mu + sigma * z[t] + phi_1 * z[t - 1] + phi_2 * z[t - 2]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(r))\n",
    "plt.title('MA(2) Sample Path')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('r')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(r, title=\"MA(2) Sample Autocorrelation Function\")\n",
    "plot_pacf(r, title=\"MA(2) Sample Partial Autocorrelation Function\")\n",
    "plt.show()\n",
    "\n",
    "# ## Model estimation: MA(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ma2 = sm.tsa.ARIMA(r, order=(0, 0, 2)).fit()\n",
    "print(model_ma2.summary())\n",
    "\n",
    "# ## Real data is much harder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "# Define query parameters\n",
    "ticker = \"TR\"\n",
    "date_first = \"1987-12-31\"\n",
    "date_last = \"2017-12-31\"\n",
    "\n",
    "# Get the data\n",
    "TR = yf.download(ticker, start=date_first, end=date_last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is what the price looks like over time\n",
    "\n",
    "plt.plot(TR.index, TR['Adj Close'], label='Adjusted Price')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.title('TR Adjusted Price 1988-2017')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the returns\n",
    "P = TR['Adj Close']\n",
    "r = np.diff(np.log(P))\n",
    "N = len(r)\n",
    "\n",
    "# The returns can also be stored as a new column in TR.\n",
    "TR['r'] = np.append([np.nan], r)\n",
    "\n",
    "# Trim off the first row, which has return NA\n",
    "TR = TR.dropna()\n",
    "\n",
    "plt.plot(TR.index, TR['r'], label='Daily Returns')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('TR Daily Returns 1988-2017')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the series stationary?\n",
    "plt.plot(TR.index, np.random.normal(0, np.std(TR['r']), len(TR)), label='White Noise')\n",
    "plt.ylim(-0.18, 0.18)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.title('White Noise Process with TR Volatility')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brownian Motions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def brownian_motion(n, num_paths):\n",
    "    # n: number of steps\n",
    "    # num_paths: number of paths to generate\n",
    "    dt = 0.1  # time step\n",
    "    paths = np.zeros((num_paths, n, 2))  # initialize paths\n",
    "\n",
    "    for i in range(num_paths):\n",
    "        for j in range(1, n):\n",
    "            # Random steps\n",
    "            dx = np.sqrt(dt) * np.random.randn()\n",
    "            dy = np.sqrt(dt) * np.random.randn()\n",
    "            paths[i, j] = paths[i, j-1] + [dx, dy]\n",
    "\n",
    "    return paths\n",
    "\n",
    "# Parameters\n",
    "num_steps = 1000\n",
    "num_paths = 5\n",
    "\n",
    "# Generate Brownian motion paths\n",
    "paths = brownian_motion(num_steps, num_paths)\n",
    "\n",
    "# Plot the paths\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(num_paths):\n",
    "    plt.plot(paths[i, :, 0], paths[i, :, 1], label=f'Path {i+1}')\n",
    "\n",
    "plt.title('Brownian Motion Paths')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
